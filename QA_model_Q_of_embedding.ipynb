{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering Model \n",
    "## no trainer\n",
    "\n",
    "- dataset\n",
    "- torch\n",
    "- transformers\n",
    "- transformers[torch]\n",
    "- evaluate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    default_data_collator,\n",
    "    get_scheduler,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    BertConfig\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "\n",
    "import evaluate\n",
    "import collections\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import os\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set cache directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TRANSFORMERS_CACHE=/mount/arbeitsdaten31/studenten1/linku/cache\n",
      "env: HF_MODULES_CACHE=/mount/arbeitsdaten31/studenten1/linku/cache\n",
      "env: HF_DATASETS_CACHE=/mount/arbeitsdaten31/studenten1/linku/cache\n"
     ]
    }
   ],
   "source": [
    "CACHE_DIR='/mount/arbeitsdaten31/studenten1/linku/cache'\n",
    "%set_env TRANSFORMERS_CACHE $CACHE_DIR\n",
    "%set_env HF_MODULES_CACHE $CACHE_DIR\n",
    "%set_env HF_DATASETS_CACHE $CACHE_DIR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arguments.py\n",
    "\n",
    "args_input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_input_ALstrategy = 'KMeansSampling'\n",
    "args_input_initseed = 100 # 1000\n",
    "args_input_quota = 100 # 1000\n",
    "args_input_batch = 35 # 128\n",
    "args_input_dataset_name = 'SQuAD'\n",
    "args_input_iteration = 1\n",
    "args_input_model_batch = 8 # already add in arguments.py\n",
    "args_input_max_length = 384\n",
    "\n",
    "stride = 128"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = args_input_max_length\n",
    "NUM_QUERY = args_input_batch\n",
    "NUM_INIT_LB = args_input_initseed\n",
    "NUM_ROUND = int(args_input_quota / args_input_batch)\n",
    "DATA_NAME = args_input_dataset_name\n",
    "STRATEGY_NAME = args_input_ALstrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/mount/arbeitsdaten31/studenten1/linku/models'\n",
    "pretrain_model_dir = model_dir + '/' + 'SQuAD_100_Bert'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad (/home/users1/linku/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c12f37b663342b6ac4059d13b3b6d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "squad = load_dataset(args_input_dataset_name.lower())\n",
    "# squad[\"train\"] = squad[\"train\"].shuffle(42).select(range(2000))\n",
    "squad[\"train\"] = squad[\"train\"].select(range(4000))\n",
    "squad[\"validation\"] = squad[\"validation\"].select(range(1500))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will preprocess the dataset (training and evaluation data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_training_features(examples):\n",
    "    # keep [\"offset_mapping\"], for compute_metrics()\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs[\"offset_mapping\"]\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    example_ids = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        \n",
    "        example_ids.append(examples[\"id\"][sample_idx]) # newly added for used in unlabel data predict\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label is (0, 0)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_training_examples(examples):\n",
    "    # no ['offset_mapping'], for .train() and .eval()\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    example_ids = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        \n",
    "        example_ids.append(examples[\"id\"][sample_idx]) # newly added for used in unlabel data predict\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label is (0, 0)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_validation_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "548e6134e4a94a0fafeeab022bfa6c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da97954a99db421dbe71171abfe08a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc23d6809c3448b59e7268ca06bb9c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/users1/linku/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453/cache-9456706e0dd13065.arrow\n"
     ]
    }
   ],
   "source": [
    "# load tokenizer for dataset preprocessing\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# preprocess data\n",
    "train_dataset = squad[\"train\"].map(\n",
    "    preprocess_training_examples,\n",
    "    batched=True,\n",
    "    remove_columns=squad[\"train\"].column_names,\n",
    ")\n",
    "train_features = squad[\"train\"].map(\n",
    "    preprocess_training_features,\n",
    "    batched=True,\n",
    "    remove_columns=squad[\"train\"].column_names,\n",
    ")\n",
    "val_dataset = squad[\"validation\"].map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=squad[\"validation\"].column_names,\n",
    ")\n",
    "val_features = squad[\"validation\"].map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=squad[\"validation\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(\"torch\")\n",
    "train_features.set_format(\"torch\")\n",
    "val_dataset = val_dataset.remove_columns([\"offset_mapping\"])\n",
    "val_dataset.set_format(\"torch\")\n",
    "val_features.set_format(\"torch\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_train(num_train_epochs, train_dataloader, device, model, optimizer, lr_scheduler, record_loss=False):\n",
    "\tprint('Num of train dataset:', len(train_dataloader.dataset))\n",
    "\tfor epoch in range(num_train_epochs):\n",
    "\t\tmodel.train()\n",
    "\t\tfor step, batch in enumerate(tqdm(train_dataloader, desc=\"Training\")):\n",
    "\t\t\tbatch = {key: value.to(device) for key, value in batch.items()}\n",
    "\t\t\toutputs = model(**batch)\n",
    "\t\t\tloss = outputs.loss\n",
    "\t\t\tloss.backward()\n",
    "\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\tlr_scheduler.step()\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\tif record_loss:\n",
    "\t\t\tprint('Train Epoch: {}\\tLoss: {:.6f}'.format(epoch, loss.item()))\n",
    "\n",
    "\tmodel_to_save = model.module if hasattr(model, 'module') else model \n",
    "\tmodel_to_save.save_pretrained(model_dir)\n",
    "\tprint('TRAIN done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(start_logits, end_logits, features, examples):\n",
    "    \n",
    "    example_to_features = collections.defaultdict(list)\n",
    "    max_answer_length = 30\n",
    "    n_best = 20\n",
    "    for idx, feature in enumerate(features):\n",
    "        example_to_features[feature[\"example_id\"]].append(idx)\n",
    "\n",
    "    predicted_answers = []\n",
    "    for example in tqdm(examples, desc=\"Computing metrics\"):\n",
    "        example_id = example[\"id\"]\n",
    "        context = example[\"context\"]\n",
    "        answers = []\n",
    "\n",
    "        # Loop through all features associated with that example\n",
    "        for feature_index in example_to_features[example_id]:\n",
    "            start_logit = start_logits[feature_index]\n",
    "            end_logit = end_logits[feature_index]\n",
    "            offsets = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Skip answers that are not fully in the context\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                        continue\n",
    "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                    if (\n",
    "                        end_index < start_index\n",
    "                        or end_index - start_index + 1 > max_answer_length\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    answer = {\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "\n",
    "        # Select the answer with the best score\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            predicted_answers.append(\n",
    "                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n",
    "            )\n",
    "        else:\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
    "\n",
    "    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n",
    "    return metric.compute(predictions=predicted_answers, references=theoretical_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(eval_dataloader, device, features, examples, record_loss=False, rd_0=False):\n",
    "    if rd_0:\n",
    "        config = BertConfig.from_pretrained(pretrain_model_dir, output_hidden_states=True)\n",
    "    else:\n",
    "        config = BertConfig.from_pretrained(model_dir, output_hidden_states=True)\n",
    "    model = AutoModelForQuestionAnswering.from_config(config).to(device)\n",
    "    \n",
    "    test_loss = []\n",
    "    model.eval()\n",
    "    start_logits = []\n",
    "    end_logits = []\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating_pred\"):\n",
    "        batch = {key: value.to(device) for key, value in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            print(outputs)\n",
    "            print(outputs.loss)\n",
    "            test_loss.append(outputs.loss)\n",
    "\n",
    "        start_logits.append(outputs.start_logits.cpu().numpy())\n",
    "        end_logits.append(outputs.end_logits.cpu().numpy())\n",
    "\n",
    "    start_logits = np.concatenate(start_logits)\n",
    "    end_logits = np.concatenate(end_logits)\n",
    "    start_logits = start_logits[: len(features)]\n",
    "    end_logits = end_logits[: len(features)]\n",
    "\n",
    "    if record_loss:\n",
    "        test_loss /= len(eval_dataloader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}\\n'.format(test_loss))\n",
    "\n",
    "    return compute_metrics(start_logits, end_logits, features, examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(eval_dataloader, device, features, examples):\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(model_dir).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    start_logits = []\n",
    "    end_logits = []\n",
    "\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating_prob\"):\n",
    "        batch = {key: value.to(device) for key, value in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        start_logits.append(outputs.start_logits.cpu().numpy())\n",
    "        end_logits.append(outputs.end_logits.cpu().numpy())\n",
    "\n",
    "    start_logits = np.concatenate(start_logits)\n",
    "    end_logits = np.concatenate(end_logits)\n",
    "    start_logits = start_logits[: len(features)]\n",
    "    end_logits = end_logits[: len(features)]\n",
    "\n",
    "    prob_dict = {}\n",
    "    example_to_features = collections.defaultdict(list)\n",
    "    max_answer_length = 30\n",
    "    n_best = 20 # TODO: if set n_best as 5, will it effect the time??\n",
    "    \n",
    "    for idx, feature in enumerate(features):\n",
    "        example_to_features[feature[\"example_id\"]].append(idx)\n",
    "\n",
    "    for example in tqdm(examples, desc=\"Computing metrics\"):\n",
    "        example_id = example[\"id\"]\n",
    "        # context = example[\"context\"]\n",
    "        answers = []\n",
    "\n",
    "        # Loop through all features associated with that example\n",
    "        for feature_index in example_to_features[example_id]:\n",
    "            start_logit = start_logits[feature_index]\n",
    "            end_logit = end_logits[feature_index]\n",
    "            offsets = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Skip answers that are not fully in the context\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                        continue\n",
    "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                    if (\n",
    "                        end_index < start_index\n",
    "                        or end_index - start_index + 1 > max_answer_length\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    answers.append(start_logit[start_index] + end_logit[end_index])\n",
    "        \n",
    "            if len(answers) > 1:\n",
    "                prob_dict[feature_index] = softmax(answers)\n",
    "            elif example_to_features[example_id] != []:\n",
    "                prob_dict[feature_index] = np.array([0])\n",
    "    \n",
    "    return prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_dropout(eval_dataloader, device, features, examples, n_drop=10):\n",
    "    # deepAL+: self.clf.train()\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(model_dir).to(device)\n",
    "    model.train()\n",
    "    # deepAL+: probs = torch.zeros([len(data), len(np.unique(data.Y))])\n",
    "    # deepAL+: loader = DataLoader(data, shuffle=False, **self.params['loader_te_args'])\n",
    "    prob_dict = {}\n",
    "    # deepAL+: for i in range(n_drop):\n",
    "    # deepAL+:     with torch.no_grad():\n",
    "    # deepAL+:         for x, y, idxs in loader:\n",
    "    # deepAL+:             x, y = x.to(self.device), y.to(self.device)\n",
    "    # deepAL+:             out, e1 = self.clf(x)\n",
    "    # deepAL+:             prob = F.softmax(out, dim=1)\n",
    "    # deepAL+:             probs[idxs] += prob.cpu()\n",
    "    for i in range(n_drop):\n",
    "        start_logits = []\n",
    "        end_logits = []\n",
    "        for batch in tqdm(eval_dataloader, desc=\"Evaluating_prob_dropout\"):\n",
    "            batch = {key: value.to(device) for key, value in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "\n",
    "            start_logits.append(outputs.start_logits.cpu().numpy())\n",
    "            end_logits.append(outputs.end_logits.cpu().numpy())\n",
    "\n",
    "        start_logits = np.concatenate(start_logits)\n",
    "        end_logits = np.concatenate(end_logits)\n",
    "        start_logits = start_logits[: len(features)]\n",
    "        end_logits = end_logits[: len(features)]\n",
    "\n",
    "        example_to_features = collections.defaultdict(list)\n",
    "        max_answer_length = 30\n",
    "        n_best = 20\n",
    "            \n",
    "        for idx, feature in enumerate(features):\n",
    "            example_to_features[feature[\"example_id\"]].append(idx)\n",
    "\n",
    "        n = 0\n",
    "        for example in tqdm(examples):\n",
    "            example_id = example[\"id\"]\n",
    "            answers = []\n",
    "\n",
    "            # Loop through all features associated with that example\n",
    "            for feature_index in example_to_features[example_id]:\n",
    "                start_logit = start_logits[feature_index]\n",
    "                end_logit = end_logits[feature_index]\n",
    "                offsets = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "                start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "                end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "                for start_index in start_indexes:\n",
    "                    for end_index in end_indexes:\n",
    "                        # Skip answers that are not fully in the context\n",
    "                        if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                            continue\n",
    "                        # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                        if (\n",
    "                            end_index < start_index\n",
    "                            or end_index - start_index + 1 > max_answer_length\n",
    "                        ):\n",
    "                            continue\n",
    "\n",
    "                        answers.append(start_logit[start_index] + end_logit[end_index])\n",
    "\n",
    "            if 1 < len(answers) < 200: # pad to same numbers of possible answers\n",
    "                zero_list = [0] * (200 - len(answers))\n",
    "                answers.extend(zero_list)\n",
    "            elif len(answers) >= 200:\n",
    "                answers = answers[:200]\n",
    "\n",
    "            if len(answers) > 1:\n",
    "                if feature_index not in prob_dict:\n",
    "                    prob_dict[feature_index] = softmax(answers)\n",
    "                else:\n",
    "                    prob_dict[feature_index] += softmax(answers)\n",
    "            elif example_to_features[example_id] != []:\n",
    "                if feature_index not in prob_dict:\n",
    "                    prob_dict[feature_index] = np.array([0])   \n",
    "\n",
    "    for key in prob_dict.keys():\n",
    "        prob_dict[key] /= n_drop\n",
    "\n",
    "    return prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_dropout_split(eval_dataloader, device, features, examples, n_drop=10):\n",
    "    ## use tensor to save the answers\n",
    "    \n",
    "    # deepAL+: self.clf.train()\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(model_dir).to(device)\n",
    "    model.train()\n",
    "    # deepAL+: probs = torch.zeros([len(data), len(np.unique(data.Y))])\n",
    "    # deepAL+: loader = DataLoader(data, shuffle=False, **self.params['loader_te_args'])\n",
    "    probs = torch.zeros([n_drop, len(eval_dataloader.dataset), 200])\n",
    "    for_check = []\n",
    "    # deepAL+: for i in range(n_drop):\n",
    "    # deepAL+:     with torch.no_grad():\n",
    "    # deepAL+:         for x, y, idxs in loader:\n",
    "    # deepAL+:             x, y = x.to(self.device), y.to(self.device)\n",
    "    # deepAL+:             out, e1 = self.clf(x)\n",
    "    # deepAL+:             prob = F.softmax(out, dim=1)\n",
    "    # deepAL+:             probs[i][idxs] += F.softmax(out, dim=1).cpu()\n",
    "    for i in range(n_drop):\n",
    "        prob_dict = {}\n",
    "        start_logits = []\n",
    "        end_logits = []\n",
    "        for batch in tqdm(eval_dataloader, desc=\"Evaluating_prob_dropout\"):\n",
    "            batch = {key: value.to(device) for key, value in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "\n",
    "            start_logits.append(outputs.start_logits.cpu().numpy())\n",
    "            end_logits.append(outputs.end_logits.cpu().numpy())\n",
    "\n",
    "        start_logits = np.concatenate(start_logits)\n",
    "        end_logits = np.concatenate(end_logits)\n",
    "        start_logits = start_logits[: len(features)]\n",
    "        end_logits = end_logits[: len(features)]\n",
    "\n",
    "        example_to_features = collections.defaultdict(list)\n",
    "        max_answer_length = 30\n",
    "        n_best = 20\n",
    "            \n",
    "        for idx, feature in enumerate(features):\n",
    "            example_to_features[feature[\"example_id\"]].append(idx)\n",
    "\n",
    "        n = 0\n",
    "        for example in tqdm(examples, desc=\"Computing metrics\"):\n",
    "            example_id = example[\"id\"]\n",
    "            # context = example[\"context\"]\n",
    "            answers = []\n",
    "\n",
    "            # Loop through all features associated with that example\n",
    "            for feature_index in example_to_features[example_id]:\n",
    "                start_logit = start_logits[feature_index]\n",
    "                end_logit = end_logits[feature_index]\n",
    "                offsets = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "                start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "                end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "                for start_index in start_indexes:\n",
    "                    for end_index in end_indexes:\n",
    "                        # Skip answers that are not fully in the context\n",
    "                        if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                            continue\n",
    "                        # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                        if (\n",
    "                            end_index < start_index\n",
    "                            or end_index - start_index + 1 > max_answer_length\n",
    "                        ):\n",
    "                            continue\n",
    "\n",
    "                        answers.append(start_logit[start_index] + end_logit[end_index])\n",
    "\n",
    "            \n",
    "                if 1 < len(answers) < 200: # pad to same numbers of possible answers\n",
    "                    zero_list = [0] * (200 - len(answers))\n",
    "                    answers.extend(zero_list)\n",
    "                elif len(answers) >= 200:\n",
    "                    answers = answers[:200]\n",
    "\n",
    "                probs[i][feature_index] += torch.tensor(softmax(answers))\n",
    "\n",
    "            # if n == 0 and len(softmax(answers)) > 1:\n",
    "            #     for_check.append(answers[:5])\n",
    "            #     n += 1 \n",
    "\n",
    "    # return prob_dict, for_check\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(eval_dataloader, device, features, examples, rd):\n",
    "    if rd == 1:\n",
    "        config = BertConfig.from_pretrained(pretrain_model_dir, output_hidden_states=True)\n",
    "    else: \n",
    "        config = BertConfig.from_pretrained(model_dir, output_hidden_states=True)\n",
    "    model = AutoModelForQuestionAnswering.from_config(config).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    embeddings = torch.zeros([len(eval_dataloader.dataset), model.config.to_dict()['hidden_size']])\n",
    "    idxs_start = 0\n",
    "\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating_prob\"):\n",
    "        batch = {key: value.to(device) for key, value in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            # print('len_output:', len(outputs)) # 4\n",
    "            # print('outputs:', outputs) # (loss, start_logits, end_logits, hidden_states)\n",
    "\n",
    "        hidden_states = outputs.hidden_states\n",
    "        # print('len_hidden_states:', len(hidden_states)) # 13 # each one has: (batch_size, sequence_length, hidden_size)\n",
    "        # # hidden_states[0] -> last hidden states\n",
    "        # print('len_hidden_states[0]:', len(hidden_states[0])) # 8, 8, 4\n",
    "        # print('len_hidden_states[0][0]:', len(hidden_states[0][0])) # 384, 384, 384 # tokens in each sequence\n",
    "        # print('len_hidden_states[0][0][0]:', len(hidden_states[0][0][0])) # 768, 768, 768 # number of hidden units\n",
    "        # print('hidden_states:', hidden_states) \n",
    "\n",
    "        # TODO: Question!!!!! \n",
    "        embedding_of_last_layer = hidden_states[-1][:, 0, :] # [:, 0, :] -> to get [cls], but all the same\n",
    "        print(embedding_of_last_layer)\n",
    "        idxs_end = idxs_start + len(hidden_states[-1])\n",
    "        # print(idxs_start)\n",
    "        # print(idxs_end)\n",
    "        embeddings[idxs_start:idxs_end] = embedding_of_last_layer.cpu()\n",
    "        idxs_start = idxs_end\n",
    "        \n",
    "    return embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9353af2465754390aa5f6ff2f33f0137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating_prob:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3821, -0.2329, -0.7528,  ...,  0.3398,  0.3708, -0.3504],\n",
      "        [ 0.3757, -0.2713, -0.7949,  ...,  0.3613,  0.3396, -0.3583],\n",
      "        [ 0.2734, -0.4379, -0.8023,  ...,  0.3172,  0.3971, -0.3816],\n",
      "        ...,\n",
      "        [ 0.3346, -0.3376, -0.9554,  ...,  0.3716,  0.3823, -0.4001],\n",
      "        [ 0.3462, -0.1903, -0.8239,  ...,  0.3848,  0.4839, -0.4290],\n",
      "        [ 0.3775, -0.2474, -0.7431,  ...,  0.3860,  0.3522, -0.3633]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.2751, -0.2796, -0.7901,  ...,  0.4045,  0.4772, -0.2615],\n",
      "        [ 0.3696, -0.2389, -0.8716,  ...,  0.4472,  0.4582, -0.4561],\n",
      "        [ 0.3333, -0.1796, -0.8043,  ...,  0.2796,  0.3625, -0.3216],\n",
      "        ...,\n",
      "        [ 0.3022, -0.2155, -0.8702,  ...,  0.2496,  0.4065, -0.3365],\n",
      "        [ 0.2407, -0.1008, -0.9183,  ...,  0.3682,  0.5604, -0.2810],\n",
      "        [ 0.3983, -0.4316, -0.7011,  ...,  0.5084,  0.3698, -0.3399]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.2109, -0.2321, -0.9000,  ...,  0.3921,  0.5575, -0.2895],\n",
      "        [ 0.3232, -0.3161, -0.9249,  ...,  0.3819,  0.3963, -0.3836],\n",
      "        [ 0.2600, -0.2331, -0.8252,  ...,  0.3611,  0.4996, -0.2758],\n",
      "        ...,\n",
      "        [ 0.3559, -0.3967, -0.8049,  ...,  0.3309,  0.4544, -0.3747],\n",
      "        [ 0.3069, -0.1839, -0.7975,  ...,  0.2464,  0.3680, -0.3239],\n",
      "        [ 0.3561, -0.1897, -0.8532,  ...,  0.4581,  0.4689, -0.3997]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.2464, -0.3592, -0.8853,  ...,  0.5037,  0.3991, -0.4459],\n",
      "        [ 0.2501, -0.2765, -0.7118,  ...,  0.4031,  0.3878, -0.4112],\n",
      "        [ 0.3571, -0.2682, -0.7344,  ...,  0.3236,  0.4902, -0.3224],\n",
      "        ...,\n",
      "        [ 0.2938, -0.2488, -0.7087,  ...,  0.3449,  0.3327, -0.2896],\n",
      "        [ 0.3615, -0.3322, -0.7302,  ...,  0.2853,  0.4614, -0.3413],\n",
      "        [ 0.2861, -0.2984, -0.7052,  ...,  0.4301,  0.3952, -0.3994]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.3392, -0.3032, -0.7624,  ...,  0.2690,  0.4784, -0.3893],\n",
      "        [ 0.3503, -0.2855, -0.7060,  ...,  0.3492,  0.3468, -0.3783],\n",
      "        [ 0.2909, -0.2757, -0.6899,  ...,  0.3481,  0.3299, -0.2819],\n",
      "        ...,\n",
      "        [ 0.2644, -0.2715, -0.7074,  ...,  0.4109,  0.4024, -0.4164],\n",
      "        [ 0.2625, -0.2945, -0.7946,  ...,  0.3959,  0.4827, -0.2984],\n",
      "        [ 0.3665, -0.4001, -0.8569,  ...,  0.3303,  0.4713, -0.3787]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.2713, -0.3597, -0.7890,  ...,  0.3713,  0.3711, -0.4189],\n",
      "        [ 0.3460, -0.2395, -0.8019,  ...,  0.3570,  0.3684, -0.3572],\n",
      "        [ 0.2616, -0.4143, -0.7926,  ...,  0.3323,  0.3958, -0.3770],\n",
      "        ...,\n",
      "        [ 0.3164, -0.2970, -0.7733,  ...,  0.3111,  0.5181, -0.3374],\n",
      "        [ 0.3137, -0.2820, -0.6936,  ...,  0.3397,  0.3527, -0.3374],\n",
      "        [ 0.2368, -0.2794, -0.7061,  ...,  0.3275,  0.3939, -0.3792]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.3149, -0.1776, -0.9116,  ...,  0.4095,  0.5456, -0.4109],\n",
      "        [ 0.3505, -0.3279, -0.9401,  ...,  0.3851,  0.3633, -0.4022],\n",
      "        [ 0.3836, -0.4274, -0.7031,  ...,  0.5098,  0.4152, -0.3494],\n",
      "        ...,\n",
      "        [ 0.3654, -0.2413, -0.8720,  ...,  0.4239,  0.3595, -0.4039],\n",
      "        [ 0.3237, -0.2108, -0.7159,  ...,  0.3083,  0.4441, -0.4171],\n",
      "        [ 0.3780, -0.4435, -0.7350,  ...,  0.5221,  0.3638, -0.3598]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.3588, -0.4183, -0.8006,  ...,  0.3268,  0.4701, -0.3565],\n",
      "        [ 0.3040, -0.1883, -0.9784,  ...,  0.4680,  0.5065, -0.4081],\n",
      "        [ 0.3741, -0.3786, -0.7901,  ...,  0.3634,  0.4352, -0.3524],\n",
      "        ...,\n",
      "        [ 0.3206, -0.3599, -0.7080,  ...,  0.4177,  0.3537, -0.4146],\n",
      "        [ 0.2977, -0.1458, -0.7993,  ...,  0.4366,  0.4173, -0.4243],\n",
      "        [ 0.3726, -0.2259, -0.8060,  ...,  0.4977,  0.4582, -0.4154]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.2443, -0.2911, -0.7177,  ...,  0.3445,  0.3679, -0.3708],\n",
      "        [ 0.2371, -0.2684, -0.6965,  ...,  0.3183,  0.3967, -0.3803],\n",
      "        [ 0.3780, -0.4626, -0.7086,  ...,  0.5328,  0.3708, -0.3536],\n",
      "        ...,\n",
      "        [ 0.3355, -0.2739, -0.6913,  ...,  0.3527,  0.3534, -0.3904],\n",
      "        [ 0.2768, -0.3730, -0.7613,  ...,  0.4207,  0.3840, -0.4250],\n",
      "        [ 0.3070, -0.3971, -0.7240,  ...,  0.3988,  0.3087, -0.4515]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.2971, -0.3087, -0.7272,  ...,  0.4544,  0.3261, -0.4221],\n",
      "        [ 0.2807, -0.4295, -0.7878,  ...,  0.3241,  0.3789, -0.3382],\n",
      "        [ 0.3070, -0.4090, -0.7220,  ...,  0.4033,  0.3212, -0.4540],\n",
      "        ...,\n",
      "        [ 0.3360, -0.2426, -0.7165,  ...,  0.3538,  0.3624, -0.3749],\n",
      "        [ 0.3929, -0.1583, -0.8890,  ...,  0.3808,  0.4763, -0.3711],\n",
      "        [ 0.1809, -0.2130, -0.8815,  ...,  0.3390,  0.5101, -0.2872]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.3380, -0.2285, -0.8279,  ...,  0.4872,  0.4972, -0.4523],\n",
      "        [ 0.3507, -0.2520, -0.8623,  ...,  0.5076,  0.4074, -0.4408],\n",
      "        [ 0.3188, -0.2608, -0.9671,  ...,  0.4794,  0.4918, -0.4032],\n",
      "        ...,\n",
      "        [ 0.3045, -0.3245, -0.7466,  ...,  0.4058,  0.4214, -0.4170],\n",
      "        [ 0.2837, -0.3592, -0.7872,  ...,  0.4711,  0.3768, -0.4078],\n",
      "        [ 0.2739, -0.3739, -0.8122,  ...,  0.4785,  0.3572, -0.4208]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.2759, -0.1705, -0.8097,  ...,  0.2630,  0.4322, -0.3236],\n",
      "        [ 0.2204, -0.3403, -0.8432,  ...,  0.4970,  0.3958, -0.4377],\n",
      "        [ 0.3080, -0.3634, -0.7057,  ...,  0.4416,  0.3176, -0.3724],\n",
      "        ...,\n",
      "        [ 0.3292, -0.3167, -0.7310,  ...,  0.3450,  0.3559, -0.3235],\n",
      "        [ 0.3037, -0.4425, -0.8120,  ...,  0.3473,  0.3826, -0.3354],\n",
      "        [ 0.3161, -0.3124, -0.7100,  ...,  0.3468,  0.3163, -0.3064]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.2846, -0.0950, -0.8544,  ...,  0.3988,  0.4189, -0.4227],\n",
      "        [ 0.2378, -0.3539, -0.8354,  ...,  0.4863,  0.3863, -0.4181],\n",
      "        [ 0.2996, -0.2859, -0.7104,  ...,  0.4177,  0.4020, -0.4070],\n",
      "        [ 0.3864, -0.2662, -0.7709,  ...,  0.3542,  0.3510, -0.3849]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "embeddings = get_embeddings(unlabeled_dataloader, device, unlabeled_feature_20, squad['train'], rd=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unlabel_data(n_pool, labeled_idxs, train_dataset):\n",
    "    unlabeled_idxs = np.arange(n_pool)[~labeled_idxs]\n",
    "    unlabeled_data = train_dataset.select(indices=unlabeled_idxs)\n",
    "    return unlabeled_idxs, unlabeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x): \n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling_query(labeled_idxs, n, rd):\n",
    "    return np.random.choice(np.where(labeled_idxs==0)[0], n, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_sampling_query(n_pool, labeled_idxs, train_dataset, train_features, examples, model, device, n, rd):\n",
    "    # deepAL+: unlabeled_idxs, unlabeled_data = self.dataset.get_unlabeled_data()\n",
    "    unlabeled_idxs, unlabeled_data = get_unlabel_data(n_pool, labeled_idxs, train_dataset)\n",
    "    unlabeled_features = train_features.select(unlabeled_idxs)\n",
    "    unlabeled_dataloader = DataLoader(\n",
    "\t\tunlabeled_data,\n",
    "\t\tshuffle=True,\n",
    "\t\tcollate_fn=default_data_collator,\n",
    "\t\tbatch_size=8,\n",
    "\t)\n",
    "    # TODO: print for recording\n",
    "    print('Margin querying starts!')\n",
    "    # deepAL+: probs = self.predict_prob(unlabeled_data)\n",
    "    prob_dict = get_prob(unlabeled_dataloader, device, unlabeled_features, examples)\n",
    "    # TODO: print for recording\n",
    "    print('Got probability!')\n",
    "    # deepAL+: probs_sorted, _ = probs.sort(descending=True)\n",
    "    # deepAL+: uncertainties = probs_sorted[:, 0] - probs_sorted[:,1]\n",
    "    uncertainties_dict = {}\n",
    "    for idx, probs in prob_dict.items():\n",
    "        if len(probs) > 1: # if prob_dict['probs'] is not 0\n",
    "            sort_probs = np.sort(probs)[::-1] # This method returns a copy of the array, leaving the original array unchanged.\n",
    "            uncertainties_dict[idx] = sort_probs[0] - sort_probs[1]\n",
    "        elif idx:\n",
    "            uncertainties_dict[idx] = np.array([0])\n",
    "\n",
    "    # deepAL+: return unlabeled_idxs[uncertainties.sort()[1][:n]] \n",
    "    sorted_uncertainties_list = sorted(uncertainties_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return unlabeled_idxs[[idx for (idx, uncertainties) in sorted_uncertainties_list[:n]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_confidence_query(n_pool, labeled_idxs, train_dataset, train_features, examples, device, n, rd):\n",
    "    # deepAL+: unlabeled_idxs, unlabeled_data = self.dataset.get_unlabeled_data()\n",
    "    unlabeled_idxs, unlabeled_data = get_unlabel_data(n_pool, labeled_idxs, train_dataset)\n",
    "    unlabeled_features = train_features.select(unlabeled_idxs)\n",
    "    unlabeled_dataloader = DataLoader(\n",
    "\t\tunlabeled_data,\n",
    "\t\tshuffle=True,\n",
    "\t\tcollate_fn=default_data_collator,\n",
    "\t\tbatch_size=8,\n",
    "\t)\n",
    "    # TODO: print for recording\n",
    "    print('LC querying starts!')\n",
    "    # deepAL+: probs = self.predict_prob(unlabeled_data)\n",
    "    prob_dict = get_prob(unlabeled_dataloader, device, unlabeled_features, examples)\n",
    "    # TODO: print for recording\n",
    "    print('Got probability!')\n",
    "    # deepAL+: uncertainties = probs.max(1)[0]\n",
    "    confidence_dict = {}\n",
    "    for idx, probs in prob_dict.items():\n",
    "        if len(probs) > 1: # if prob_dict['probs'] is not 0\n",
    "            confidence_dict[idx] = max(probs)\n",
    "        elif idx:\n",
    "            confidence_dict[idx] = np.array([0])\n",
    "\n",
    "    # deepAL+: return unlabeled_idxs[uncertainties.sort()[1][:n]]\n",
    "    sorted_confidence_list = sorted(confidence_dict.items, key=lambda x: x[1])\n",
    "    return unlabeled_idxs[[idx for (idx, confidence) in sorted_confidence_list[:n]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_ratio_query(n_pool, labeled_idxs, train_dataset, train_features, examples, device, n, rd):\n",
    "    # deepAL+: unlabeled_idxs, unlabeled_data = self.dataset.get_unlabeled_data()\n",
    "    unlabeled_idxs, unlabeled_data = get_unlabel_data(n_pool, labeled_idxs, train_dataset)\n",
    "    unlabeled_features = train_features.select(unlabeled_idxs)\n",
    "    unlabeled_dataloader = DataLoader(\n",
    "\t\tunlabeled_data,\n",
    "\t\tshuffle=True,\n",
    "\t\tcollate_fn=default_data_collator,\n",
    "\t\tbatch_size=8,\n",
    "\t)\n",
    "    # TODO: print for recording\n",
    "    print('Var Ratio querying starts!')\n",
    "    # deepAL+: probs = self.predict_prob(unlabeled_data)\n",
    "    prob_dict = get_prob(unlabeled_dataloader, device, unlabeled_features, examples)\n",
    "    # TODO: print for recording\n",
    "    print('Got probability!')\n",
    "    # deepAL+: preds = torch.max(probs, 1)[0]\n",
    "    # deepAL+: uncertainties = 1.0 - preds\n",
    "    confidence_dict = {}\n",
    "    for idx, probs in prob_dict.items():\n",
    "        if len(probs) > 1: # if prob_dict['probs'] is not 0\n",
    "            confidence_dict[idx] = 1.0 - max(probs)\n",
    "        elif idx:\n",
    "            confidence_dict[idx] = np.array([0])\n",
    "\n",
    "    # deepAL+: return unlabeled_idxs[uncertainties.sort(descending=True)[1][:n]]\n",
    "    sorted_confidence_list = sorted(confidence_dict.items, key=lambda x: x[1], reverse=True)\n",
    "    return unlabeled_idxs[[idx for (idx, confidence) in sorted_confidence_list[:n]]]\n",
    "# comment for the same query as LC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_query(n_pool, labeled_idxs, train_dataset, train_features, examples, device, n, rd):\n",
    "    # deepAL+: unlabeled_idxs, unlabeled_data = self.dataset.get_unlabeled_data()\n",
    "    unlabeled_idxs, unlabeled_data = get_unlabel_data(n_pool, labeled_idxs, train_dataset)\n",
    "    unlabeled_features = train_features.select(unlabeled_idxs)\n",
    "    unlabeled_dataloader = DataLoader(\n",
    "\t\tunlabeled_data,\n",
    "\t\tshuffle=True,\n",
    "\t\tcollate_fn=default_data_collator,\n",
    "\t\tbatch_size=8,\n",
    "\t)\n",
    "    # deepAL+: probs = self.predict_prob(unlabeled_data)\n",
    "    # TODO: print for recording\n",
    "    print('Entropy querying starts!')\n",
    "    prob_dict = get_prob(unlabeled_dataloader, device, unlabeled_features, examples)\n",
    "    # TODO: print for recording\n",
    "    print('Got probability!')\n",
    "    # deepAL+: log_probs = torch.log(probs)\n",
    "    # deepAL+: uncertainties = (probs*log_probs).sum(1)\n",
    "    entropy_dict = {}\n",
    "    for idx, probs in prob_dict.items():\n",
    "        if len(probs) > 1: # if prob_dict['probs'] is not 0\n",
    "            log_probs = np.log(probs)\n",
    "            entropy_dict[idx] = (probs*log_probs).sum()\n",
    "        elif idx:\n",
    "            entropy_dict[idx] = np.array([0])\n",
    "    # deepAL+: return unlabeled_idxs[uncertainties.sort()[1][:n]]\n",
    "    sorted_entropy_list = sorted(entropy_dict.items(), key=lambda x: x[1])\n",
    "    return unlabeled_idxs[[idx for (idx, entropy) in sorted_entropy_list[:n]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_sampling_dropout_query(n_pool, labeled_idxs, train_dataset, train_features, examples, device, n, rd):\n",
    "    unlabeled_idxs, unlabeled_data = get_unlabel_data(n_pool, labeled_idxs, train_dataset)\n",
    "    unlabeled_features = train_features.select(unlabeled_idxs)\n",
    "    unlabeled_dataloader = DataLoader(\n",
    "\t\tunlabeled_data,\n",
    "\t\tshuffle=True,\n",
    "\t\tcollate_fn=default_data_collator,\n",
    "\t\tbatch_size=8,\n",
    "\t)\n",
    "    # TODO: print for recording\n",
    "    print('Margin dropout querying starts!')\n",
    "    prob_dict = get_prob_dropout(unlabeled_dataloader, device, unlabeled_features, examples)\n",
    "    # TODO: print for recording\n",
    "    print('Got probability!')\n",
    "    uncertainties_dict = {}\n",
    "    for idx, probs in prob_dict.items():\n",
    "        if len(probs) > 1: # if prob_dict['probs'] is not 0\n",
    "            sort_probs = np.sort(probs)[::-1] # This method returns a copy of the array, leaving the original array unchanged.\n",
    "            uncertainties_dict[idx] = sort_probs[0] - sort_probs[1]\n",
    "        elif idx:\n",
    "            uncertainties_dict[idx] = np.array([0])\n",
    "\n",
    "    sorted_uncertainties_list = sorted(uncertainties_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    return unlabeled_idxs[[idx for (idx, uncertainties) in sorted_uncertainties_list[:n]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_query(n_pool, labeled_idxs, train_dataset, train_features, examples, device, n, rd):\n",
    "    # deepAL+: unlabeled_idxs, unlabeled_data = self.dataset.get_unlabeled_data()\n",
    "    unlabeled_idxs, unlabeled_data = get_unlabel_data(n_pool, labeled_idxs, train_dataset)\n",
    "    unlabeled_features = train_features.select(unlabeled_idxs)\n",
    "    unlabeled_dataloader = DataLoader(\n",
    "  \t\tunlabeled_data,\n",
    "      shuffle=True,\n",
    "      collate_fn=default_data_collator,\n",
    "      batch_size=8,\n",
    "    )\n",
    "    # TODO: print for recording\n",
    "    print('Mean STD querying starts!')\n",
    "    # deepAL+: probs = self.predict_prob_dropout_split(unlabeled_data, n_drop=self.n_drop).numpy()\n",
    "    probs = get_prob_dropout_split(unlabeled_dataloader, device, unlabeled_features, examples).numpy()\n",
    "    # TODO: print for recording\n",
    "    print('Got probability!')\n",
    "    # deepAL+: sigma_c = np.std(probs, axis=0)\n",
    "    sigma_c = np.std(probs, axis=0)\n",
    "    # deepAL+: uncertainties = torch.from_numpy(np.mean(sigma_c, axis=-1))\n",
    "    uncertainties = torch.from_numpy(np.mean(sigma_c, axis=-1)) # use tensor.sort() will sort the data and produce sorted indexes\n",
    "    # deepAL+: return unlabeled_idxs[uncertainties.sort(descending=True)[1][:n]] # [1]: to get sorted data's indexes\n",
    "    return unlabeled_idxs[uncertainties.sort(descending=True)[1][:n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_query(n_pool, labeled_idxs, train_dataset, train_features, examples, device, n, rd):\n",
    "    # deepAL+: unlabeled_idxs, unlabeled_data = self.dataset.get_unlabeled_data()\n",
    "    unlabeled_idxs, unlabeled_data = get_unlabel_data(n_pool, labeled_idxs, train_dataset)\n",
    "    unlabeled_features = train_features.select(unlabeled_idxs)\n",
    "    unlabeled_dataloader = DataLoader(\n",
    "      unlabeled_data,\n",
    "      shuffle=True,\n",
    "      collate_fn=default_data_collator,\n",
    "      batch_size=8,\n",
    "    )\n",
    "    # deepAL+: probs = self.predict_prob_dropout_split(unlabeled_data, n_drop=self.n_drop)\n",
    "    probs = get_prob_dropout_split(unlabeled_dataloader, device, unlabeled_features, examples)\n",
    "    # deepAL+: pb = probs.mean(0)\n",
    "    probs_mean = probs.mean(0)\n",
    "    # deepAL+: entropy1 = (-pb*torch.log(pb)).sum(1)\n",
    "    entropy1 = (-probs_mean*torch.log(probs_mean)).sum(1)\n",
    "    # deepAL+: entropy2 = (-probs*torch.log(probs)).sum(2).mean(0)\n",
    "    entropy2 = (-probs*torch.log(probs)).sum(2).mean(0)\n",
    "    # deepAL+: uncertainties = entropy2 - entropy1\n",
    "    uncertainties = entropy2 - entropy1\n",
    "    # later on, we can use batch\n",
    "    # deepAL+: return unlabeled_idxs[uncertainties.sort()[1][:n]]\n",
    "    return unlabeled_idxs[uncertainties.sort()[1][:n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_query(n_pool, labeled_idxs, train_dataset, train_features, examples, device, n, rd):\n",
    "    unlabeled_idxs, unlabeled_data = get_unlabel_data(n_pool, labeled_idxs, train_dataset)\n",
    "    unlabeled_features = train_features.select(unlabeled_idxs)\n",
    "    unlabeled_dataloader = DataLoader(\n",
    "      unlabeled_data,\n",
    "      shuffle=True,\n",
    "      collate_fn=default_data_collator,\n",
    "      batch_size=8,\n",
    "    )\n",
    "    # TODO: print for recording\n",
    "    print('BALD querying starts!')\n",
    "    probs = get_prob_dropout_split(unlabeled_dataloader, device, unlabeled_features, examples)\n",
    "    # TODO: print for recording\n",
    "    print('Got probability!')\n",
    "    probs_mean = probs.mean(0)\n",
    "    entropy1 = (-probs_mean*torch.log(probs_mean)).sum(1)\n",
    "    entropy2 = (-probs*torch.log(probs)).sum(2).mean(0)\n",
    "    uncertainties = entropy2 - entropy1\n",
    "    # later on, we can use batch\n",
    "    return unlabeled_idxs[uncertainties.sort()[1][:n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_query(n_pool, labeled_idxs, train_dataset, train_features, examples, device, n, rd):\n",
    "    unlabeled_idxs, unlabeled_data = get_unlabel_data(n_pool, labeled_idxs, train_dataset)\n",
    "    unlabeled_features = train_features.select(unlabeled_idxs)\n",
    "    unlabeled_dataloader = DataLoader(\n",
    "  \t\tunlabeled_data,\n",
    "      shuffle=True,\n",
    "      collate_fn=default_data_collator,\n",
    "      batch_size=8,\n",
    "    )\n",
    "    # TODO: print for recording\n",
    "    print('Mean STD querying starts!')\n",
    "    probs = get_prob_dropout_split(unlabeled_dataloader, device, unlabeled_features, examples).numpy()\n",
    "    # TODO: print for recording\n",
    "    print('Got probability!')\n",
    "    sigma_c = np.std(probs, axis=0)\n",
    "    uncertainties = torch.from_numpy(np.mean(sigma_c, axis=-1)) # use tensor.sort() will sort the data and produce sorted indexes\n",
    "    return unlabeled_idxs[uncertainties.sort(descending=True)[1][:n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_query(n_pool, labeled_idxs, train_dataset, train_features, examples, device, n, rd):\n",
    "    # deepAL+: unlabeled_idxs, unlabeled_data = self.dataset.get_unlabeled_data()\n",
    "    unlabeled_idxs, unlabeled_data = get_unlabel_data(n_pool, labeled_idxs, train_dataset)\n",
    "    unlabeled_features = train_features.select(unlabeled_idxs)\n",
    "    unlabeled_dataloader = DataLoader(\n",
    "      unlabeled_data,\n",
    "      shuffle=True,\n",
    "      collate_fn=default_data_collator,\n",
    "      batch_size=8,\n",
    "    )\n",
    "    # deepAL+: embeddings = get_embeddings(unlabeled_data)\n",
    "    embeddings = get_embeddings(unlabeled_dataloader, device, unlabeled_features, examples, rd=1)\n",
    "    # deepAL+: embeddings = embeddings.numpy()\n",
    "    embeddings = embeddings.numpy()\n",
    "    # print(embeddings.shape)\n",
    "    # deepAL+: cluster_learner = KMeans(n_clusters=n)\n",
    "    cluster_learner = KMeans(n_clusters=n)\n",
    "    # deepAL+: cluster_learner.fit(embeddings)\n",
    "    cluster_learner.fit(embeddings)\n",
    "    # deepAL+: cluster_idxs = cluster_learner.predict(embeddings)\n",
    "    cluster_idxs = cluster_learner.predict(embeddings)\n",
    "    # deepAL+: centers = cluster_learner.cluster_centers_[cluster_idxs]\n",
    "    centers = cluster_learner.cluster_centers_[cluster_idxs]\n",
    "    # deepAL+: dis = (embeddings - centers)**2\n",
    "    dis = (embeddings - centers)**2\n",
    "    # deepAL+: dis = dis.sum(axis=1)\n",
    "    dis = dis.sum(axis=1)\n",
    "    # deepAL+: q_idxs = np.array([np.arange(embeddings.shape[0])[cluster_idxs==i][dis[cluster_idxs==i].argmin()] for i in range(n)])\n",
    "    q_idxs = np.array([np.arange(embeddings.shape[0])[cluster_idxs==i][dis[cluster_idxs==i].argmin()] for i in range(n)])\n",
    "\n",
    "    # deepAL+: return unlabeled_idxs[q_idxs]\n",
    "    return unlabeled_idxs[q_idxs]\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seed and device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 4666\n",
    "# os.environ['TORCH_HOME']='./basicmodel'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(3)\n",
    "\n",
    "# fix random seed\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "# torch.backends.cudnn.enabled  = True\n",
    "# torch.backends.cudnn.benchmark= True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = args_input_iteration\n",
    "model_batch = args_input_model_batch\n",
    "num_train_epochs = 3\n",
    "\n",
    "all_acc = []\n",
    "acq_time = []\n",
    "\n",
    "# Change \"fp16_training\" to True to support automatic mixed precision training (fp16)\t\n",
    "fp16_training = False\n",
    "\n",
    "if fp16_training:\n",
    "    !pip install accelerate==0.2.0\n",
    "    from accelerate import Accelerator\n",
    "    accelerator = Accelerator(fp16=True)\n",
    "    device = accelerator.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQuAD\n",
      "KMeansSampling\n",
      "Round 0\n",
      "testing accuracy 13.8252\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# repeate # iteration trials\n",
    "while (iteration > 0): \n",
    "\titeration = iteration - 1\n",
    "\n",
    "\tstart = datetime.datetime.now()\n",
    "\n",
    "\t## generate initial labeled pool\n",
    "\tn_pool = len(train_dataset)\n",
    "\tlabeled_idxs = np.zeros(n_pool, dtype=bool)\n",
    "\n",
    "\ttmp_idxs = np.arange(n_pool)\n",
    "\tnp.random.shuffle(tmp_idxs)\n",
    "\tlabeled_idxs[tmp_idxs[:NUM_INIT_LB]] = True\n",
    "\n",
    "\trun_0_labeled_idxs = np.arange(n_pool)[labeled_idxs]\n",
    "\n",
    "\t## record acc performance \n",
    "\tacc = np.zeros(NUM_ROUND + 1) # quota/batch runs + run_0\n",
    "\n",
    "\t## data\n",
    "\t# eval_dataloader = DataLoader(\n",
    "\t# \tval_dataset, \n",
    "\t# \tcollate_fn=default_data_collator, \n",
    "\t# \tbatch_size=8\n",
    "\t# )\n",
    "\n",
    "\t## print info\n",
    "\tprint(DATA_NAME)\n",
    "\tprint(STRATEGY_NAME)\n",
    "\t\n",
    "\t## round 0 accuracy\n",
    "\t# acc[0] = get_pred(eval_dataloader, device, val_features, squad['validation'], rd_0=True)['f1']\n",
    "\t# acc[0] = 77.96450701 # init=4000\n",
    "\tacc[0] = 13.8252 # init=100\n",
    "\n",
    "\tprint('Round 0\\ntesting accuracy {}'.format(acc[0]))\n",
    "\tprint('\\n')\n",
    "\t\n",
    "\t# ## round 1 to rd\n",
    "\t# for rd in range(1, NUM_ROUND+1):\n",
    "\t# \tprint('Round {}'.format(rd))\n",
    "\n",
    "\t\t# ## query\n",
    "\t\t# if STRATEGY_NAME == 'RandomSampling':\n",
    "\t\t# \tq_idxs = random_sampling_query(labeled_idxs, NUM_QUERY, rd)\n",
    "\t\t# elif STRATEGY_NAME == 'MarginSampling':\n",
    "\t\t# \tq_idxs = margin_sampling_query(n_pool, labeled_idxs, train_dataset, train_features, squad['train'], device, NUM_QUERY, rd)\n",
    "\t\t# elif STRATEGY_NAME == 'LeastConfidence':\n",
    "\t\t# \tq_idxs = least_confidence_query(n_pool, labeled_idxs, train_dataset, train_features, squad['train'], device, NUM_QUERY, rd)\n",
    "\t\t# elif STRATEGY_NAME == 'EntropySampling':\n",
    "\t\t# \tq_idxs = entropy_query(n_pool, labeled_idxs, train_dataset, train_features, squad['train'], device, NUM_QUERY, rd)\n",
    "\t\t# elif STRATEGY_NAME == 'MarginSamplingDropout':\n",
    "\t\t# \tq_idxs = margin_sampling_dropout_query(n_pool, labeled_idxs, train_dataset, train_features, squad['train'], device, NUM_QUERY, rd)\n",
    "\t\t# elif STRATEGY_NAME == 'LeastConfidenceDropout':\n",
    "\t\t# \tq_idxs = least_confidence_dropout_query(n_pool, labeled_idxs, train_dataset, train_features, squad['train'], device, NUM_QUERY, rd)\n",
    "\t\t# elif STRATEGY_NAME == 'EntropySamplingDropout':\n",
    "\t\t# \tq_idxs = entropy_dropout_query(n_pool, labeled_idxs, train_dataset, train_features, squad['train'], device, NUM_QUERY, rd)\n",
    "\t\t# elif STRATEGY_NAME == 'VarRatio':\n",
    "\t\t# \tq_idxs = var_ratio_query(n_pool, labeled_idxs, train_dataset, train_features, squad['train'], device, NUM_QUERY, rd)\n",
    "\t\t# elif STRATEGY_NAME == 'KMeansSampling':\n",
    "\t\t# \tq_idxs = KMeans_query(n_pool, labeled_idxs, train_dataset, train_features, squad['train'], device, NUM_QUERY, rd)\n",
    "\t\t# elif STRATEGY_NAME == 'KCenterGreedy':\n",
    "\t\t# \tq_idxs = kcenter_query()\n",
    "\t\t# elif STRATEGY_NAME == 'KCenterGreedyPCA': # not sure\n",
    "\t\t# \tq_idxs = \n",
    "\t\t# elif STRATEGY_NAME == 'BALDDropout':\n",
    "\t\t# \tq_idxs = bayesian_query(n_pool, labeled_idxs, train_dataset, train_features, squad['train'], device, NUM_QUERY, rd)\n",
    "\t\t# elif STRATEGY_NAME == 'MeanSTD':\n",
    "\t\t# \tq_idxs = mean_std_query(n_pool, labeled_idxs, train_dataset, train_features, squad['train'], device, NUM_QUERY, rd)\n",
    "\t\t# elif STRATEGY_NAME == 'BadgeSampling':\n",
    "\t\t# \tq_idxs = badge_query()\n",
    "\t\t# elif STRATEGY_NAME == 'LossPredictionLoss':\n",
    "\t\t# \t# different net!\n",
    "\t\t# \tq_idxs = loss_prediction_query()\n",
    "\t\t# elif STRATEGY_NAME == 'CEALSampling':\n",
    "\t\t# \t# why use 'CEALSampling' in STRATEGY_NAME\n",
    "\t\t# \tq_idxs = ceal_query()\n",
    "\t\t# else:\n",
    "\t\t# \traise NotImplementedError\n",
    "\n",
    "\t# \t## update\n",
    "\t# \tlabeled_idxs[q_idxs] = True\n",
    "\t# \trun_rd_labeled_idxs = np.arange(n_pool)[labeled_idxs]\n",
    "\n",
    "\t# \ttrain_dataloader_rd = DataLoader(\n",
    "\t# \t\ttrain_dataset.select(indices=run_rd_labeled_idxs),\n",
    "\t# \t\tshuffle=True,\n",
    "\t# \t\tcollate_fn=default_data_collator,\n",
    "\t# \t\tbatch_size=8,\n",
    "\t# \t)\n",
    "\n",
    "\t# \tnum_update_steps_per_epoch_rd = len(train_dataloader_rd)\n",
    "\t# \tnum_training_steps_rd = num_train_epochs * num_update_steps_per_epoch_rd\n",
    "\n",
    "\t# \tlr_scheduler_rd = get_scheduler(\n",
    "\t# \t\t\"linear\",\n",
    "\t# \t\toptimizer=optimizer,\n",
    "\t# \t\tnum_warmup_steps=0,\n",
    "\t# \t\tnum_training_steps=num_training_steps_rd,\n",
    "\t# \t)\n",
    "\n",
    "\t# \tmodel_rd = AutoModelForQuestionAnswering.from_pretrained(model_dir).to(device)\n",
    "\t# \toptimizer_rd = AdamW(model_rd.parameters(), lr=1e-4)\n",
    "\n",
    "\t# \t## train\n",
    "\t# \tto_train(num_train_epochs, train_dataloader_rd, device, model_rd, optimizer_rd, lr_scheduler_rd)\n",
    "\n",
    "\t# \t## round rd accuracy\n",
    "\t# \tacc[rd] = get_pred(eval_dataloader, device, val_features, squad['validation'])['f1']\n",
    "\t# \tprint('testing accuracy {}'.format(acc[rd]))\n",
    "\t# \tprint('\\n')\n",
    "\n",
    "\t# \ttorch.cuda.empty_cache()\n",
    "\t\n",
    "\t# ## print results\n",
    "\t# print('SEED {}'.format(SEED))\n",
    "\t# print(STRATEGY_NAME)\n",
    "\t# print(acc)\n",
    "\t# all_acc.append(acc)\n",
    "\t\n",
    "\t# ## save model and record acq time\n",
    "\t# timestamp = re.sub('\\.[0-9]*','_',str(datetime.datetime.now())).replace(\" \", \"_\").replace(\"-\", \"\").replace(\":\",\"\")\n",
    "\t# final_model_dir = model_dir + '/' + timestamp + DATA_NAME+ '_'  + STRATEGY_NAME + '_' + str(NUM_QUERY) + '_' + str(NUM_INIT_LB) +  '_' + str(args_input.quota)\n",
    "\t# os.makedirs(final_model_dir, exist_ok=True)\n",
    "\t# end = datetime.datetime.now()\n",
    "\t# acq_time.append(round(float((end-start).seconds), 3))\n",
    "\n",
    "\t# final_model = AutoModelForQuestionAnswering.from_pretrained(model_dir).to(device)\n",
    "\t# model_to_save = final_model.module if hasattr(final_model, 'module') else final_model \n",
    "\t# model_to_save.save_pretrained(final_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## query workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get unlable data\n",
    "# unlabeled_idxs = np.arange(n_pool)[~labeled_idxs]\n",
    "# unlabeled_data = train_dataset.select(indices=unlabeled_idxs)\n",
    "# len(unlabeled_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unlable data\n",
    "unlabeled_idxs = np.arange(n_pool)[~labeled_idxs]\n",
    "# smaller data\n",
    "unlabeled_idxs_20 = unlabeled_idxs[20:40]\n",
    "unlabeled_data_20 = train_dataset.select(unlabeled_idxs_20)\n",
    "len(unlabeled_data_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_features_20 = train_features.select(unlabeled_idxs_20)\n",
    "unlabeled_dataloader_20 = DataLoader(\n",
    "\t\tunlabeled_data_20,\n",
    "\t\tshuffle=False,\n",
    "\t\tcollate_fn=default_data_collator,\n",
    "\t\tbatch_size=8,\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f661cb44ae854fcf9158e78ded915a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating_prob:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0abc9c8449944fb0a4ddb2634a8df890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing metrics:   0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{0: array([5.92328131e-01, 8.99790507e-03, 3.19611863e-03, 1.26474025e-03,\n",
       "        1.10692240e-03, 8.35207582e-04, 6.53406081e-04, 1.70150568e-04,\n",
       "        3.31909984e-01, 5.04196156e-03, 4.77753766e-03, 7.08695035e-04,\n",
       "        6.20262115e-04, 4.68007172e-04, 3.66135006e-04, 1.06273947e-04,\n",
       "        9.53436174e-05, 2.27802270e-03, 8.09169607e-04, 3.20197549e-04,\n",
       "        2.11451639e-04, 4.07111421e-02, 6.18432765e-04, 2.19671623e-04,\n",
       "        8.69265423e-05, 7.60796029e-05, 5.74044352e-05, 4.49090876e-05,\n",
       "        1.30352637e-05, 1.16945785e-05, 5.13553778e-06, 4.90996581e-06,\n",
       "        4.42525698e-06, 2.85630108e-06, 1.15006953e-03, 1.74704201e-05,\n",
       "        6.20561241e-06, 2.45563024e-06, 2.14921101e-06, 1.62164599e-06,\n",
       "        1.26865859e-06, 3.30365992e-07, 8.86360613e-06, 3.14841304e-06,\n",
       "        1.24586359e-06, 8.22741754e-07, 2.99569976e-04, 4.55069085e-06,\n",
       "        1.61643788e-06, 6.39642565e-07, 5.59826503e-07, 4.22406345e-07,\n",
       "        3.30460210e-07, 9.59190842e-08, 8.60536602e-08, 3.81241125e-06,\n",
       "        1.35419566e-06, 5.35870413e-07, 3.53877397e-07, 3.50060782e-06,\n",
       "        1.24343967e-06, 4.92043000e-07, 4.30644718e-07, 3.24934717e-07,\n",
       "        2.08906815e-04, 3.17345143e-06, 1.12723149e-06, 4.46058522e-07,\n",
       "        3.90397986e-07, 2.94567599e-07, 2.30448407e-07, 6.68896760e-08,\n",
       "        6.00100307e-08, 3.49475897e-07, 1.08205079e-07, 9.94920981e-08,\n",
       "        9.51219974e-08, 5.53357857e-08, 2.74120703e-06, 9.73695364e-07,\n",
       "        3.85302513e-07, 2.54445609e-07, 1.94633429e-07, 9.35199935e-08,\n",
       "        8.05856146e-08, 5.20143040e-08, 2.24297128e-06, 7.96718723e-07,\n",
       "        1.68608977e-07, 5.85077828e-07, 2.04466417e-07, 6.68737243e-08,\n",
       "        2.12237387e-06, 7.53881636e-07, 1.97003970e-07, 1.97039935e-06,\n",
       "        6.99899260e-07, 2.76958247e-07, 2.42398499e-07, 1.82897338e-07,\n",
       "        1.27930645e-04, 1.94336189e-06, 6.90296019e-07, 2.73157866e-07,\n",
       "        2.39072335e-07, 1.80387644e-07, 1.41122257e-07, 4.09619751e-08,\n",
       "        3.67490500e-08], dtype=float32),\n",
       " 1: array([9.98269618e-01, 1.88759470e-04, 1.57796283e-04, 1.39423093e-04,\n",
       "        1.21707235e-04, 3.87622786e-05, 1.95389148e-05, 1.93901760e-05,\n",
       "        1.79461549e-05, 8.23664959e-06, 3.94350718e-06, 8.02212046e-04,\n",
       "        1.26805489e-07, 9.78042252e-08, 3.11494510e-08, 3.16901283e-09,\n",
       "        1.28423460e-04, 2.02998773e-08, 1.79362409e-08, 1.56571591e-08,\n",
       "        4.98661512e-09, 2.51360444e-09, 5.07316744e-10, 3.12206284e-05,\n",
       "        5.90340088e-09, 4.93503816e-09, 4.36042136e-09, 3.80636234e-09,\n",
       "        1.21227972e-09, 6.11074524e-10, 6.06422634e-10, 5.61261204e-10,\n",
       "        2.57599109e-10, 1.23332122e-10, 2.54879687e-05, 4.02887901e-09,\n",
       "        3.10744741e-09, 9.89684557e-10, 4.98870556e-10, 1.00686182e-10,\n",
       "        1.89101046e-09, 1.83549775e-09, 1.16949936e-10, 1.08375052e-10,\n",
       "        1.26540936e-05, 2.00023020e-09, 1.76733106e-09, 1.54276436e-09,\n",
       "        4.91351737e-10, 2.47675852e-10, 2.27485905e-10, 1.04408017e-10,\n",
       "        4.99879964e-11, 5.43977190e-11, 9.46870296e-06, 1.79040416e-09,\n",
       "        1.49671586e-09, 1.32244460e-09, 1.15440690e-09, 3.67664510e-10,\n",
       "        1.85328822e-10, 1.83918075e-10, 1.70221393e-10, 7.81256101e-11,\n",
       "        5.43465932e-11, 3.74046211e-11, 8.48461301e-10, 5.40602181e-11,\n",
       "        7.24214244e-10, 4.61437624e-11, 4.27605000e-11, 1.25751742e-09,\n",
       "        3.08906151e-10, 3.14267709e-11, 2.08678755e-10, 6.63078592e-10,\n",
       "        4.22484617e-11, 3.91508007e-11, 5.03686488e-06, 9.52404045e-10,\n",
       "        7.96176236e-10, 7.03472558e-10, 6.14085505e-10, 1.95578789e-10,\n",
       "        9.85854662e-11, 9.78349693e-11, 9.05490197e-11, 4.15588085e-11,\n",
       "        2.89096212e-11, 1.98973546e-11, 4.05317863e-10, 3.93419464e-10,\n",
       "        2.50669780e-11, 2.32290437e-11, 3.59308056e-10, 2.28935499e-11,\n",
       "        2.83432805e-10, 1.80590994e-11, 8.59099875e-11], dtype=float32),\n",
       " 2: array([2.5003207e-01, 1.7144020e-01, 1.9037079e-02, 5.7305919e-04,\n",
       "        5.2881783e-01, 2.1469127e-02, 4.9210927e-03, 3.4141971e-04,\n",
       "        2.3945019e-04, 8.7805711e-05, 8.1456419e-05, 1.1574931e-03,\n",
       "        1.8407407e-05, 1.2909792e-05, 4.7339840e-06, 4.3916662e-06,\n",
       "        8.1653037e-04, 9.0669237e-05, 2.7293495e-06, 2.0131755e-04,\n",
       "        1.3803800e-04, 1.5328027e-05, 4.6140846e-07, 2.2996537e-05,\n",
       "        5.2712003e-06, 3.6570972e-07, 2.5648572e-07, 9.4052616e-08,\n",
       "        8.7251564e-08, 8.6806474e-05, 5.9520848e-05, 6.6093194e-06,\n",
       "        2.5019756e-07, 1.9895543e-07, 1.9200947e-08, 1.2697938e-08,\n",
       "        1.1162087e-08, 3.6354468e-05, 2.4927273e-05, 2.7679764e-06,\n",
       "        1.0478248e-07, 8.3322355e-08, 8.0413365e-09, 5.3178844e-09,\n",
       "        4.6746713e-09, 1.7303995e-04, 7.0251313e-06, 1.6102807e-06,\n",
       "        1.1171944e-07, 7.8352933e-08, 2.8731792e-08, 2.6654188e-08,\n",
       "        4.8215338e-09, 1.8250225e-06, 5.4937317e-08, 1.4038078e-05,\n",
       "        9.6255289e-06, 1.0688389e-06, 4.0461192e-08, 3.2174473e-08,\n",
       "        3.1051173e-09, 2.0534714e-09, 1.8050997e-09, 9.7092970e-06,\n",
       "        6.6574016e-06, 7.3925190e-07, 2.7984585e-08, 2.2253147e-08,\n",
       "        2.1476239e-09, 1.4202631e-09, 1.2484783e-09, 7.8001640e-06,\n",
       "        5.3483600e-06, 5.9389322e-07, 1.7877529e-08, 7.8942947e-10,\n",
       "        4.0743000e-09, 1.8440882e-06, 1.2644414e-06, 1.4040621e-07,\n",
       "        5.3151159e-09, 4.2265453e-09, 4.0789869e-10, 2.6975064e-10,\n",
       "        2.3712377e-10, 1.2385749e-06, 8.4925716e-07, 9.4303296e-08,\n",
       "        3.5698771e-09, 2.8387430e-09, 2.7396360e-10, 1.8117700e-10,\n",
       "        1.5926328e-10, 8.3336425e-07, 9.2538500e-08, 2.7856186e-09,\n",
       "        1.0909926e-06, 7.4806405e-07, 8.3066595e-08, 3.1445102e-09,\n",
       "        2.5004940e-09, 2.4131938e-10, 1.5958895e-10, 1.4028635e-10,\n",
       "        1.0816108e-06, 7.4163120e-07, 8.2352280e-08, 3.1174696e-09,\n",
       "        2.4789917e-09, 2.3924421e-10, 1.5821659e-10, 1.3907998e-10],\n",
       "       dtype=float32),\n",
       " 3: array([8.58709693e-01, 1.99174462e-03, 1.48543890e-03, 1.39197346e-03,\n",
       "        6.59484649e-04, 6.06611781e-02, 3.22491769e-03, 1.53460621e-03,\n",
       "        1.42122910e-03, 1.16171408e-03, 1.93831627e-04, 2.08851732e-02,\n",
       "        9.07148409e-04, 6.22687454e-04, 4.17181407e-04, 4.08082211e-04,\n",
       "        1.17999349e-04, 3.25595625e-02, 7.55206638e-05, 7.03589030e-05,\n",
       "        5.63231551e-05, 5.27792436e-05, 2.50055728e-05, 1.34839490e-03,\n",
       "        5.85675880e-05, 4.02021433e-05, 2.69341945e-05, 2.63467209e-05,\n",
       "        7.61830961e-06, 5.00513015e-05, 2.38173579e-05, 2.20577258e-05,\n",
       "        1.80300012e-05, 3.00830038e-06, 1.57417435e-05, 9.29709768e-06,\n",
       "        6.37649465e-03, 1.47900355e-05, 1.03363354e-05, 4.89711647e-06,\n",
       "        8.77097500e-06, 1.96821260e-04, 8.54893642e-06, 3.93150367e-06,\n",
       "        3.84575242e-06, 1.11202189e-06, 2.76259845e-03, 6.40774169e-06,\n",
       "        4.77887806e-06, 4.47818866e-06, 2.12166219e-06, 5.00021315e-06,\n",
       "        8.73719691e-05, 3.79500443e-06, 1.74525496e-06, 1.70718863e-06,\n",
       "        4.93643597e-07, 1.14458438e-04, 6.08493065e-06, 2.89556897e-06,\n",
       "        2.68164376e-06, 3.65730784e-07, 3.55079010e-07, 1.95144503e-06,\n",
       "        1.33951744e-06, 2.53838550e-07, 1.15393811e-06, 7.92089281e-07,\n",
       "        1.50101044e-07, 2.35060015e-05, 1.02098409e-06, 7.00826661e-07,\n",
       "        4.69532409e-07, 1.32806761e-07, 4.32508386e-05, 2.29933585e-06,\n",
       "        1.09415953e-06, 1.01332273e-06, 1.38200065e-07, 1.34175039e-07],\n",
       "       dtype=float32),\n",
       " 4: array([2.5279745e-01, 6.6036493e-02, 3.1850494e-02, 2.7612060e-02,\n",
       "        2.5127476e-01, 6.5638736e-02, 3.1658649e-02, 2.7445743e-02,\n",
       "        1.5860605e-01, 2.3490839e-02, 1.3168121e-02, 1.8114559e-02,\n",
       "        2.3930054e-03, 1.4710758e-03, 4.1645179e-03, 3.3805217e-03,\n",
       "        6.7954452e-04, 6.1754249e-03, 9.1462949e-04, 5.1270844e-04,\n",
       "        5.8173540e-04, 5.5291748e-04, 1.5662008e-04, 4.7515929e-04,\n",
       "        1.8969066e-03, 6.0367648e-04, 1.5404698e-04, 1.2134965e-04,\n",
       "        1.7814523e-03, 1.6137365e-04, 1.2911494e-04, 5.4523529e-04,\n",
       "        1.0960193e-04, 1.4568284e-03, 1.9686398e-04, 3.4403766e-04,\n",
       "        3.4164367e-04, 1.1405731e-03, 2.9794400e-04, 1.4370332e-04,\n",
       "        1.3275545e-03, 9.6217540e-05], dtype=float32),\n",
       " 5: array([7.6779878e-01, 1.9386831e-01, 3.1552929e-02, 5.6208712e-05,\n",
       "        4.4173239e-06, 1.7215816e-04, 4.1376759e-07, 3.0224510e-07,\n",
       "        5.6345840e-03, 2.3155502e-04, 4.1249461e-07, 3.2417088e-08,\n",
       "        3.8997197e-04, 9.8467579e-05, 1.6026022e-05, 2.8548920e-08,\n",
       "        2.2436004e-09, 1.7892569e-09, 1.1957743e-04, 3.0193194e-05,\n",
       "        4.9140726e-06, 1.6990677e-08, 8.7539789e-09, 8.6130720e-09,\n",
       "        1.3933185e-09, 6.8795708e-10, 6.0327299e-10, 5.4864124e-10,\n",
       "        5.1124527e-10, 2.0469035e-06, 3.6463748e-09, 4.9656242e-06,\n",
       "        1.2538158e-06, 2.0406394e-07, 7.0556228e-10, 3.6352155e-10,\n",
       "        3.5767034e-10, 5.7859550e-11, 2.8568406e-11, 2.5051761e-11,\n",
       "        2.2783105e-11, 2.1230195e-11, 2.6701589e-11, 2.5629081e-06,\n",
       "        6.4713203e-07, 1.0532353e-07, 3.6416184e-10, 1.8762449e-10,\n",
       "        1.8460432e-10, 2.9863067e-11, 1.4745019e-11, 1.2929975e-11,\n",
       "        1.1759050e-11, 6.5700490e-08, 1.5790558e-10, 1.1534542e-10,\n",
       "        2.2239162e-06, 5.6153681e-07, 9.1392550e-08, 3.1599473e-10,\n",
       "        1.6280759e-10, 1.6018707e-10, 2.5913110e-11, 1.2794712e-11,\n",
       "        1.1219751e-11, 1.0203704e-11, 1.8570123e-06, 4.6889397e-07,\n",
       "        7.6314528e-08, 2.6386163e-10, 1.3594745e-10, 1.3375925e-10,\n",
       "        1.0683828e-11, 9.3686985e-12, 8.5202791e-12, 1.6419333e-06,\n",
       "        4.1458668e-07, 6.7475781e-08, 1.2020203e-10, 9.4464289e-12,\n",
       "        7.5334608e-12, 1.3663939e-11, 5.8765857e-12, 7.8037243e-11,\n",
       "        5.4664229e-12, 2.7406552e-08, 4.8822300e-11, 3.8368436e-12,\n",
       "        6.1690730e-07, 2.5352003e-08, 4.5162336e-11, 3.5492147e-12,\n",
       "        5.7054297e-07, 1.4406159e-07, 2.3446651e-08, 8.1068069e-11,\n",
       "        4.1768092e-11, 4.1095800e-11, 6.6479773e-12, 3.2824676e-12,\n",
       "        2.8784108e-12, 2.6177454e-12, 2.4393187e-12], dtype=float32),\n",
       " 6: array([5.46559930e-01, 3.12724937e-04, 7.29197855e-05, 1.49180979e-01,\n",
       "        8.53568126e-05, 1.99031201e-05, 1.18664570e-01, 6.78962679e-05,\n",
       "        1.58317416e-05, 1.10733536e-05, 1.41155515e-05, 9.87298063e-06,\n",
       "        6.66727945e-02, 3.81481514e-05, 8.89521198e-06, 6.22166726e-06,\n",
       "        3.15080360e-02, 1.80279458e-05, 1.09288783e-06, 3.99378195e-07,\n",
       "        2.63101526e-07, 1.45070499e-03, 3.42313651e-05, 2.73455385e-06,\n",
       "        2.29759644e-06, 2.68305570e-07, 2.43852952e-07, 1.39614416e-03,\n",
       "        2.55130908e-06, 5.93375660e-07, 2.36186594e-07, 2.17383057e-02,\n",
       "        2.43084331e-04, 1.24379967e-05, 7.54015218e-07, 2.75542419e-07,\n",
       "        1.81521244e-07, 1.01334136e-03, 1.85177635e-06, 4.30680416e-07,\n",
       "        1.71427573e-07, 2.10645944e-02, 2.35550702e-04, 1.20525256e-05,\n",
       "        7.30646661e-07, 2.67003003e-07, 1.75895650e-07, 9.15717799e-04,\n",
       "        1.67337998e-06, 3.89189438e-07, 1.54912669e-07, 8.77605460e-04,\n",
       "        1.60373315e-06, 3.72991337e-07, 1.62311650e-07, 1.48465062e-07,\n",
       "        1.79367233e-02, 2.00573893e-04, 1.02628483e-05, 6.22153379e-07,\n",
       "        2.27355784e-07, 1.49776952e-07, 1.34439483e-06, 1.41527159e-02,\n",
       "        1.58259965e-04, 8.09775429e-06, 4.90901186e-07, 1.79391932e-07,\n",
       "        1.18179322e-07, 1.14821285e-06, 8.03105934e-07, 3.16169520e-04,\n",
       "        1.34375256e-07, 5.84750062e-08, 5.34865805e-08, 6.68400276e-07,\n",
       "        4.67505885e-07, 4.92627127e-03, 2.81866323e-06, 6.57243106e-07],\n",
       "       dtype=float32),\n",
       " 7: array([5.61349452e-01, 1.11499287e-01, 3.83709595e-02, 1.21658435e-02,\n",
       "        5.46190096e-03, 1.03668554e-03, 5.94242127e-04, 1.85042068e-01,\n",
       "        3.67544033e-02, 1.26485275e-02, 4.01032530e-03, 1.80045038e-03,\n",
       "        3.41730891e-04, 1.95884772e-04, 8.14560149e-03, 7.13110901e-04,\n",
       "        6.07690250e-04, 7.70611223e-05, 7.34847417e-05, 7.97512475e-03,\n",
       "        6.98186399e-04, 5.94972225e-04, 7.54483481e-05, 7.19468153e-05,\n",
       "        2.10262672e-03, 1.84075587e-04, 1.19405777e-04, 1.29910750e-05,\n",
       "        2.42944188e-05, 2.20722868e-05, 1.01592368e-05, 2.63545639e-03,\n",
       "        5.23473369e-04, 4.51547297e-04, 3.95309398e-05, 2.56428484e-05,\n",
       "        2.78988455e-06, 2.40222478e-04, 2.10304024e-05, 1.79214403e-05,\n",
       "        2.16714375e-06, 8.15570238e-04, 1.61994452e-04, 5.57481981e-05,\n",
       "        7.93545496e-06, 8.63359617e-07, 1.53226123e-04, 1.32172601e-04,\n",
       "        1.15711173e-05, 7.50593244e-06, 8.16627903e-07, 1.23227903e-04,\n",
       "        1.07880505e-05, 9.19323520e-06, 1.16579304e-06, 1.11168833e-06,\n",
       "        4.84687880e-05, 1.10312812e-05, 8.15360920e-07, 6.18726597e-04,\n",
       "        1.22895959e-04, 4.22929734e-05, 1.34093480e-05, 6.02017599e-06,\n",
       "        6.54981704e-07, 9.88337124e-05, 8.65244328e-06, 7.37333721e-06,\n",
       "        8.91618981e-07, 5.48513026e-06, 6.95568019e-07, 6.63287210e-07,\n",
       "        2.89254931e-05, 6.58331055e-06, 4.86596264e-07, 7.09153683e-05,\n",
       "        6.20832225e-06, 5.29053523e-06, 6.39755967e-07, 7.10739041e-05,\n",
       "        6.13082229e-05, 5.36726247e-06, 3.48162325e-06, 3.78792436e-07,\n",
       "        3.51562951e-04, 6.98299700e-05, 6.02352156e-05, 5.27332350e-06,\n",
       "        3.42069029e-06, 3.72163015e-07, 2.15979853e-05, 4.91560058e-06,\n",
       "        1.11787688e-06, 1.01562875e-06, 4.67464361e-07], dtype=float32),\n",
       " 8: array([5.2028596e-01, 1.3051804e-02, 1.3803948e-03, 1.0289188e-03,\n",
       "        8.2027755e-04, 7.0420874e-04, 4.4815626e-04, 3.1980866e-04,\n",
       "        2.3949263e-04, 2.2063190e-04, 4.0392408e-01, 1.0132768e-02,\n",
       "        1.0716694e-03, 6.3682272e-04, 3.4792628e-04, 2.5680626e-04,\n",
       "        2.4828356e-04, 1.7128764e-04, 2.8632857e-02, 7.1827893e-04,\n",
       "        7.5967160e-05, 4.5142293e-05, 2.4663361e-05, 1.8204153e-05,\n",
       "        1.7600007e-05, 1.2142019e-05, 2.6878167e-04, 2.8427097e-05,\n",
       "        2.1189006e-05, 1.6892347e-05, 1.4502092e-05, 6.5859685e-06,\n",
       "        4.9319806e-06, 5.7867453e-03, 1.4516532e-04, 1.5353078e-05,\n",
       "        1.1443885e-05, 9.1233296e-06, 7.8323765e-06, 3.5569897e-06,\n",
       "        2.6636935e-06, 2.4539213e-06, 9.4229408e-06, 6.4492096e-06,\n",
       "        2.1932960e-06, 9.4749721e-06, 8.2235229e-06, 2.8728140e-03,\n",
       "        7.2066934e-05, 7.6219985e-06, 4.5292509e-06, 2.4745432e-06,\n",
       "        1.8264731e-06, 1.7658574e-06, 1.6358242e-06, 1.2182421e-06,\n",
       "        1.5180932e-03, 3.8082639e-05, 4.0277228e-06, 2.3934099e-06,\n",
       "        1.3076340e-06, 9.3313986e-07, 6.9879343e-07, 6.4376115e-07,\n",
       "        2.9498042e-06, 2.5601983e-06, 1.2616410e-03, 3.1649313e-05,\n",
       "        3.3473191e-06, 2.4950266e-06, 1.9890908e-06, 1.7076358e-06,\n",
       "        1.0867340e-06, 7.7550442e-07, 5.8074568e-07, 5.3501049e-07,\n",
       "        7.8956737e-06, 7.8826992e-07, 7.0598895e-07, 4.6635083e-07,\n",
       "        1.2387162e-03, 3.1074229e-05, 3.2864948e-06, 2.4496890e-06,\n",
       "        1.9529489e-06, 1.6766063e-06, 1.0669869e-06, 7.6141271e-07,\n",
       "        5.7019287e-07, 5.2528878e-07, 5.3992212e-06, 4.8277002e-07,\n",
       "        3.1890013e-07, 1.6818109e-06, 1.4596784e-06, 5.6019019e-07,\n",
       "        4.8654670e-07, 7.8929681e-04, 1.9800167e-05, 2.0941195e-06,\n",
       "        1.2443971e-06, 6.7987344e-07, 5.0181802e-07, 4.8516409e-07,\n",
       "        4.4943744e-07, 3.3470843e-07, 4.8763345e-06, 4.3601617e-07,\n",
       "        2.8801600e-07, 7.6264056e-04, 1.9131463e-05, 2.0233974e-06,\n",
       "        1.5082010e-06, 1.2023717e-06, 1.0322367e-06, 6.5691222e-07,\n",
       "        4.6877921e-07, 3.5105086e-07, 3.2340475e-07, 1.8776214e-05,\n",
       "        1.9858251e-06, 1.4801954e-06, 1.0130692e-06, 3.4453222e-07,\n",
       "        3.8667872e-06, 1.3077187e-06], dtype=float32),\n",
       " 9: array([9.95986521e-01, 2.62121921e-05, 5.63619187e-06, 1.26948419e-06,\n",
       "        1.00732746e-06, 7.29865690e-07, 3.97036178e-03, 1.75079080e-07,\n",
       "        1.04491242e-07, 2.24678889e-08, 5.06061948e-09, 4.01556832e-09,\n",
       "        2.90950641e-09, 1.41852308e-09, 3.05013237e-10, 6.87005383e-11,\n",
       "        5.45134320e-11, 3.94980819e-11, 3.54216899e-11, 3.92429311e-10,\n",
       "        8.43808565e-11, 1.90057553e-11, 1.50809434e-11, 1.09270024e-11,\n",
       "        9.79928378e-12, 2.05604436e-10, 4.42094347e-11, 9.95763454e-12,\n",
       "        7.90131849e-12, 5.72495393e-12, 5.13411189e-12, 4.66041997e-11,\n",
       "        2.91460476e-12, 3.75312311e-06, 1.65499697e-10, 9.87740653e-11,\n",
       "        2.12385561e-11, 4.78373027e-12, 3.79585859e-12, 2.75031256e-12,\n",
       "        2.43162348e-12, 7.79324383e-11, 3.77434846e-12, 2.99492093e-12,\n",
       "        1.94603708e-12, 2.38573830e-06, 1.05202777e-10, 6.27874350e-11,\n",
       "        1.35006659e-11, 3.04085988e-12, 2.41290278e-12, 1.74828522e-12,\n",
       "        1.54570302e-12, 5.41771211e-11, 2.62385643e-12, 2.08201295e-12,\n",
       "        1.35284741e-12, 1.79887911e-06, 7.93242902e-11, 4.73425778e-11,\n",
       "        1.01796870e-11, 2.29284994e-12, 1.81936150e-12, 1.31823079e-12,\n",
       "        1.16548123e-12, 1.95993985e-11, 1.71700479e-12, 1.34026882e-12,\n",
       "        1.39948816e-11, 1.60325295e-11, 1.40452938e-12, 1.09635510e-12,\n",
       "        1.24271054e-11, 1.33762498e-11, 9.14710365e-13, 2.30249131e-12,\n",
       "        1.37146631e-12, 8.23144330e-12, 1.16351666e-12, 7.91312382e-13,\n",
       "        2.66218245e-11, 1.28932357e-12, 6.64768804e-13, 1.13702416e-11,\n",
       "        7.77532986e-13], dtype=float32),\n",
       " 10: array([3.7371480e-01, 6.1139543e-02, 2.4389466e-02, 4.7026169e-03,\n",
       "        4.2544603e-03, 2.0794903e-03, 2.9520905e-01, 4.8296049e-02,\n",
       "        1.9266011e-02, 3.7147440e-03, 3.3825594e-03, 3.3607315e-03,\n",
       "        3.6566224e-02, 2.3863949e-03, 4.6012847e-04, 4.1898256e-04,\n",
       "        4.1627861e-04, 3.1471021e-02, 5.1486441e-03, 2.0538706e-03,\n",
       "        6.0679932e-04, 3.5827394e-04, 1.7511674e-04, 3.3597511e-03,\n",
       "        2.0844630e-04, 2.0803283e-04, 1.8980628e-04, 1.8858151e-04,\n",
       "        3.2836709e-03, 2.0372603e-04, 2.0332212e-04, 1.8550814e-04,\n",
       "        1.8431111e-04, 9.6510706e-04, 5.0930178e-04, 3.2454706e-04,\n",
       "        3.2246331e-04, 1.1385793e-02, 1.8627105e-03, 7.4306282e-04,\n",
       "        2.1953190e-04, 1.4327248e-04, 1.2961871e-04, 6.3354892e-05,\n",
       "        1.0639774e-02, 1.7406619e-03, 6.9437589e-04, 2.0514772e-04,\n",
       "        1.1054338e-04, 5.9203754e-05, 8.7238848e-03, 1.4272236e-03,\n",
       "        5.6934042e-04, 1.6820716e-04, 9.0638037e-05, 4.8542999e-05,\n",
       "        6.2957043e-03, 1.2768995e-03, 7.9221645e-05, 7.9064492e-05,\n",
       "        7.2137351e-05, 7.1671871e-05, 1.1980212e-03, 7.4327792e-05,\n",
       "        7.4180498e-05, 6.7681191e-05, 6.7244408e-05, 1.0754385e-03,\n",
       "        6.6722503e-05, 6.6590284e-05, 6.0755996e-05, 3.2924383e-04,\n",
       "        1.1071841e-04, 1.0675717e-04, 4.4680499e-03, 7.3097082e-04,\n",
       "        2.9159512e-04, 8.6149412e-05, 4.6421414e-05, 2.4861931e-05,\n",
       "        3.8643563e-03, 6.3220691e-04, 2.5219671e-04, 7.4509480e-05,\n",
       "        6.3505395e-05, 4.0149262e-05, 2.1502752e-05, 2.3879486e-04,\n",
       "        8.0302161e-05, 7.7429140e-05, 1.8722643e-04, 1.4526192e-04,\n",
       "        6.0708040e-05, 2.9910526e-03, 4.8933458e-04, 1.9520281e-04,\n",
       "        5.7671095e-05, 4.9153819e-05, 3.1075931e-05, 1.6643364e-05,\n",
       "        5.7484093e-04, 3.5664358e-05, 3.5593683e-05, 3.2475153e-05],\n",
       "       dtype=float32),\n",
       " 11: array([6.74856961e-01, 2.09619522e-01, 5.91122434e-02, 4.89798039e-02,\n",
       "        4.21157107e-03, 7.50063395e-04, 4.65697172e-04, 7.03896163e-04,\n",
       "        2.18639500e-04, 6.16558536e-05, 5.10874015e-05, 8.73237968e-06,\n",
       "        4.39279711e-06, 4.85736109e-07, 4.31142638e-07, 2.83225876e-04,\n",
       "        8.79737199e-05, 2.48083961e-05, 2.05559809e-05, 3.51363769e-06,\n",
       "        1.76752474e-06, 3.14788849e-07, 1.95445082e-07, 1.38158735e-04,\n",
       "        4.29139436e-05, 1.21016355e-05, 1.00272937e-05, 1.71396709e-06,\n",
       "        8.62205525e-07, 9.53389332e-08, 5.77327046e-05, 1.79325452e-05,\n",
       "        5.05693652e-06, 4.19012758e-06, 7.16219290e-07, 3.60291921e-07,\n",
       "        9.07805671e-08, 3.98394953e-08, 3.53617722e-08, 5.63164322e-05,\n",
       "        1.74926317e-05, 4.93288189e-06, 4.08733695e-06, 6.98649274e-07,\n",
       "        3.51453423e-07, 8.85535627e-08, 3.88621650e-08, 3.44942919e-08,\n",
       "        2.36525992e-07, 9.68487086e-08, 9.12507545e-08, 2.95084401e-08,\n",
       "        5.95740516e-07, 4.33998196e-07, 3.86154930e-08, 2.16059834e-06,\n",
       "        5.10446625e-07, 3.71861432e-07, 3.30868346e-08, 2.73728510e-05,\n",
       "        8.50237120e-06, 2.39764950e-06, 1.98666862e-06, 3.39581618e-07,\n",
       "        1.70825331e-07, 4.30418581e-08, 1.88891285e-08, 1.67661209e-08,\n",
       "        2.37102158e-05, 7.36470793e-06, 2.07683092e-06, 1.72084128e-06,\n",
       "        2.94143604e-07, 1.47968038e-07, 7.69063746e-08, 3.72826392e-08,\n",
       "        1.63616534e-08, 1.45227146e-08, 1.11203974e-07, 4.29019877e-08,\n",
       "        1.74154547e-06, 1.44302703e-06, 1.24079961e-07, 2.20981242e-08,\n",
       "        1.97301270e-05, 1.72820603e-06, 1.43197428e-06, 1.23129610e-07,\n",
       "        2.19288747e-08, 1.85145800e-05, 5.75087506e-06, 1.62173365e-06,\n",
       "        1.34375227e-06, 2.29687871e-07, 1.15543656e-07, 6.00538073e-08,\n",
       "        2.91128579e-08, 1.27763204e-08, 1.13403482e-08, 2.79895403e-07,\n",
       "        2.03904392e-07, 1.81426447e-08, 2.39751103e-07, 1.74659164e-07,\n",
       "        1.55405004e-08, 1.34368056e-05, 4.17365072e-06, 1.17695993e-06,\n",
       "        9.75217290e-07, 1.66694164e-07, 8.38549070e-08, 4.35835759e-08,\n",
       "        2.11284110e-08, 9.27231447e-09, 8.23016144e-09, 1.29328059e-08,\n",
       "        1.44343531e-07, 1.05154548e-07, 1.21259678e-08], dtype=float32),\n",
       " 12: array([7.67992914e-01, 1.67511646e-02, 2.61344365e-03, 8.76699458e-04,\n",
       "        3.34738754e-04, 2.50224111e-04, 1.22990416e-04, 7.88883699e-05,\n",
       "        7.01780809e-05, 4.31907938e-05, 2.02813849e-01, 2.31521393e-04,\n",
       "        8.83988032e-05, 6.60799124e-05, 3.24796674e-05, 2.08330694e-05,\n",
       "        1.85328336e-05, 1.14059485e-05, 5.62443770e-03, 2.45147658e-06,\n",
       "        1.83252962e-06, 9.00727002e-07, 5.13952955e-07, 3.16310093e-07,\n",
       "        2.04943717e-07, 6.21441174e-08, 4.89695076e-08, 3.65989820e-07,\n",
       "        2.73584845e-07, 4.72230397e-08, 7.31400505e-04, 2.48892070e-06,\n",
       "        8.34927619e-07, 3.18789404e-07, 2.38301809e-07, 1.17130313e-07,\n",
       "        7.51295843e-08, 6.68343176e-08, 4.11328855e-08, 1.84106199e-07,\n",
       "        1.37623132e-07, 6.76446490e-08, 3.85979355e-08, 2.37549287e-08,\n",
       "        4.03037382e-04, 4.60085801e-07, 1.75668490e-07, 1.31315900e-07,\n",
       "        6.45445155e-08, 3.68289683e-08, 2.26662227e-08, 5.35538511e-08,\n",
       "        1.71615770e-08, 1.21925066e-08, 1.07614619e-08, 1.33025608e-07,\n",
       "        9.94394398e-08, 4.88765579e-08, 1.71640782e-08, 3.58550878e-08,\n",
       "        1.94376746e-08, 1.08721681e-08, 8.56725890e-09, 2.39832778e-04,\n",
       "        5.23113840e-06, 8.16139334e-07, 2.73780103e-07, 3.84080963e-08,\n",
       "        2.46356731e-08, 2.19155574e-08, 1.34878340e-08, 2.30296559e-04,\n",
       "        5.02313833e-06, 7.83688108e-07, 2.62894048e-07, 1.00377463e-07,\n",
       "        7.50342082e-08, 3.68808770e-08, 2.36560886e-08, 2.10441726e-08,\n",
       "        1.29515438e-08, 1.12929989e-07, 2.55783306e-08, 2.00347365e-08,\n",
       "        6.11171780e-09, 7.42203810e-08, 5.54812480e-08, 7.41548689e-08,\n",
       "        5.54322774e-08, 2.72461484e-08, 9.56808410e-09, 1.66701444e-04,\n",
       "        3.63602589e-06, 5.67276913e-07, 1.90297385e-07, 2.66964388e-08,\n",
       "        1.71235985e-08, 1.52329349e-08, 9.37504119e-09, 1.55817019e-04,\n",
       "        1.77872323e-07, 6.79146552e-08, 5.07675857e-08, 2.49533514e-08,\n",
       "        1.42383305e-08, 8.76291839e-09], dtype=float32),\n",
       " 13: array([8.73541474e-01, 1.39151951e-02, 7.28883082e-03, 3.81597038e-03,\n",
       "        2.38817930e-03, 1.01857330e-03, 5.48398588e-04, 5.24739851e-04,\n",
       "        5.18137764e-04, 4.85614059e-04, 6.42547980e-02, 6.51311502e-03,\n",
       "        4.48373938e-03, 1.21344207e-03, 4.43553727e-04, 2.48560589e-03,\n",
       "        1.73447086e-04, 2.84261223e-05, 1.71582487e-05, 8.59681586e-06,\n",
       "        8.04174226e-03, 6.71003072e-05, 3.51294693e-05, 9.37689492e-06,\n",
       "        4.76992727e-06, 4.47051752e-06, 7.12726847e-04, 7.22447585e-05,\n",
       "        4.97345100e-05, 1.34597358e-05, 4.91998480e-06, 4.11287008e-04,\n",
       "        4.16896546e-05, 2.86998657e-05, 7.76709476e-06, 3.35154851e-04,\n",
       "        2.33873197e-05, 3.83293082e-06, 2.31358968e-06, 1.15918078e-06,\n",
       "        5.80361984e-06, 2.57818538e-05, 4.80335120e-06, 1.56378909e-03,\n",
       "        2.49105851e-05, 1.30482613e-05, 6.83124290e-06, 1.82342126e-06,\n",
       "        9.27555163e-07, 8.69332155e-07, 1.45934685e-03, 2.32468719e-05,\n",
       "        3.98971679e-06, 3.70440785e-06, 1.70163776e-06, 9.16159706e-07,\n",
       "        8.76635113e-07, 8.65606012e-07, 1.96108249e-05, 3.65364281e-06,\n",
       "        1.14296342e-03, 1.82069925e-05, 9.53688414e-06, 4.99290854e-06,\n",
       "        3.12475390e-06, 2.90129947e-06, 1.33272715e-06, 7.17538683e-07,\n",
       "        6.86583007e-07, 6.77944229e-07, 1.07626326e-03, 1.71444844e-05,\n",
       "        8.98033977e-06, 4.70153736e-06, 1.25495319e-06, 6.75665149e-07,\n",
       "        6.46515957e-07, 6.38381493e-07, 5.98310010e-07, 1.02446609e-06,\n",
       "        1.40369346e-04, 9.79506149e-06, 1.60530556e-06, 9.68976224e-07,\n",
       "        4.85487362e-07, 7.01033605e-06, 3.67016833e-06, 1.54437271e-06,\n",
       "        9.32196599e-07, 4.67059635e-07, 1.13055889e-04, 1.14597806e-05,\n",
       "        7.88910711e-06, 1.29294131e-06, 7.80430469e-07, 6.63246843e-04,\n",
       "        1.05652825e-05, 5.53413065e-06, 2.89732066e-06, 1.81325413e-06,\n",
       "        1.68358645e-06, 7.73363752e-07, 4.16378015e-07, 3.98414812e-07,\n",
       "        3.93402303e-07, 5.44830618e-06, 2.85238798e-06, 7.61370870e-07,\n",
       "        3.62990221e-07], dtype=float32),\n",
       " 14: array([9.95310128e-01, 7.37403298e-06, 1.94943800e-06, 4.77415767e-07,\n",
       "        4.66073537e-03, 2.37876677e-07, 3.45303590e-08, 9.12862674e-09,\n",
       "        2.23559349e-09, 5.39604707e-06, 2.75405726e-10, 3.99781042e-11,\n",
       "        1.05688245e-11, 6.50920333e-12, 2.58829807e-12, 4.35033598e-06,\n",
       "        2.22034308e-10, 1.12947963e-10, 3.22306834e-11, 3.17280577e-11,\n",
       "        8.52066594e-12, 5.24776880e-12, 3.75533936e-12, 2.70276293e-12,\n",
       "        2.08670559e-12, 1.93602946e-12, 1.69681084e-06, 8.66025515e-11,\n",
       "        1.25712982e-11, 1.23752545e-11, 3.32341533e-12, 2.04684663e-12,\n",
       "        8.13901464e-13, 7.55132122e-13, 1.63410391e-06, 8.34020977e-11,\n",
       "        1.21067175e-11, 1.19179172e-11, 3.20059322e-12, 1.97120423e-12,\n",
       "        1.01523098e-12, 7.83823039e-13, 7.27225084e-13, 1.40202201e-06,\n",
       "        7.15569964e-11, 3.64007539e-11, 1.02252868e-11, 1.69124578e-12,\n",
       "        1.27470690e-12, 1.21026713e-12, 8.71043797e-13, 6.72501497e-13,\n",
       "        6.23941708e-13, 6.80982397e-13, 1.27847136e-06, 6.52511725e-11,\n",
       "        9.47190937e-12, 9.32420634e-12, 2.50404428e-12, 1.54220701e-12,\n",
       "        7.94285048e-13, 6.13238193e-13, 5.68958184e-13, 6.90825912e-12,\n",
       "        1.82630408e-12, 4.89031287e-13, 7.92816991e-07, 4.04641320e-11,\n",
       "        2.05839529e-11, 5.78220978e-12, 9.56368014e-13, 7.20822978e-13,\n",
       "        6.84382889e-13, 4.92559010e-13, 3.80287056e-13, 3.52827386e-13,\n",
       "        8.40640437e-13, 7.21706115e-13, 7.18729154e-07, 3.66828234e-11,\n",
       "        1.86603944e-11, 5.32490631e-12, 5.24186640e-12, 1.40771921e-12,\n",
       "        8.66996091e-13, 4.46529722e-13, 3.44749484e-13, 3.19855931e-13,\n",
       "        6.77210664e-07, 3.45637685e-11, 5.01730255e-12, 4.93906478e-12,\n",
       "        1.32640079e-12, 8.16913160e-13, 4.20735468e-13, 3.24834669e-13,\n",
       "        3.01379120e-13, 5.58485453e-07, 2.85042216e-11, 4.13769453e-12,\n",
       "        4.07317235e-12, 1.09386274e-12, 6.73695366e-13, 3.46974267e-13,\n",
       "        2.67886028e-13, 2.48542858e-13, 3.88155133e-12, 1.02614759e-12,\n",
       "        2.74772528e-13, 8.41214685e-13, 3.25907704e-13, 2.52579397e-13,\n",
       "        1.28755557e-11, 6.22045471e-12, 4.50885097e-13, 4.28091698e-13,\n",
       "        4.16195588e-13, 4.85124872e-07, 2.47600083e-11, 1.25953232e-11,\n",
       "        3.59418138e-12, 3.53813506e-12, 9.50177003e-13, 5.85201700e-13,\n",
       "        4.18773984e-13, 3.01396928e-13, 2.32697704e-13, 2.15895146e-13,\n",
       "        1.21104359e-11, 5.85080899e-12, 4.24091589e-13, 4.02652629e-13,\n",
       "        3.91463500e-13], dtype=float32),\n",
       " 15: array([9.61845934e-01, 5.93457429e-04, 3.77846300e-04, 4.98213485e-05,\n",
       "        2.31605754e-05, 7.86210421e-06, 1.07825372e-06, 2.63821501e-02,\n",
       "        1.62777596e-05, 1.03638204e-05, 1.36653375e-06, 6.35263916e-07,\n",
       "        4.38431925e-07, 2.15647120e-07, 2.95750748e-08, 9.10034031e-03,\n",
       "        5.61490106e-06, 3.57492786e-06, 7.43859658e-08, 1.02017150e-08,\n",
       "        1.36956340e-03, 4.77102958e-06, 8.45018405e-07, 5.38011477e-07,\n",
       "        2.24589755e-07, 7.09401320e-08, 3.29781109e-08, 2.27600783e-08,\n",
       "        1.11947731e-08, 1.53531454e-09, 9.99735903e-08, 2.08021889e-09,\n",
       "        3.43586604e-10, 2.85293011e-10, 1.62122975e-04, 1.00029716e-07,\n",
       "        6.36875086e-08, 8.39759196e-09, 1.32518962e-09, 1.81744064e-10,\n",
       "        1.82014755e-05, 6.34069011e-08, 1.12302851e-08, 7.15016490e-09,\n",
       "        2.98479463e-09, 9.42793621e-10, 4.38278580e-10, 3.02481123e-10,\n",
       "        1.48778337e-10, 3.60343803e-11, 1.59576970e-11, 8.44690931e-06,\n",
       "        2.94257685e-08, 5.21173149e-09, 3.31823613e-09, 1.38517831e-09,\n",
       "        4.37529984e-10, 2.03395564e-10, 1.40374920e-10, 6.90447907e-11,\n",
       "        9.46919453e-12, 5.66763492e-06, 1.97438546e-08, 3.49692342e-09,\n",
       "        2.22644192e-09, 9.29415045e-10, 2.93570113e-10, 1.36472653e-10,\n",
       "        9.41875605e-11, 4.63270984e-11, 1.12205011e-11, 4.96896317e-12,\n",
       "        2.06230100e-09, 4.29117124e-11, 7.08766379e-12, 5.88515564e-12,\n",
       "        1.52465685e-08, 7.17711668e-10, 3.56124609e-11, 1.45511901e-11,\n",
       "        8.66468008e-12, 3.83712550e-12, 3.79964419e-12, 3.57619456e-06,\n",
       "        1.24580835e-08, 2.20650742e-09, 1.40485246e-09, 5.86447391e-10,\n",
       "        1.85238450e-10, 8.61122423e-11, 5.94309948e-11, 2.92317212e-11,\n",
       "        4.00900450e-12, 9.66960512e-10, 2.01202076e-11, 3.32322711e-12,\n",
       "        2.75940121e-12, 1.88525189e-06, 1.16319798e-09, 7.40591866e-10,\n",
       "        9.76516021e-11, 4.53955415e-11, 3.13300635e-11, 1.54100014e-11,\n",
       "        2.11341535e-12, 5.89630345e-09, 2.77560502e-10, 1.37724094e-11,\n",
       "        5.62737964e-12, 3.35088858e-12, 1.48393027e-12, 1.46943655e-12,\n",
       "        1.33484473e-11, 5.45415492e-12, 3.96073452e-12, 1.79526988e-12,\n",
       "        1.51478667e-12, 1.43825002e-12, 1.42420223e-12, 1.39004453e-06,\n",
       "        8.57655724e-10, 5.46057199e-10, 2.27948452e-10, 7.20010232e-11,\n",
       "        3.34712952e-11, 2.31004590e-11, 1.13621890e-11, 1.55827521e-12,\n",
       "        8.55790439e-10, 5.44869649e-10, 1.13374778e-11, 1.55488621e-12,\n",
       "        1.19123240e-06, 4.14979429e-09, 7.34988848e-10, 4.67956951e-10,\n",
       "        1.95345948e-10, 6.17030246e-11, 2.86840360e-11, 1.97964978e-11,\n",
       "        9.73710262e-12, 2.35834182e-12, 6.85909356e-07, 4.23205249e-10,\n",
       "        2.69448769e-10, 3.55284899e-11, 1.65162155e-11, 1.13987864e-11,\n",
       "        5.60660633e-12, 7.68921819e-13], dtype=float32),\n",
       " 16: array([8.81188869e-01, 5.46092428e-02, 4.20492055e-04, 1.91132669e-04,\n",
       "        2.50418616e-05, 7.48044249e-06, 4.08462547e-02, 4.08369675e-03,\n",
       "        2.53133383e-03, 2.12911895e-04, 1.09362889e-04, 4.70844534e-05,\n",
       "        1.94913064e-05, 1.30976741e-06, 1.16077933e-06, 4.59772451e-07,\n",
       "        4.56636940e-07, 1.18112611e-02, 7.31970242e-04, 5.63618278e-06,\n",
       "        2.56189992e-06, 3.35655471e-07, 1.32949609e-07, 1.00266192e-07,\n",
       "        1.46631093e-03, 9.08705406e-05, 3.18047370e-07, 4.16699812e-08,\n",
       "        1.24475568e-08, 8.21649330e-04, 8.21462163e-05, 5.09194433e-05,\n",
       "        4.28286330e-06, 2.19990693e-06, 9.47134765e-07, 3.92080466e-07,\n",
       "        2.63468287e-08, 2.33498447e-08, 9.24862320e-09, 9.18555010e-09,\n",
       "        1.28383836e-04, 1.28354586e-05, 7.95623237e-06, 6.69203075e-07,\n",
       "        3.43738378e-07, 1.47991074e-07, 6.12631226e-08, 4.11672962e-09,\n",
       "        2.57408606e-09, 1.86297400e-09, 1.44511059e-09, 1.43525480e-09,\n",
       "        1.02810758e-04, 6.37141056e-06, 5.35902927e-07, 1.18512368e-07,\n",
       "        4.90599668e-08, 2.92170221e-09, 1.15725551e-09, 9.93477661e-05,\n",
       "        6.15680119e-06, 4.74074717e-08, 2.82328960e-09, 1.11827536e-09,\n",
       "        8.43366210e-10, 5.64520815e-05, 5.64392121e-06, 3.49846118e-06,\n",
       "        2.94257518e-07, 1.51146324e-07, 6.50736496e-08, 2.69382081e-08,\n",
       "        1.60426961e-09, 6.35434372e-10, 6.31100505e-10, 2.77160166e-06,\n",
       "        9.70062164e-09, 1.27095789e-09, 3.79657444e-10, 4.37097915e-05,\n",
       "        4.36998289e-06, 2.70879286e-06, 2.27838086e-07, 1.17029813e-07,\n",
       "        5.03853066e-08, 2.08577440e-08, 1.40158862e-09, 8.76377637e-10,\n",
       "        6.34271302e-10, 4.92004826e-10, 4.88649177e-10, 4.19690514e-05,\n",
       "        2.60091542e-06, 2.18764455e-07, 4.83787268e-08, 2.00270929e-08,\n",
       "        1.19268706e-09, 4.72410666e-10, 2.86842169e-05, 1.77762479e-06,\n",
       "        1.49517007e-07, 3.30649748e-08, 1.36877363e-08, 8.15155610e-10,\n",
       "        3.22874560e-10, 2.02670708e-05, 1.25599536e-06, 9.67118208e-09,\n",
       "        4.39599024e-09, 5.75954617e-10, 2.28129585e-10, 1.72047765e-10,\n",
       "        4.07173717e-09, 1.59357347e-10, 8.22201807e-10, 3.76214310e-10,\n",
       "        2.72282058e-10, 1.42539452e-10, 1.13073724e-10, 1.67258768e-05,\n",
       "        1.03653963e-06, 8.71839347e-08, 4.47823219e-08, 1.92803107e-08,\n",
       "        7.98137112e-09, 4.75320061e-10, 1.88269289e-10, 1.86985247e-10,\n",
       "        1.28111933e-05, 7.93938057e-07, 1.47677630e-08, 6.11333473e-09,\n",
       "        3.64071606e-10, 1.44204940e-10, 9.84362759e-06, 6.10031407e-07,\n",
       "        4.69725014e-09, 2.13511298e-09, 2.79738732e-10, 1.10801583e-10,\n",
       "        8.35627956e-11, 6.76125228e-06, 4.19009808e-07, 3.52431435e-08,\n",
       "        7.79385534e-09, 3.22638183e-09, 1.92143024e-10, 7.61058369e-11,\n",
       "        7.55867799e-11], dtype=float32),\n",
       " 17: array([9.76930678e-01, 1.26743270e-02, 7.47937988e-03, 7.84193748e-04,\n",
       "        1.88247592e-04, 2.56300209e-05, 1.97453628e-05, 1.52239945e-05,\n",
       "        1.52057910e-04, 5.88733701e-06, 3.11789358e-06, 1.19157335e-06,\n",
       "        9.49741263e-07, 4.25667095e-04, 1.40929085e-04, 8.19392153e-05,\n",
       "        4.89584127e-05, 4.14428996e-06, 3.17250033e-06, 2.66527263e-06,\n",
       "        1.03772675e-06, 2.32651237e-05, 1.35268501e-05, 8.08224831e-06,\n",
       "        6.84155737e-07, 5.23728829e-07, 2.77363227e-07, 1.71312024e-07,\n",
       "        1.33409330e-05, 7.97116263e-06, 6.74752414e-07, 5.16530463e-07,\n",
       "        2.73551024e-07, 5.06212600e-05, 3.13206829e-06, 7.51860910e-07,\n",
       "        6.08046093e-08, 6.22739433e-04, 8.07918696e-06, 4.99880116e-07,\n",
       "        1.19997495e-07, 9.70445679e-09, 2.22717645e-04, 2.88945398e-06,\n",
       "        1.70512499e-06, 1.78777981e-07, 4.29161062e-08, 5.84305271e-09,\n",
       "        4.50148585e-09, 3.47071816e-09, 1.70295766e-06, 1.05366389e-07,\n",
       "        2.52934651e-08, 2.04553707e-09, 1.60077298e-06, 9.90439446e-08,\n",
       "        1.92279592e-09, 2.16346692e-07, 8.37645153e-09, 4.43611192e-09,\n",
       "        1.69536030e-09, 1.96700455e-07, 7.61579422e-09, 4.03327327e-09,\n",
       "        1.54140622e-09, 1.10286691e-09, 8.79037843e-10, 7.19743753e-07,\n",
       "        2.38291420e-07, 1.38547804e-07, 8.27818525e-08, 7.00741776e-09,\n",
       "        5.36425615e-09, 2.84087354e-09, 1.75465109e-09, 2.31926158e-08,\n",
       "        4.50251447e-10, 6.80436614e-08, 1.39521128e-09, 5.33211364e-10,\n",
       "        4.24995067e-10, 1.61062071e-05, 2.08955839e-07, 1.29286368e-08,\n",
       "        3.10355208e-09, 3.25532629e-10, 2.50990867e-10, 6.29781789e-06,\n",
       "        8.17055223e-08, 5.05533171e-09, 1.21354549e-09, 1.65224917e-10,\n",
       "        1.27289179e-10, 9.81420223e-11, 2.93282891e-08, 1.70521020e-08,\n",
       "        1.01885735e-08, 8.62454663e-10, 6.60218658e-10, 3.49647394e-10],\n",
       "       dtype=float32),\n",
       " 18: array([7.61548936e-01, 3.43635567e-02, 3.97433713e-03, 2.59717880e-03,\n",
       "        2.41828166e-04, 1.50209686e-04, 6.77301650e-05, 9.07416120e-02,\n",
       "        1.85645558e-02, 8.90754454e-04, 1.78132570e-04, 1.25796359e-04,\n",
       "        1.16917101e-04, 4.70963344e-02, 1.38154645e-02, 1.24525493e-02,\n",
       "        2.54763081e-03, 1.22239042e-04, 5.26846416e-05, 2.69236625e-05,\n",
       "        2.44452967e-05, 1.72631499e-05, 5.44893446e-05, 1.08967497e-05,\n",
       "        9.51528546e-06, 9.20964976e-06, 7.15206761e-06, 3.96833569e-03,\n",
       "        3.57685564e-03, 7.31778156e-04, 3.51117851e-05, 7.73351712e-06,\n",
       "        7.02163561e-06, 4.95864469e-06, 4.60864158e-06, 9.85249353e-05,\n",
       "        1.13949554e-05, 6.93353797e-07, 4.30671435e-07, 1.94191500e-07,\n",
       "        5.71063902e-06, 2.15833040e-07, 9.73200045e-08, 4.30149375e-04,\n",
       "        1.26182073e-04, 1.13734051e-04, 2.32685143e-05, 1.11645750e-06,\n",
       "        2.45904346e-07, 2.23268458e-07, 1.57671124e-07, 1.46541993e-07,\n",
       "        8.01084563e-04, 3.61475395e-05, 4.18066293e-06, 2.54382655e-07,\n",
       "        1.58007779e-07, 7.12463830e-08, 1.40515840e-05, 1.62514323e-06,\n",
       "        6.14221420e-08, 2.76955081e-08, 3.49972815e-08, 3.38731674e-08,\n",
       "        1.94174277e-07, 3.88308585e-08, 3.28188250e-08, 2.54865853e-08,\n",
       "        1.10637200e-04, 4.99231010e-06, 5.77388334e-07, 3.77315899e-07,\n",
       "        3.51326008e-08, 2.18223466e-08, 9.83978143e-09, 1.15521725e-05,\n",
       "        1.04125356e-05, 2.13027010e-06, 1.02213470e-07, 2.04405985e-08,\n",
       "        1.44350443e-08, 1.34161544e-08, 3.37612619e-06, 3.90467733e-07,\n",
       "        2.37589504e-08, 1.47576937e-08, 6.65430377e-09, 8.46966032e-06,\n",
       "        8.31414440e-08, 1.66265846e-08, 1.40523566e-08, 1.17416077e-08,\n",
       "        1.09128333e-08, 2.98993727e-05, 1.34915672e-06, 1.56037473e-07,\n",
       "        1.01968496e-07, 9.49448076e-09, 5.89742166e-09, 2.65917310e-09],\n",
       "       dtype=float32),\n",
       " 19: array([5.32847881e-01, 3.19081694e-01, 1.29220600e-03, 7.89268583e-04,\n",
       "        5.46042807e-04, 3.40801751e-04, 1.35244743e-04, 9.67515807e-05,\n",
       "        3.06961462e-02, 1.83815677e-02, 7.44410354e-05, 4.54679539e-05,\n",
       "        3.14562822e-05, 7.79114271e-06, 5.57363546e-06, 3.01103368e-02,\n",
       "        1.80307683e-02, 7.30203756e-05, 4.46002341e-05, 3.08559611e-05,\n",
       "        1.92581319e-05, 7.64245306e-06, 5.46726824e-06, 1.47724645e-02,\n",
       "        8.84609297e-03, 3.58245998e-05, 1.51382719e-05, 3.74947081e-06,\n",
       "        2.68230156e-06, 6.83082035e-03, 4.09045396e-03, 1.65653782e-05,\n",
       "        1.01179930e-05, 6.99997236e-06, 4.36889331e-06, 2.46226341e-06,\n",
       "        1.24030259e-06, 1.15553257e-06, 1.12975004e-05, 4.77394406e-06,\n",
       "        1.18241815e-06, 8.45879867e-07, 2.41211453e-03, 1.44443021e-03,\n",
       "        5.84960435e-06, 3.57288741e-06, 2.47184494e-06, 1.54275301e-06,\n",
       "        8.69480232e-07, 6.12230849e-07, 4.37978343e-07, 5.67481607e-07,\n",
       "        1.24629668e-03, 5.04720947e-06, 2.13278099e-06, 5.28250553e-07,\n",
       "        3.77900648e-07, 1.79670751e-03, 1.07591017e-03, 4.35718448e-06,\n",
       "        2.66132997e-06, 1.84119892e-06, 1.14914758e-06, 6.47648164e-07,\n",
       "        3.26236119e-07, 3.03939061e-07, 1.20014779e-03, 7.18676310e-04,\n",
       "        2.91047104e-06, 1.77769039e-06, 1.22986671e-06, 7.67596873e-07,\n",
       "        3.04615497e-07, 2.17916153e-07, 7.04458915e-04, 4.21846431e-04,\n",
       "        1.70837882e-06, 1.04346339e-06, 7.21903461e-07, 4.50561913e-07,\n",
       "        2.53931972e-07, 1.78802182e-07, 1.27911690e-07, 1.19169513e-07,\n",
       "        6.75049494e-04, 4.04235354e-04, 1.63705806e-06, 9.99901204e-07,\n",
       "        6.91765763e-07, 4.31751801e-07, 2.43330845e-07, 1.71337561e-07,\n",
       "        1.22571763e-07, 1.14194428e-07, 1.02651221e-07, 9.32707138e-08,\n",
       "        4.19573553e-07, 4.02029571e-07, 1.39205625e-07, 5.67632874e-08,\n",
       "        3.07392038e-04, 1.84073506e-04, 7.45454486e-07, 4.55317291e-07,\n",
       "        3.15004002e-07, 1.96603466e-07, 1.10803754e-07, 5.58145494e-08,\n",
       "        5.19998302e-08, 5.92862762e-07, 2.50523982e-07, 6.20501410e-08,\n",
       "        4.43895445e-08, 5.20745154e-08, 3.63483963e-08, 2.17639311e-07],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prob(unlabeled_dataloader_20, device, unlabeled_features_20, squad['train'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test: query 5 data from 20 unlabeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# def kmeans_query(n_pool, labeled_idxs, train_dataset, train_features, examples, device, n, rd):\n",
    "#     # deepAL+: unlabeled_idxs, unlabeled_data = self.dataset.get_unlabeled_data()\n",
    "#     unlabeled_idxs, unlabeled_data = get_unlabel_data(n_pool, labeled_idxs, train_dataset)\n",
    "#     unlabeled_features = train_features.select(unlabeled_idxs)\n",
    "#     unlabeled_dataloader = DataLoader(\n",
    "#       unlabeled_data,\n",
    "#       shuffle=True,\n",
    "#       collate_fn=default_data_collator,\n",
    "#       batch_size=8,\n",
    "#     )\n",
    "n = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# smaller data\n",
    "unlabeled_idxs_20 = unlabeled_idxs[20:120]\n",
    "unlabeled_data_20 = train_dataset.select(unlabeled_idxs_20)\n",
    "unlabeled_feature_20 = train_features.select(unlabeled_idxs_20)\n",
    "len(unlabeled_data_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 21,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,\n",
       "        35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,\n",
       "        48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,\n",
       "        61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,\n",
       "        74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  85,  86,  87,\n",
       "        88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,\n",
       "       101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
       "       114, 115, 116, 117, 118, 119, 120, 121, 122])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_idxs_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_dataloader = DataLoader(\n",
    "\t\tunlabeled_data_20,\n",
    "\t\tshuffle=True,\n",
    "\t\tcollate_fn=default_data_collator,\n",
    "\t\tbatch_size=8,\n",
    "\t)\n",
    "len(unlabeled_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e35c648ea846c3bbab5add225b6b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating_prob:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'QuestionAnsweringModelOutput' object has no attribute 'last_hidden_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# # deepAL+: embeddings = get_embeddings(unlabeled_data)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# embeddings = get_embeddings(unlabeled_dataloader, device, unlabeled_features, examples, rd=1)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m embeddings \u001b[39m=\u001b[39m get_embeddings(unlabeled_dataloader, device, unlabeled_feature_20, squad[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m], rd\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[55], line 19\u001b[0m, in \u001b[0;36mget_embeddings\u001b[0;34m(eval_dataloader, device, features, examples, rd)\u001b[0m\n\u001b[1;32m     15\u001b[0m     outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbatch)\n\u001b[1;32m     16\u001b[0m     \u001b[39m# print('len_output:', len(outputs)) # 4\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[39m# print('outputs:', outputs) # (loss, start_logits, end_logits, hidden_states)\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39;49mlast_hidden_state\n\u001b[1;32m     20\u001b[0m \u001b[39m# print('len_hidden_states:', len(hidden_states)) # 13 # each one has: (batch_size, sequence_length, hidden_size)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m# # hidden_states[0] -> last hidden states\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m# print('len_hidden_states[0]:', len(hidden_states[0])) # 8, 8, 4\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[39m# TODO: Question!!!!!\u001b[39;00m\n\u001b[1;32m     28\u001b[0m embedding_of_last_layer \u001b[39m=\u001b[39m hidden_states[:, \u001b[39m0\u001b[39m, :] \u001b[39m# [:, 0, :] -> to get [cls], but all the same\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'QuestionAnsweringModelOutput' object has no attribute 'last_hidden_state'"
     ]
    }
   ],
   "source": [
    "    # # deepAL+: embeddings = get_embeddings(unlabeled_data)\n",
    "    # embeddings = get_embeddings(unlabeled_dataloader, device, unlabeled_features, examples, rd=1)\n",
    "embeddings = get_embeddings(unlabeled_dataloader, device, unlabeled_feature_20, squad['train'], rd=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9169,  2.2937,  0.6952,  ..., -0.0484,  0.1575,  0.0433],\n",
      "        [-0.9169,  2.2937,  0.6952,  ..., -0.0484,  0.1575,  0.0433],\n",
      "        [-0.9169,  2.2937,  0.6952,  ..., -0.0484,  0.1575,  0.0433],\n",
      "        ...,\n",
      "        [-0.9169,  2.2937,  0.6952,  ..., -0.0484,  0.1575,  0.0433],\n",
      "        [-0.9169,  2.2937,  0.6952,  ..., -0.0484,  0.1575,  0.0433],\n",
      "        [-0.9169,  2.2937,  0.6952,  ..., -0.0484,  0.1575,  0.0433]])\n"
     ]
    }
   ],
   "source": [
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mount/arbeitsdaten31/studenten1/linku/.venv/lib64/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mount/arbeitsdaten31/studenten1/linku/.venv/lib64/python3.10/site-packages/sklearn/base.py:1151: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=5)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # deepAL+: embeddings = embeddings.numpy()\n",
    "# embeddings = embeddings.numpy()\n",
    "print(embeddings.shape)\n",
    "    # deepAL+: cluster_learner = KMeans(n_clusters=n)\n",
    "cluster_learner = KMeans(n_clusters=n)\n",
    "    # deepAL+: cluster_learner.fit(embeddings)\n",
    "cluster_learner.fit(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.9169113 ,  2.29374051,  0.69522274, ..., -0.04836455,\n",
       "         0.15746017,  0.04329722],\n",
       "       [-0.9169113 ,  2.29374051,  0.69522274, ..., -0.04836455,\n",
       "         0.15746017,  0.04329722],\n",
       "       [-0.9169113 ,  2.29374051,  0.69522274, ..., -0.04836455,\n",
       "         0.15746017,  0.04329722],\n",
       "       ...,\n",
       "       [-0.9169113 ,  2.29374051,  0.69522274, ..., -0.04836455,\n",
       "         0.15746017,  0.04329722],\n",
       "       [-0.9169113 ,  2.29374051,  0.69522274, ..., -0.04836455,\n",
       "         0.15746017,  0.04329722],\n",
       "       [-0.9169113 ,  2.29374051,  0.69522274, ..., -0.04836455,\n",
       "         0.15746017,  0.04329722]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # deepAL+: cluster_idxs = cluster_learner.predict(embeddings)\n",
    "cluster_idxs = cluster_learner.predict(embeddings)\n",
    "    # deepAL+: centers = cluster_learner.cluster_centers_[cluster_idxs]\n",
    "centers = cluster_learner.cluster_centers_[cluster_idxs]\n",
    "centers # len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # deepAL+: dis = (embeddings - centers)**2\n",
    "dis = (embeddings - centers)**2\n",
    "dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "argmin(): Expected reduction dim to be specified for input.numel() == 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m dis \u001b[39m=\u001b[39m dis\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39m# deepAL+: q_idxs = np.array([np.arange(embeddings.shape[0])[cluster_idxs==i][dis[cluster_idxs==i].argmin()] for i in range(n)])\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m q_idxs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marange(embeddings\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])[cluster_idxs\u001b[39m==\u001b[39mi][dis[cluster_idxs\u001b[39m==\u001b[39mi]\u001b[39m.\u001b[39margmin()] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n)])\n\u001b[1;32m      6\u001b[0m \u001b[39m# deepAL+: return unlabeled_idxs[q_idxs]\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(unlabeled_idxs[q_idxs])\n",
      "Cell \u001b[0;32mIn[51], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m dis \u001b[39m=\u001b[39m dis\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39m# deepAL+: q_idxs = np.array([np.arange(embeddings.shape[0])[cluster_idxs==i][dis[cluster_idxs==i].argmin()] for i in range(n)])\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m q_idxs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marange(embeddings\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])[cluster_idxs\u001b[39m==\u001b[39mi][dis[cluster_idxs\u001b[39m==\u001b[39;49mi]\u001b[39m.\u001b[39;49margmin()] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n)])\n\u001b[1;32m      6\u001b[0m \u001b[39m# deepAL+: return unlabeled_idxs[q_idxs]\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(unlabeled_idxs[q_idxs])\n",
      "\u001b[0;31mIndexError\u001b[0m: argmin(): Expected reduction dim to be specified for input.numel() == 0."
     ]
    }
   ],
   "source": [
    "    # deepAL+: dis = dis.sum(axis=1)\n",
    "dis = dis.sum(axis=1)\n",
    "    # deepAL+: q_idxs = np.array([np.arange(embeddings.shape[0])[cluster_idxs==i][dis[cluster_idxs==i].argmin()] for i in range(n)])\n",
    "q_idxs = np.array([np.arange(embeddings.shape[0])[cluster_idxs==i][dis[cluster_idxs==i].argmin()] for i in range(n)])\n",
    "\n",
    "    # deepAL+: return unlabeled_idxs[q_idxs]\n",
    "print(unlabeled_idxs[q_idxs])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alqa",
   "language": "python",
   "name": "alqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6317ac8a4c65d05b4cf6bac76f72bfaae40b2e9380067c26c20c9afff1d8528e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
