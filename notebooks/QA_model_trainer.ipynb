{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering Model \n",
    "\n",
    "- dataset\n",
    "- torch\n",
    "- transformers\n",
    "- transformers[torch]\n",
    "- evaluate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mount/arbeitsdaten31/studenten1/linku/.venv/lib64/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DefaultDataCollator,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import torch\n",
    "\n",
    "import evaluate\n",
    "import collections\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set cache directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TRANSFORMERS_CACHE=/mount/arbeitsdaten31/studenten1/linku/cache\n",
      "env: HF_MODULES_CACHE=/mount/arbeitsdaten31/studenten1/linku/cache\n",
      "env: HF_DATASETS_CACHE=/mount/arbeitsdaten31/studenten1/linku/cache\n"
     ]
    }
   ],
   "source": [
    "model_dir = '/mount/arbeitsdaten31/studenten1/linku/models'\n",
    "CACHE_DIR='/mount/arbeitsdaten31/studenten1/linku/cache'\n",
    "%set_env TRANSFORMERS_CACHE $CACHE_DIR\n",
    "%set_env HF_MODULES_CACHE $CACHE_DIR\n",
    "%set_env HF_DATASETS_CACHE $CACHE_DIR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arguments.py\n",
    "\n",
    "args_input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_input_ALstrategy = 'MarginSampling'\n",
    "args_input_initseed = 100 # 1000\n",
    "args_input_quota = 100 # 1000\n",
    "args_input_batch = 35 # 128\n",
    "args_input_dataset_name = 'SQuAD'\n",
    "args_input_iteration = 1\n",
    "args_input_model_batch = 8 # already add in arguments.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad (/home/users1/linku/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n",
      "100%|██████████| 2/2 [00:00<00:00, 102.68it/s]\n"
     ]
    }
   ],
   "source": [
    "squad = load_dataset(args_input_dataset_name.lower())\n",
    "# squad[\"train\"] = squad[\"train\"].shuffle(42).select(range(2000))\n",
    "squad[\"train\"] = squad[\"train\"].select(range(3000))\n",
    "squad[\"validation\"] = squad[\"validation\"].select(range(1000))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will preprocess the dataset (training and evaluation data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_training_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs[\"offset_mapping\"]\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    example_ids = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        \n",
    "        example_ids.append(examples[\"id\"][sample_idx]) # newly added for used in unlabel data predict\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label is (0, 0)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_validation_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/users1/linku/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453/cache-2a9d31b0890526df.arrow\n",
      "Loading cached processed dataset at /home/users1/linku/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453/cache-0f087a92e258c27b.arrow\n"
     ]
    }
   ],
   "source": [
    "max_length = 384\n",
    "stride = 128\n",
    "\n",
    "# load tokenizer for dataset preprocessing\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# preprocess data\n",
    "train_dataset = squad[\"train\"].map(\n",
    "    preprocess_training_examples,\n",
    "    batched=True,\n",
    "    remove_columns=squad[\"train\"].column_names,\n",
    ")\n",
    "val_dataset = squad[\"validation\"].map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=squad[\"validation\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3074"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset['example_id']) # 10138 more than before tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_dataset['example_id'])) # 10000 same as before tokenizing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(start_logits, end_logits, val_dataset, examples):\n",
    "    \n",
    "    example_to_features = collections.defaultdict(list)\n",
    "    max_answer_length = 30\n",
    "    n_best = 20\n",
    "    for idx, feature in enumerate(val_dataset):\n",
    "        example_to_features[feature[\"example_id\"]].append(idx)\n",
    "\n",
    "    predicted_answers = []\n",
    "    for example in tqdm(examples):\n",
    "        example_id = example[\"id\"]\n",
    "        context = example[\"context\"]\n",
    "        answers = []\n",
    "\n",
    "        # Loop through all features associated with that example\n",
    "        for feature_index in example_to_features[example_id]:\n",
    "            start_logit = start_logits[feature_index]\n",
    "            end_logit = end_logits[feature_index]\n",
    "            offsets = val_dataset[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Skip answers that are not fully in the context\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                        continue\n",
    "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                    if (\n",
    "                        end_index < start_index\n",
    "                        or end_index - start_index + 1 > max_answer_length\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    answer = {\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "\n",
    "        # Select the answer with the best score\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            predicted_answers.append(\n",
    "                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n",
    "            )\n",
    "        else:\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
    "\n",
    "    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n",
    "    return metric.compute(predictions=predicted_answers, references=theoretical_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(trainer_qs, features, examples):\n",
    "    # thinking the posibility of get rid of 'examples'\n",
    "    preds, _, _ = trainer_qs.predict(features)\n",
    "    start_logits, end_logits = preds\n",
    "\n",
    "    prob_list_dict = []\n",
    "    example_to_features = collections.defaultdict(list)\n",
    "    max_answer_length = 30\n",
    "    n_best = 20 # TODO: if set n_best as 5, will it effect the time??\n",
    "    \n",
    "    for idx, feature in enumerate(features):\n",
    "        example_to_features[feature[\"example_id\"]].append(idx)\n",
    "\n",
    "    for example in tqdm(examples):\n",
    "        example_id = example[\"id\"]\n",
    "        # context = example[\"context\"]\n",
    "        answers = []\n",
    "        # Loop through all features associated with that example\n",
    "        for feature_index in example_to_features[example_id]:\n",
    "            start_logit = start_logits[feature_index]\n",
    "            end_logit = end_logits[feature_index]\n",
    "            offsets = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Skip answers that are not fully in the context\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                        continue\n",
    "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                    if (\n",
    "                        end_index < start_index\n",
    "                        or end_index - start_index + 1 > max_answer_length\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    answers.append(start_logit[start_index] + end_logit[end_index])\n",
    "        \n",
    "        if len(answers) > 1:\n",
    "            answers.sort(reverse=True)\n",
    "            # n_best_sorted_answers = answers[:n_best]\n",
    "            n_best_sorted_prob = softmax(answers)\n",
    "            prob_list_dict.append(\n",
    "                {'idx': example_to_features[example_id], \n",
    "                 'probs': n_best_sorted_prob}\n",
    "            )\n",
    "\n",
    "        elif example_to_features[example_id]:\n",
    "            prob_list_dict.append(\n",
    "                {'idx': example_to_features[example_id], \n",
    "                 'probs': np.array([0])}\n",
    "            )\n",
    "    \n",
    "    return prob_list_dict\n",
    "# move to evaluation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_dropout(trainer_qs, features, examples, n_drop=10):\n",
    "    prob_dict = {}\n",
    "    for i in range(n_drop):\n",
    "        preds, _, _ = trainer_qs.predict(features)\n",
    "        start_logits, end_logits = preds\n",
    "\n",
    "        example_to_features = collections.defaultdict(list)\n",
    "        max_answer_length = 30\n",
    "        n_best = 20\n",
    "            \n",
    "        for idx, feature in enumerate(features):\n",
    "            example_to_features[feature[\"example_id\"]].append(idx)\n",
    "\n",
    "        for example in tqdm(examples):\n",
    "            example_id = example[\"id\"]\n",
    "            # context = example[\"context\"]\n",
    "            answers = []\n",
    "\n",
    "            # Loop through all features associated with that example\n",
    "            for feature_index in example_to_features[example_id]:\n",
    "                start_logit = start_logits[feature_index]\n",
    "                end_logit = end_logits[feature_index]\n",
    "                offsets = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "                start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "                end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "                for start_index in start_indexes:\n",
    "                    for end_index in end_indexes:\n",
    "                        # Skip answers that are not fully in the context\n",
    "                        if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                            continue\n",
    "                        # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                        if (\n",
    "                            end_index < start_index\n",
    "                            or end_index - start_index + 1 > max_answer_length\n",
    "                        ):\n",
    "                            continue\n",
    "\n",
    "                        answers.append(start_logit[start_index] + end_logit[end_index])\n",
    "            \n",
    "            if len(answers) > 1:\n",
    "                if example_to_features[example_id] not in prob_dict:\n",
    "                    prob_dict[example_to_features[example_id]] = softmax(answers)\n",
    "                else:\n",
    "                    prob_dict[example_to_features[example_id]] += softmax(answers)\n",
    "            elif example_to_features[example_id] and example_to_features[example_id] not in prob_dict:\n",
    "                prob_dict[example_to_features[example_id]] = np.array([0])\n",
    "\n",
    "    for key in prob_dict.keys():\n",
    "        prob_dict[key] /= n_drop\n",
    "    return prob_dict\n",
    "# move to evaluation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = np.array([0])\n",
    "np.append(ans, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "d[0] = np.array([0.1, 0.02, 0.03])\n",
    "d[1] = np.array([0.8, 0.7, 0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0.3 , 0.15, 0.21]), 1: array([0.8, 0.7, 0.6])}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0] += np.array([0.2, 0.13, 0.18])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0.15 , 0.075, 0.105]), 1: array([0.4 , 0.35, 0.3 ])}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k in d.keys():\n",
    "    d[k] /= 2\n",
    "d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unlabel_data(n_pool, labeled_idxs, train_dataset):\n",
    "    unlabeled_idxs = np.arange(n_pool)[~labeled_idxs]\n",
    "    unlabeled_data = train_dataset.select(indices=unlabeled_idxs)\n",
    "    return unlabeled_idxs, unlabeled_data\n",
    "\n",
    "# move to utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x): \n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "# move to utils.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling_query(labeled_idxs, n):\n",
    "    return np.random.choice(np.where(labeled_idxs==0)[0], n, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_sampling_query(n_pool, labeled_idxs, train_dataset, trainer_qs, example, n):\n",
    "    # deepAL+: unlabeled_idxs, unlabeled_data = self.dataset.get_unlabeled_data()\n",
    "    unlabeled_idxs, unlabeled_data = get_unlabel_data(n_pool, labeled_idxs, train_dataset)\n",
    "    \n",
    "    # deepAL+: probs = self.predict_prob(unlabeled_data)\n",
    "    prob_list_dict = get_prob(trainer_qs, unlabeled_data, example)\n",
    "    \n",
    "    # deepAL+: probs_sorted, _ = probs.sort(descending=True)\n",
    "    # deepAL+: uncertainties = probs_sorted[:, 0] - probs_sorted[:,1]\n",
    "    uncertainties_list_dict = []\n",
    "    for d in prob_list_dict:\n",
    "        if len(d['probs']) > 1: # if prob_dict['probs'] is not 0\n",
    "            uncertainties = d['probs'][0] - d['probs'][1]\n",
    "            uncertainties_list_dict.append(\n",
    "                {'idx': d['idx'], \n",
    "                 'uncertainties': uncertainties}\n",
    "                 )\n",
    "        elif d['idx']:\n",
    "            uncertainties_list_dict.append(\n",
    "                {'idx': d['idx'], \n",
    "                 'uncertainties': np.array([0])}\n",
    "                 )\n",
    "    \n",
    "    # deepAL+: return unlabeled_idxs[uncertainties.sort()[1][:n]]   \n",
    "    sorted_uncertainties_dict = sorted(uncertainties_list_dict, key=lambda d: d['uncertainties']) \n",
    "    \n",
    "    return unlabeled_idxs[[uncertainties_dict['idx'][0] for uncertainties_dict in sorted_uncertainties_dict[:n]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_confidence_query(n_pool, labeled_idxs, train_dataset, trainer_qs, example, n):\n",
    "    # deepAL+: unlabeled_idxs, unlabeled_data = self.dataset.get_unlabeled_data()\n",
    "    unlabeled_idxs, unlabeled_data = get_unlabel_data(n_pool, labeled_idxs, train_dataset)\n",
    "    \n",
    "    # deepAL+: probs = self.predict_prob(unlabeled_data)\n",
    "    prob_list_dict = get_prob(trainer_qs, unlabeled_data, example)\n",
    "    \n",
    "    # deepAL+: uncertainties = probs.max(1)[0]\n",
    "    confidence_list_dict = []\n",
    "    for d in prob_list_dict:\n",
    "        if len(d['probs']) > 1: # if prob_dict['probs'] is not 0\n",
    "            confidence = max(d['probs'])\n",
    "            confidence_list_dict.append(\n",
    "                {'idx': d['idx'], \n",
    "                    'confidence': confidence}\n",
    "                    )\n",
    "        elif d['idx']:\n",
    "            confidence_list_dict.append(\n",
    "                {'idx': d['idx'], \n",
    "                    'confidence': np.array([0])}\n",
    "                    )\n",
    "    # deepAL+: return unlabeled_idxs[uncertainties.sort()[1][:n]]\n",
    "    sorted_confidence_dict = sorted(confidence_list_dict, key=lambda d: d['confidence'])   \n",
    "    return unlabeled_idxs[[confidence_dict['idx'][0] for confidence_dict in sorted_confidence_dict[:n]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_ratio_query(n_pool, labeled_idxs, train_dataset, trainer_qs, example, n):\n",
    "    # deepAL+: unlabeled_idxs, unlabeled_data = self.dataset.get_unlabeled_data()\n",
    "    unlabeled_idxs, unlabeled_data = get_unlabel_data(n_pool, labeled_idxs, train_dataset)\n",
    "    \n",
    "    # deepAL+: probs = self.predict_prob(unlabeled_data)\n",
    "    prob_list_dict = get_prob(trainer_qs, unlabeled_data, example)\n",
    "    \n",
    "    # deepAL+: preds = torch.max(probs, 1)[0]\n",
    "    # deepAL+: uncertainties = 1.0 - preds\n",
    "    confidence_list_dict = []\n",
    "    for d in prob_list_dict:\n",
    "        if len(d['probs']) > 1: # if prob_dict['probs'] is not 0\n",
    "            confidence = max(d['probs'])\n",
    "            confidence_list_dict.append(\n",
    "                {'idx': d['idx'], \n",
    "                    'confidence': 1 - confidence}\n",
    "                    )\n",
    "        elif d['idx']:\n",
    "            confidence_list_dict.append(\n",
    "                {'idx': d['idx'], \n",
    "                    'confidence': np.array([0])}\n",
    "                    )\n",
    "\n",
    "    # deepAL+: return unlabeled_idxs[uncertainties.sort(descending=True)[1][:n]]\n",
    "    sorted_confidence_dict = sorted(confidence_list_dict, key=lambda d: d['confidence'], reverse=True)\n",
    "    return unlabeled_idxs[[confidence_dict['idx'][0] for confidence_dict in sorted_confidence_dict[:n]]]\n",
    "# comment for the same query as LC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_query(n_pool, labeled_idxs, train_dataset, trainer_qs, example, n):\n",
    "    # deepAL+: unlabeled_idxs, unlabeled_data = self.dataset.get_unlabeled_data()\n",
    "    unlabeled_idxs, unlabeled_data = get_unlabel_data(n_pool, labeled_idxs, train_dataset)\n",
    "    \n",
    "    # deepAL+: probs = self.predict_prob(unlabeled_data)\n",
    "    prob_list_dict = get_prob(trainer_qs, unlabeled_data, example)\n",
    "    \n",
    "    # deepAL+: log_probs = torch.log(probs)\n",
    "    # deepAL+: uncertainties = (probs*log_probs).sum(1)\n",
    "    entropy_list_dict = []\n",
    "    for d in prob_list_dict:\n",
    "        if len(d['probs']) > 1: # if prob_dict['probs'] is not 0\n",
    "            log_probs = np.log(d['probs'])\n",
    "            entropy_list_dict.append(\n",
    "                {'idx': d['idx'], \n",
    "                'entropy': (d['probs']*log_probs).sum()}\n",
    "                )\n",
    "        elif d['idx']:\n",
    "            entropy_list_dict.append(\n",
    "                {'idx': d['idx'], \n",
    "                'entropy': np.array([0])}\n",
    "                )\n",
    "    # deepAL+: return unlabeled_idxs[uncertainties.sort()[1][:n]] # use smallest Entropy\n",
    "    sorted_entropy_dict = sorted(entropy_list_dict, key=lambda d: d['entropy'], reverse=True) # use largest Entropy, different from deepAL+\n",
    "    return unlabeled_idxs[[entropy_dict['idx'][0] for entropy_dict in sorted_entropy_dict[:n]]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_QUERY = args_input_batch\n",
    "NUM_INIT_LB = args_input_initseed\n",
    "NUM_ROUND = int(args_input_quota / args_input_batch)\n",
    "DATA_NAME = args_input_dataset_name\n",
    "STRATEGY_NAME = args_input_ALstrategy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seed and device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 4666\n",
    "# os.environ['TORCH_HOME']='./basicmodel'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(3)\n",
    "\n",
    "# fix random seed\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "# torch.backends.cudnn.enabled  = True\n",
    "# torch.backends.cudnn.benchmark= True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = args_input_iteration\n",
    "model_batch = args_input_model_batch\n",
    "\n",
    "all_acc = []\n",
    "acq_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQuAD\n",
      "MarginSampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mount/arbeitsdaten31/studenten1/linku/.venv/lib64/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 251.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# repeate # iteration trials\n",
    "while (iteration > 0): \n",
    "\titeration = iteration - 1\n",
    "\n",
    "\t## data, network, strategy\n",
    "\tnet = AutoModelForQuestionAnswering.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "\n",
    "\t## set up training\n",
    "\ttraining_args = TrainingArguments(\n",
    "\t\toutput_dir=model_dir,\n",
    "\t\tevaluation_strategy=\"no\",\n",
    "\t\teval_steps=100,\n",
    "\t\tlogging_steps=100,\n",
    "\t\tlearning_rate=1e-4,\n",
    "\t\tper_device_train_batch_size=model_batch,\n",
    "\t\tper_device_eval_batch_size=model_batch, \n",
    "\t\tgradient_accumulation_steps=1,\n",
    "\t\tnum_train_epochs=3,  # max_steps will override this value\n",
    "\t\t# max_steps=1000,  # comment out if this is not wanted\n",
    "\t\tweight_decay=0.01,\n",
    "\t\treport_to=\"none\",\n",
    "\t)\n",
    "\n",
    "\t## data collator for batching\n",
    "\tdata_collator = DefaultDataCollator()\n",
    "\n",
    "\tstart = datetime.datetime.now()\n",
    "\n",
    "\t## generate initial labeled pool\n",
    "\tn_pool = len(train_dataset)\n",
    "\tlabeled_idxs = np.zeros(n_pool, dtype=bool)\n",
    "\n",
    "\ttmp_idxs = np.arange(n_pool)\n",
    "\tnp.random.shuffle(tmp_idxs)\n",
    "\tlabeled_idxs[tmp_idxs[:args_input_initseed]] = True\n",
    "\n",
    "\trun_0_labeled_idxs = np.arange(n_pool)[labeled_idxs] \n",
    "\t\n",
    "\t## record acc performance \n",
    "\tacc = np.zeros(NUM_ROUND + 1) # build 3 runs + run_0 # origin 10 runs + run_0\n",
    "\n",
    "\t## the actual trainer which performs training and evaluation\n",
    "\ttrainer_0 = Trainer(\n",
    "\t\t\t\t\t\tmodel=net,\n",
    "\t\t\t\t\t\targs=training_args,\n",
    "\t\t\t\t\t\ttrain_dataset=train_dataset.select(indices=run_0_labeled_idxs),\n",
    "\t\t\t\t\t\teval_dataset=val_dataset,\n",
    "\t\t\t\t\t\ttokenizer=tokenizer,\n",
    "\t\t\t\t\t\tdata_collator=data_collator\n",
    "\t\t\t\t\t\t)\t\n",
    "\t\t\n",
    "\t## print info\n",
    "\tprint(DATA_NAME)\n",
    "\t# print('RANDOM SEED {}'.format(SEED))\n",
    "\tprint(STRATEGY_NAME) # print(type(strategy).__name__)\n",
    "\t\n",
    "\t## round 0 accuracy \n",
    "\ttrainer_0.train() # already update to main.py\n",
    "\tmodel_saved_dir = model_dir + '/train_bert_squad_0'\n",
    "\ttrainer_0.save_model(model_saved_dir)\n",
    "\n",
    "\tpreds, _, _ = trainer_0.predict(val_dataset)\n",
    "\tstart_logits, end_logits = preds\n",
    "\tacc[0] = compute_metrics(start_logits, end_logits, val_dataset, squad[\"validation\"])['exact_match']\n",
    "\n",
    "\ttrainer_qs = trainer_0\n",
    "\n",
    "\t# print('Round 0\\ntesting accuracy {}'.format(acc[0]))\n",
    "\t# print('\\n')\n",
    "\t\n",
    "\t# ## round 1 to rd\n",
    "\t# for rd in range(1, NUM_ROUND+1):\n",
    "\t# \tprint('Round {}'.format(rd))\n",
    "\t\t\n",
    "\t# \t## query\n",
    "\t# \tif STRATEGY_NAME == 'RandomSampling':\n",
    "\t# \t\tq_idxs = random_sampling_query(labeled_idxs)\n",
    "\t# \telif STRATEGY_NAME == 'MarginSampling':\n",
    "\t# \t\tq_idxs = margin_sampling_query(n_pool, labeled_idxs, train_dataset, trainer_qs, squad['train'])\n",
    "\t# \telif STRATEGY_NAME == 'LeastConfidence':\n",
    "\t# \t\tq_idxs = least_confidence_query(n_pool, labeled_idxs, train_dataset, trainer_qs, squad['train'])\n",
    "\t# \telif STRATEGY_NAME == 'EntropySampling':\n",
    "\t# \t\tq_idxs = entropy_query()\n",
    "\t# \telif STRATEGY_NAME == 'MarginSamplingDropout':\n",
    "\t# \t\tq_idxs = margin_sampling_dropout_query()\n",
    "\t# \telif STRATEGY_NAME == 'LeastConfidenceDropout':\n",
    "\t# \t\tq_idxs = least_confidence_dropout_query()\n",
    "\t# \telif STRATEGY_NAME == 'EntropySamplingDropout':\n",
    "\t# \t\tq_idxs = entropy_dropout_query()\n",
    "\t# \telif STRATEGY_NAME == 'VarRatio':\n",
    "\t# \t\tq_idxs = var_ratio_query(n_pool, labeled_idxs, train_dataset, trainer_qs, squad['train'])\n",
    "\t# \telif STRATEGY_NAME == 'KMeansSampling':\n",
    "\t# \t\tq_idxs = kmeans_query()\n",
    "\t# \telif STRATEGY_NAME == 'KCenterGreedy':\n",
    "\t# \t\tq_idxs = kcenter_query()\n",
    "\t# \t# elif STRATEGY_NAME == 'KCenterGreedyPCA': # not sure\n",
    "\t# \t# \tq_idxs = \n",
    "\t# \telif STRATEGY_NAME == 'BALDDropout':\n",
    "\t# \t\tq_idxs = bayesian_query()\n",
    "\t# \telif STRATEGY_NAME == 'MeanSTD':\n",
    "\t# \t\tq_idxs = mean_std_query()\n",
    "\t# \telif STRATEGY_NAME == 'BadgeSampling':\n",
    "\t# \t\tq_idxs = badge_query()\n",
    "\t# \telif STRATEGY_NAME == 'LossPredictionLoss':\n",
    "\t# \t\t# different net!\n",
    "\t# \t\tq_idxs = loss_prediction_query()\n",
    "\t# \telif STRATEGY_NAME == 'CEALSampling':\n",
    "\t# \t\t# why use 'CEALSampling' in STRATEGY_NAME\n",
    "\t# \t\tq_idxs = ceal_query()\n",
    "\t# \telse:\n",
    "\t# \t\traise NotImplementedError\n",
    "\t\n",
    "\t# \t## update\n",
    "\t# \tlabeled_idxs[q_idxs] = True\n",
    "\t# \trun_rd_labeled_idxs = np.arange(n_pool)[labeled_idxs]\n",
    "\t# \tprint('run_rd_labeled_idxs', len(run_rd_labeled_idxs))\n",
    "\n",
    "\t# \ttrainer_rd = Trainer(\n",
    "\t# \t\t\t\t\tmodel=AutoModelForQuestionAnswering.from_pretrained(model_saved_dir).to(device),\n",
    "\t# \t\t\t\t\targs=training_args,\n",
    "\t# \t\t\t\t\ttrain_dataset=train_dataset.select(indices=run_rd_labeled_idxs),\n",
    "\t# \t\t\t\t\teval_dataset=val_dataset,\n",
    "\t# \t\t\t\t\ttokenizer=tokenizer,\n",
    "\t# \t\t\t\t\tdata_collator=data_collator\n",
    "\t# \t\t\t\t\t)\n",
    "\n",
    "\t# \t## train # already update to main.py\n",
    "\t# \ttrainer_rd.train()\n",
    "\t# \tmodel_saved_dir = 'train_bert_squad_' + rd\n",
    "\t# \ttrainer_rd.save_model(model_saved_dir)\n",
    "\n",
    "\t# \ttrainer_qs = trainer_rd\n",
    "\t\n",
    "\t# \t## round rd accuracy\n",
    "\t# \tpreds, _, _ = trainer_rd.predict(val_dataset)\n",
    "\t# \tstart_logits, end_logits = preds\n",
    "\t# \tacc[rd] = compute_metrics(start_logits, end_logits, val_dataset, squad[\"validation\"])['exact_match']\n",
    "\t# \tprint('testing accuracy {}'.format(acc[rd]))\n",
    "\t# \tprint('\\n')\n",
    "\n",
    "\t# \ttorch.cuda.empty_cache()\n",
    "\t\n",
    "\t# ## print results\n",
    "\t# print('SEED {}'.format(SEED))\n",
    "\t# print(STRATEGY_NAME)\n",
    "\t# print(acc)\n",
    "\t# all_acc.append(acc)\n",
    "\t\n",
    "\t# ## save model\n",
    "\t# timestamp = re.sub('\\.[0-9]*','_',str(datetime.datetime.now())).replace(\" \", \"_\").replace(\"-\", \"\").replace(\":\",\"\")\n",
    "\t# model_path = './modelpara/' + timestamp + DATA_NAME+ '_'  + STRATEGY_NAME + '_' + str(NUM_QUERY) + '_' + str(NUM_INIT_LB) +  '_' + str(args_input_quota)  +'.params'\n",
    "\t# end = datetime.datetime.now()\n",
    "\t# acq_time.append(round(float((end - start).seconds), 3))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## query workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_qs = trainer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2974"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unlable data\n",
    "unlabeled_idxs = np.arange(n_pool)[~labeled_idxs]\n",
    "unlabeled_data = train_dataset.select(indices=unlabeled_idxs)\n",
    "len(unlabeled_idxs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test: query 5 data from 20 unlabeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# smaller data\n",
    "unlabeled_idxs_20 = unlabeled_idxs[20:40]\n",
    "unlabeled_data_20 = train_dataset.select(unlabeled_idxs_20)\n",
    "len(unlabeled_data_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37,\n",
       "       38, 39, 40])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_idxs_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(unlabeled_idxs_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 5851.62it/s]\n"
     ]
    }
   ],
   "source": [
    "probs_list_dict_20 = get_prob(trainer_qs, unlabeled_data_20, squad['train'])\n",
    "# len(probs_list_dict_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_dropout(trainer_qs, features, examples, n_drop=5):\n",
    "    prob_dict = {}\n",
    "    for_check = []\n",
    "    \n",
    "    for i in range(n_drop):\n",
    "        preds, _, _ = trainer_qs.predict(features)\n",
    "        start_logits, end_logits = preds\n",
    "\n",
    "        example_to_features = collections.defaultdict(list)\n",
    "        max_answer_length = 30\n",
    "        n_best = 20\n",
    "            \n",
    "        for idx, feature in enumerate(features):\n",
    "            example_to_features[feature[\"example_id\"]].append(idx)\n",
    "\n",
    "        n = 0\n",
    "        for example in tqdm(examples):\n",
    "            example_id = example[\"id\"]\n",
    "            # context = example[\"context\"]\n",
    "            answers = []\n",
    "\n",
    "            # Loop through all features associated with that example\n",
    "            for feature_index in example_to_features[example_id]:\n",
    "                start_logit = start_logits[feature_index]\n",
    "                end_logit = end_logits[feature_index]\n",
    "                offsets = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "                start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "                end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "                for start_index in start_indexes:\n",
    "                    for end_index in end_indexes:\n",
    "                        # Skip answers that are not fully in the context\n",
    "                        if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                            continue\n",
    "                        # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                        if (\n",
    "                            end_index < start_index\n",
    "                            or end_index - start_index + 1 > max_answer_length\n",
    "                        ):\n",
    "                            continue\n",
    "\n",
    "                        answers.append(start_logit[start_index] + end_logit[end_index])\n",
    "\n",
    "            if len(answers) > 1:\n",
    "                if example_to_features[example_id][0] not in prob_dict:\n",
    "                    prob_dict[example_to_features[example_id][0]] = softmax(answers)\n",
    "\n",
    "                else:\n",
    "                    prob_dict[example_to_features[example_id][0]] += softmax(answers)\n",
    "            elif example_to_features[example_id] != []:\n",
    "                if example_to_features[example_id][0] not in prob_dict:\n",
    "                    prob_dict[example_to_features[example_id][0]] = np.array([0])\n",
    "            if n == 0 and len(softmax(answers)) > 1:\n",
    "                for_check.append(answers[:5])\n",
    "                n += 1      \n",
    "\n",
    "    for key in prob_dict.keys():\n",
    "        prob_dict[key] /= n_drop\n",
    "    return prob_dict, for_check\n",
    "# move to evaluation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 5734.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 5820.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 5825.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 6011.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 5953.54it/s]\n"
     ]
    }
   ],
   "source": [
    "probs_list_dict_20_dropout, for_check = get_prob_dropout(trainer_qs, unlabeled_data_20, squad['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.8517385, 4.0963006, 4.0622125, 5.072318, 4.9641094],\n",
       " [5.8517385, 4.0963006, 4.0622125, 5.072318, 4.9641094],\n",
       " [5.8517385, 4.0963006, 4.0622125, 5.072318, 4.9641094],\n",
       " [5.8517385, 4.0963006, 4.0622125, 5.072318, 4.9641094],\n",
       " [5.8517385, 4.0963006, 4.0622125, 5.072318, 4.9641094]]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_check\n",
    "# the prediction are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0.09048778, 0.01563914, 0.01511502, 0.04150419, 0.03724753,\n",
       "        0.02748025, 0.02079083, 0.01467046, 0.01446176, 0.0141665 ,\n",
       "        0.01355814, 0.01209789, 0.01193168, 0.01174672, 0.01135304,\n",
       "        0.05076183, 0.03866458, 0.0244996 , 0.01414402, 0.01388623,\n",
       "        0.0072037 , 0.00657532, 0.02396834, 0.01699181, 0.01383731,\n",
       "        0.01358511, 0.01215176, 0.02045504, 0.0150912 , 0.00805651,\n",
       "        0.00794189, 0.00777975, 0.01967757, 0.00775029, 0.00764003,\n",
       "        0.02599083, 0.01646894, 0.00950779, 0.0093345 , 0.00834963,\n",
       "        0.00442002, 0.02166077, 0.01649871, 0.00307392, 0.00280578,\n",
       "        0.01611677, 0.01227592, 0.00228716, 0.00208765, 0.01525799,\n",
       "        0.0116218 , 0.00736409, 0.00216529, 0.00197641, 0.00402448,\n",
       "        0.00262445, 0.00258839, 0.00254827, 0.00246287, 0.00273657,\n",
       "        0.0060964 , 0.00547115, 0.00403647, 0.00305389, 0.00215489,\n",
       "        0.00212424, 0.00208086, 0.0110093 , 0.00838564, 0.00531351,\n",
       "        0.00301167, 0.00156235, 0.00142607, 0.00460301, 0.0032632 ,\n",
       "        0.00265739, 0.00260896, 0.00233369, 0.00302047, 0.00245973,\n",
       "        0.0024149 , 0.00216011, 0.00811123, 0.00617821, 0.00115108,\n",
       "        0.00142347, 0.0014014 , 0.00135444, 0.00395668, 0.00291913,\n",
       "        0.00155839, 0.00153622], dtype=float32),\n",
       " 1: array([0.08637714, 0.05672275, 0.04606516, 0.04116594, 0.03513036,\n",
       "        0.01787195, 0.07856173, 0.01385441, 0.01247181, 0.01220701,\n",
       "        0.01143543, 0.0109888 , 0.03146222, 0.02811608, 0.02399382,\n",
       "        0.01881838, 0.01531635, 0.01220643, 0.00788441, 0.02284375,\n",
       "        0.01681929, 0.01185729, 0.00867944, 0.00775221, 0.00732288,\n",
       "        0.02502342, 0.02032179, 0.01816049, 0.01549786, 0.009893  ,\n",
       "        0.00788427, 0.00509262, 0.02751385, 0.01806799, 0.01311265,\n",
       "        0.01119013, 0.00569278, 0.0106815 , 0.00405842, 0.00326853,\n",
       "        0.00794582, 0.00412436, 0.003019  , 0.00254714, 0.00243141,\n",
       "        0.01486621, 0.00976245, 0.00185639, 0.0022579 , 0.00211518,\n",
       "        0.00203257, 0.00193231, 0.01242422, 0.00815883, 0.01172456,\n",
       "        0.00769937, 0.00476848, 0.00578198, 0.00516704, 0.00440947,\n",
       "        0.00345835, 0.00281477, 0.00224324, 0.00144896, 0.00175873,\n",
       "        0.00141643, 0.00430828, 0.00385007, 0.00257689, 0.00209734,\n",
       "        0.00167149, 0.00107965, 0.00128192, 0.00120089, 0.00115399,\n",
       "        0.00698274, 0.00458548, 0.00293203, 0.00215878, 0.0015219 ,\n",
       "        0.00111402, 0.00099501, 0.0009399 ], dtype=float32),\n",
       " 2: array([0.09445281, 0.02002779, 0.01886882, 0.01252503, 0.01180023,\n",
       "        0.01130694, 0.00924749, 0.05229262, 0.0494432 , 0.02864361,\n",
       "        0.02361058, 0.02009769, 0.01220322, 0.00950888, 0.02562434,\n",
       "        0.02310612, 0.01564762, 0.01128119, 0.00861059, 0.00845623,\n",
       "        0.00796586, 0.02691789, 0.0221881 , 0.01943306, 0.01888685,\n",
       "        0.01326493, 0.03297451, 0.03117773, 0.00769506, 0.00599608,\n",
       "        0.02699113, 0.01563661, 0.01288906, 0.01097137, 0.0077056 ,\n",
       "        0.00519092, 0.01096594, 0.00368491, 0.01873863, 0.01771757,\n",
       "        0.00437292, 0.00340743, 0.00937281, 0.00572355, 0.00314956,\n",
       "        0.0030931 , 0.01535594, 0.01451918, 0.00841131, 0.00358352,\n",
       "        0.00279232, 0.0067815 , 0.00593946, 0.00577252, 0.00560947,\n",
       "        0.00405426, 0.01250782, 0.01182626, 0.00685123, 0.00564739,\n",
       "        0.00291887, 0.00227442, 0.00275415, 0.00263402, 0.0024816 ,\n",
       "        0.00237786, 0.00194476, 0.00154181, 0.00437795, 0.00360869,\n",
       "        0.00316061, 0.00307177, 0.00215742, 0.00719763, 0.00680543,\n",
       "        0.00167967, 0.00323829, 0.0028362 , 0.00275648, 0.00267862,\n",
       "        0.00193598, 0.00360612, 0.00325173, 0.0022021 , 0.00158761,\n",
       "        0.00121177, 0.00119005], dtype=float32),\n",
       " 3: array([0.15088388, 0.0211699 , 0.01953864, 0.01222424, 0.01131223,\n",
       "        0.01128231, 0.01045567, 0.02401301, 0.01939776, 0.01385865,\n",
       "        0.01183326, 0.01054758, 0.0090808 , 0.06915317, 0.0432624 ,\n",
       "        0.01970579, 0.0173837 , 0.01563137, 0.01270965, 0.01020054,\n",
       "        0.01952429, 0.01865333, 0.01645525, 0.01479651, 0.01350691,\n",
       "        0.02934928, 0.01336844, 0.01179313, 0.01060435, 0.00968012,\n",
       "        0.00692006, 0.03883892, 0.02429774, 0.0071382 , 0.00572899,\n",
       "        0.00768246, 0.00417735, 0.00352484, 0.02842225, 0.01778103,\n",
       "        0.00522372, 0.00419247, 0.00601736, 0.00429908, 0.00327195,\n",
       "        0.00276087, 0.00290412, 0.00260558, 0.00241118, 0.0024048 ,\n",
       "        0.00222861, 0.01643307, 0.01028057, 0.00468275, 0.00302023,\n",
       "        0.00242398, 0.00192372, 0.00162323, 0.01326981, 0.00830162,\n",
       "        0.00378135, 0.00299951, 0.00243886, 0.00195738, 0.01286226,\n",
       "        0.00804667, 0.00236395, 0.00142413, 0.00350775, 0.00335127,\n",
       "        0.00295637, 0.00265836, 0.00242667, 0.00348545, 0.00281556,\n",
       "        0.00201156, 0.00171758, 0.00153097, 0.00144665, 0.00133872,\n",
       "        0.00133518, 0.0088799 , 0.00555529, 0.00163204, 0.00130984],\n",
       "       dtype=float32),\n",
       " 4: array([0.08991415, 0.07934231, 0.06998449, 0.06901853, 0.02976787,\n",
       "        0.0122225 , 0.07087391, 0.01962233, 0.01346424, 0.06645869,\n",
       "        0.04590575, 0.0357306 , 0.03523743, 0.01270957, 0.03538288,\n",
       "        0.03120974, 0.03077898, 0.01327506, 0.00545065, 0.00525923,\n",
       "        0.00451993, 0.01146184, 0.00432019, 0.0040565 , 0.00333253,\n",
       "        0.00302752, 0.02483011, 0.00192985, 0.01713152, 0.01333427,\n",
       "        0.00474308, 0.01512261, 0.01177063, 0.01160818, 0.00500664,\n",
       "        0.00418688, 0.00312551, 0.00212541, 0.00199568, 0.00163951,\n",
       "        0.00148945, 0.0014062 , 0.0172757 , 0.00298439, 0.00134271,\n",
       "        0.01513791, 0.00261509, 0.00137176, 0.00124621, 0.00117655,\n",
       "        0.00208021, 0.0017453 , 0.00259104, 0.000917  , 0.00536244,\n",
       "        0.00148466, 0.00502628, 0.0044353 , 0.00391219, 0.0038582 ,\n",
       "        0.00166405], dtype=float32),\n",
       " 5: array([0.08895899, 0.08334685, 0.05614651, 0.04510506, 0.02915882,\n",
       "        0.01108536, 0.00875953, 0.07378616, 0.02633681, 0.00726551,\n",
       "        0.11640741, 0.01929584, 0.04146025, 0.02792966, 0.02243717,\n",
       "        0.01450484, 0.00698997, 0.00551433, 0.00454963, 0.00435736,\n",
       "        0.03421194, 0.02159288, 0.01734655, 0.01221141, 0.00336875,\n",
       "        0.00869318, 0.0041605 , 0.00306984, 0.00243881, 0.01643229,\n",
       "        0.01037125, 0.0083317 , 0.00586525, 0.00538615, 0.00161804,\n",
       "        0.01447321, 0.00913479, 0.00516599, 0.00142514, 0.02284571,\n",
       "        0.01159429, 0.00781048, 0.00627451, 0.00405625, 0.00195473,\n",
       "        0.00155276, 0.00154207, 0.0012723 , 0.0213636 , 0.00260759,\n",
       "        0.0167479 , 0.00204421, 0.00103222, 0.00294715, 0.00253215,\n",
       "        0.00148699, 0.00128092, 0.00094513, 0.00075085, 0.00567046,\n",
       "        0.00202398, 0.00096999], dtype=float32),\n",
       " 6: array([0.08673108, 0.06814831, 0.06803267, 0.06784814, 0.0292767 ,\n",
       "        0.01051437, 0.07470978, 0.02023803, 0.01371531, 0.03510397,\n",
       "        0.0350444 , 0.03494936, 0.01508078, 0.00790404, 0.00541608,\n",
       "        0.00533327, 0.06410837, 0.04393361, 0.0345205 , 0.03446192,\n",
       "        0.01190112, 0.03656653, 0.00324452, 0.00908665, 0.00535492,\n",
       "        0.00292735, 0.00265112, 0.00259616, 0.01634137, 0.01284011,\n",
       "        0.01281832, 0.00551615, 0.00442669, 0.01573325, 0.01236229,\n",
       "        0.00426196, 0.01554531, 0.0032301 , 0.00137932, 0.00124742,\n",
       "        0.00122156, 0.00322896, 0.00251874, 0.00137884, 0.00137691,\n",
       "        0.00124698, 0.00122113, 0.01549304, 0.00321924, 0.00137469,\n",
       "        0.00779055, 0.00336165, 0.00176189, 0.00160889, 0.0012073 ,\n",
       "        0.00120297, 0.00118884, 0.00228556, 0.00171756, 0.00230709,\n",
       "        0.00135961, 0.00537148, 0.00145507], dtype=float32),\n",
       " 7: array([0.08548807, 0.08426452, 0.06687707, 0.06596337, 0.02593878,\n",
       "        0.01175526, 0.06710857, 0.01697358, 0.00694848, 0.06786106,\n",
       "        0.01171937, 0.04194986, 0.03329377, 0.03283889, 0.01061026,\n",
       "        0.03785712, 0.02961551, 0.02921088, 0.0114866 , 0.00648981,\n",
       "        0.00520564, 0.04278431, 0.00420805, 0.00860271, 0.00494587,\n",
       "        0.0030941 , 0.0029713 , 0.00293359, 0.01675236, 0.01329562,\n",
       "        0.01311397, 0.00515681, 0.00423713, 0.01582433, 0.01255909,\n",
       "        0.0040024 , 0.01814641, 0.00399909, 0.00178479, 0.0016925 ,\n",
       "        0.00167421, 0.00167102, 0.01588313, 0.00350031, 0.00156219,\n",
       "        0.00146539, 0.00262018, 0.00184584, 0.00116938, 0.00115475,\n",
       "        0.00110892, 0.00109693, 0.00109484, 0.00196623, 0.00194764,\n",
       "        0.00086923, 0.00085835, 0.00082428, 0.00081537, 0.00081382,\n",
       "        0.00543783, 0.00137537, 0.00132667, 0.00477682, 0.00470845,\n",
       "        0.00373689, 0.00368583, 0.00144938], dtype=float32),\n",
       " 8: array([0.05208046, 0.02387594, 0.02117902, 0.01811941, 0.01534667,\n",
       "        0.10134436, 0.04775461, 0.04486981, 0.04452572, 0.02113624,\n",
       "        0.01664973, 0.01351721, 0.02225229, 0.02178987, 0.01736018,\n",
       "        0.01469004, 0.03882214, 0.02488537, 0.01140853, 0.01011987,\n",
       "        0.00865791, 0.00733303, 0.01129158, 0.01103387, 0.01001613,\n",
       "        0.0072841 , 0.02452254, 0.00699771, 0.00530313, 0.00470152,\n",
       "        0.01386608, 0.00888829, 0.00309234, 0.00299862, 0.00265844,\n",
       "        0.01764975, 0.00831676, 0.00394586, 0.00368101, 0.00235411,\n",
       "        0.00812512, 0.00385494, 0.00292142, 0.00229986, 0.01329627,\n",
       "        0.00852303, 0.00296526, 0.00254919, 0.01492123, 0.00703106,\n",
       "        0.00333586, 0.00311195, 0.00199018, 0.00332009, 0.0032511 ,\n",
       "        0.00259018, 0.00219179, 0.01102305, 0.00706588, 0.00287341,\n",
       "        0.0024583 , 0.00211337, 0.00208212, 0.01336965, 0.00629993,\n",
       "        0.00591936, 0.00587396, 0.00298898, 0.00278835, 0.00178323,\n",
       "        0.00670713, 0.00307484, 0.00272752, 0.00197641, 0.00285788,\n",
       "        0.00279265, 0.00253507, 0.00184359, 0.00183695, 0.01096951,\n",
       "        0.00516896, 0.00485671, 0.00481946, 0.0024524 , 0.00228778,\n",
       "        0.0014631 , 0.00515079, 0.00236135, 0.00209462, 0.0015178 ,\n",
       "        0.00901535, 0.00424813, 0.0039609 , 0.00201551, 0.00188023,\n",
       "        0.00120246, 0.00422492, 0.0020045 , 0.00151909, 0.00119589],\n",
       "       dtype=float32),\n",
       " 9: array([0.05394945, 0.02552741, 0.01892729, 0.0180825 , 0.01311901,\n",
       "        0.02649814, 0.02561499, 0.02496684, 0.02143993, 0.01761402,\n",
       "        0.10520816, 0.04768933, 0.04429671, 0.04332054, 0.01736845,\n",
       "        0.01580598, 0.01380483, 0.01334473, 0.01287839, 0.00917643,\n",
       "        0.00912249, 0.03466612, 0.02315187, 0.01095484, 0.00812246,\n",
       "        0.00775993, 0.00562989, 0.01889454, 0.00778003, 0.00382058,\n",
       "        0.00311924, 0.00718922, 0.00353045, 0.00232244, 0.01668847,\n",
       "        0.00756464, 0.0070265 , 0.00687165, 0.00275504, 0.0025072 ,\n",
       "        0.00385063, 0.00372229, 0.0036281 , 0.00311558, 0.00255961,\n",
       "        0.01135255, 0.00758183, 0.00265996, 0.00169858, 0.01118722,\n",
       "        0.00747141, 0.00262123, 0.00207247, 0.00167385, 0.01106366,\n",
       "        0.00311566, 0.00204958, 0.00165536, 0.01476407, 0.00669234,\n",
       "        0.00621625, 0.00607926, 0.00298538, 0.00243735, 0.00688801,\n",
       "        0.00325922, 0.00230869, 0.00167497, 0.00938317, 0.00626658,\n",
       "        0.00219853, 0.0021004 , 0.00152386, 0.00140392, 0.01301913,\n",
       "        0.00590138, 0.00548156, 0.00536076, 0.00263254, 0.00214928,\n",
       "        0.00616415, 0.00291671, 0.00206607, 0.00149895, 0.00286841,\n",
       "        0.00279583, 0.00240088, 0.00197245, 0.01168489, 0.00481138,\n",
       "        0.00236275, 0.00192902, 0.00248098, 0.00213051], dtype=float32),\n",
       " 10: array([0.07020772, 0.03155866, 0.02367901, 0.02262711, 0.02804634,\n",
       "        0.02793983, 0.02094438, 0.01587101, 0.01493662, 0.07924432,\n",
       "        0.0492112 , 0.03717924, 0.03114143, 0.01158419, 0.01154106,\n",
       "        0.05825401, 0.03364391, 0.01512308, 0.01134711, 0.01084303,\n",
       "        0.01432379, 0.01423696, 0.01074739, 0.00808719, 0.00761107,\n",
       "        0.02067393, 0.00969963, 0.00812444, 0.00302218, 0.00301093,\n",
       "        0.01566149, 0.00972588, 0.00432625, 0.00228945, 0.0169827 ,\n",
       "        0.00430785, 0.00281287, 0.00232823, 0.00230709, 0.0165817 ,\n",
       "        0.00957657, 0.00308641, 0.00227326, 0.00225262, 0.01633329,\n",
       "        0.0094331 , 0.00304018, 0.0027053 , 0.0022392 , 0.00221887,\n",
       "        0.00870266, 0.00391188, 0.00293515, 0.00384886, 0.00383424,\n",
       "        0.00287424, 0.00217801, 0.00204979, 0.01451978, 0.00838573,\n",
       "        0.00282826, 0.00270262, 0.00199058, 0.00809116, 0.0035991 ,\n",
       "        0.00235008, 0.00192752, 0.01263891, 0.00784884, 0.00349131,\n",
       "        0.0018476 , 0.00782913, 0.00351922, 0.00264053, 0.00267769,\n",
       "        0.00266146, 0.00200912, 0.00151182, 0.00142282, 0.00248796,\n",
       "        0.00247288, 0.00186676, 0.0014047 , 0.001322  , 0.00238427,\n",
       "        0.00178052, 0.00843537, 0.00523842, 0.00395764, 0.00331493,\n",
       "        0.00233015, 0.00123311], dtype=float32),\n",
       " 11: array([0.06361363, 0.02821   , 0.02709785, 0.02319275, 0.02058271,\n",
       "        0.03251385, 0.02666303, 0.01996903, 0.01556037, 0.01442958,\n",
       "        0.06990807, 0.0542421 , 0.04407782, 0.03442102, 0.01268714,\n",
       "        0.0126753 , 0.01483128, 0.01458967, 0.01401448, 0.00865543,\n",
       "        0.00802644, 0.03830963, 0.02600458, 0.01153195, 0.01107731,\n",
       "        0.00948095, 0.00841399, 0.00935693, 0.0041494 , 0.00398582,\n",
       "        0.00302751, 0.01365256, 0.00926735, 0.00337876, 0.00212221,\n",
       "        0.00877699, 0.00389223, 0.00373878, 0.00283987, 0.01285692,\n",
       "        0.00872728, 0.00318186, 0.00238828, 0.00199854, 0.00477035,\n",
       "        0.00391193, 0.00292981, 0.00228298, 0.00211707, 0.01016949,\n",
       "        0.00300809, 0.00235894, 0.00386454, 0.00380158, 0.00365171,\n",
       "        0.00277373, 0.00225532, 0.00209142, 0.01195669, 0.00927727,\n",
       "        0.00274418, 0.00216994, 0.00317243, 0.00312075, 0.00299771,\n",
       "        0.00185141, 0.00171686, 0.01043277, 0.00809485, 0.00657798,\n",
       "        0.00513684, 0.00189337, 0.00189161, 0.00927322, 0.00629466,\n",
       "        0.00268137, 0.00229496, 0.00203669, 0.00144147, 0.00901026,\n",
       "        0.00213432, 0.00167373, 0.00140059, 0.00916882, 0.00711414,\n",
       "        0.00578104, 0.0045145 , 0.00210433, 0.00166399, 0.00848743,\n",
       "        0.00658545, 0.00194795, 0.00154033, 0.00837156, 0.00649554,\n",
       "        0.00527836, 0.00412195, 0.00192135, 0.0015193 ], dtype=float32),\n",
       " 12: array([0.05706758, 0.05099855, 0.02670166, 0.02406795, 0.02290036,\n",
       "        0.06722038, 0.05711686, 0.04601815, 0.03416701, 0.01394572,\n",
       "        0.01351061, 0.03930196, 0.01854792, 0.01738547, 0.01010958,\n",
       "        0.01003347, 0.02283815, 0.0170143 , 0.01328362, 0.00989375,\n",
       "        0.00981926, 0.03198483, 0.02233998, 0.01996416, 0.01045278,\n",
       "        0.00942177, 0.0089647 , 0.01028819, 0.00538666, 0.00485535,\n",
       "        0.00455105, 0.00264641, 0.00262649, 0.00905154, 0.00808893,\n",
       "        0.00423518, 0.00381744, 0.01221425, 0.00853111, 0.00342341,\n",
       "        0.00198502, 0.00833479, 0.0074484 , 0.00389981, 0.00351515,\n",
       "        0.00935673, 0.00266413, 0.00189872, 0.01111886, 0.00776603,\n",
       "        0.00311639, 0.0018562 , 0.001807  , 0.00373157, 0.00278   ,\n",
       "        0.00217043, 0.00161656, 0.00160439, 0.00921914, 0.00783346,\n",
       "        0.00631129, 0.00468594, 0.00223041, 0.00185295, 0.00557439,\n",
       "        0.00263074, 0.00246587, 0.00143389, 0.0014231 , 0.00879064,\n",
       "        0.00613988, 0.00548691, 0.00287282, 0.00246384, 0.00142863,\n",
       "        0.00826362, 0.00702156, 0.00199924, 0.0016609 , 0.00746317,\n",
       "        0.00634142, 0.00510918, 0.00379341, 0.00180558, 0.00150002,\n",
       "        0.00646442, 0.00549279, 0.00156395, 0.00129928, 0.00596466,\n",
       "        0.00139716, 0.00099575, 0.00096936, 0.00557367, 0.00473592,\n",
       "        0.00381566, 0.00134845, 0.00112025], dtype=float32),\n",
       " 13: array([0.05862064, 0.0511677 , 0.03695256, 0.02509213, 0.01625721,\n",
       "        0.05377216, 0.04693564, 0.02301676, 0.01553374, 0.01491258,\n",
       "        0.04001238, 0.03682205, 0.01821092, 0.00679547, 0.00501252,\n",
       "        0.03059315, 0.02815383, 0.01392392, 0.00519576, 0.00383253,\n",
       "        0.0225898 , 0.01634961, 0.01427096, 0.0102508 , 0.00699833,\n",
       "        0.0065262 , 0.00472309, 0.00453422, 0.00389555, 0.02576262,\n",
       "        0.02370846, 0.0117254 , 0.00886764, 0.00426693, 0.00377254,\n",
       "        0.00322739, 0.02396115, 0.02205063, 0.01090549, 0.00406942,\n",
       "        0.01830862, 0.00905482, 0.00337884, 0.01070865, 0.00675039,\n",
       "        0.00674007, 0.00324318, 0.00286741, 0.00903659, 0.00788769,\n",
       "        0.00569637, 0.00386804, 0.00250611, 0.0109152 , 0.00201439,\n",
       "        0.00200488, 0.00862362, 0.00391323, 0.00264592, 0.0025002 ,\n",
       "        0.00249137, 0.00180303, 0.00148712, 0.00935396, 0.00462615,\n",
       "        0.00172626, 0.00584599, 0.0042311 , 0.00369316, 0.00265279,\n",
       "        0.00181109, 0.00168891, 0.00122228, 0.00117341, 0.00100812,\n",
       "        0.00716569, 0.00659434, 0.00326133, 0.00121698, 0.00089768,\n",
       "        0.00384377, 0.00335508, 0.00242299, 0.0016453 , 0.00106599,\n",
       "        0.00696954, 0.00317206, 0.00240263, 0.00239895, 0.00115433,\n",
       "        0.00102058, 0.0008731 , 0.00355602, 0.00310391, 0.0022416 ,\n",
       "        0.00107696, 0.00342242, 0.0029873 , 0.00146494, 0.00098867,\n",
       "        0.00094914], dtype=float32),\n",
       " 14: array([0.06103452, 0.05836289, 0.04155605, 0.02532889, 0.01645714,\n",
       "        0.04076964, 0.03898507, 0.01691911, 0.01099298, 0.00929764,\n",
       "        0.04044907, 0.03414549, 0.01841839, 0.00714575, 0.00506767,\n",
       "        0.02446788, 0.01730794, 0.01655033, 0.01252427, 0.00718267,\n",
       "        0.0069394 , 0.00466685, 0.00394713, 0.00383095, 0.02957207,\n",
       "        0.02496356, 0.01346557, 0.00522422, 0.00370494, 0.028481  ,\n",
       "        0.02404252, 0.01296875, 0.01016768, 0.00485249, 0.00435271,\n",
       "        0.00356825, 0.02473254, 0.02087821, 0.0112619 , 0.00436926,\n",
       "        0.01070156, 0.00728628, 0.00677621, 0.00323392, 0.00290085,\n",
       "        0.0157447 , 0.00849283, 0.00329495, 0.00938699, 0.0089761 ,\n",
       "        0.00639124, 0.00389553, 0.00253108, 0.01233566, 0.00258153,\n",
       "        0.01026178, 0.00525265, 0.00317599, 0.00291037, 0.00289252,\n",
       "        0.00165542, 0.00160669, 0.00214653, 0.00878559, 0.00473903,\n",
       "        0.00183859, 0.00465313, 0.00444945, 0.00316813, 0.00140613,\n",
       "        0.00635414, 0.00449475, 0.00429801, 0.00325247, 0.00186529,\n",
       "        0.00180211, 0.00121195, 0.00102504, 0.00099487, 0.00739261,\n",
       "        0.00624054, 0.00336621, 0.00130598, 0.00092618, 0.00719499,\n",
       "        0.00327622, 0.00276195, 0.0025686 , 0.00122586, 0.0010996 ,\n",
       "        0.00090143, 0.00391074, 0.00373956, 0.00162293, 0.00105448,\n",
       "        0.00089186, 0.00385249, 0.00368386, 0.00262301, 0.00159876,\n",
       "        0.00103877], dtype=float32),\n",
       " 15: array([0.08494448, 0.0583987 , 0.04103978, 0.03555416, 0.01664993,\n",
       "        0.06525497, 0.0448623 , 0.02731298, 0.01667436, 0.0127906 ,\n",
       "        0.02149107, 0.01400145, 0.01030814, 0.00968281, 0.00677353,\n",
       "        0.00601145, 0.0365495 , 0.02485107, 0.01442127, 0.00569452,\n",
       "        0.00421274, 0.01699498, 0.01235867, 0.01168392, 0.00805168,\n",
       "        0.00711338, 0.00434266, 0.00389519, 0.00333118, 0.02596034,\n",
       "        0.01765119, 0.01024312, 0.00404469, 0.00299222, 0.02512005,\n",
       "        0.01707985, 0.01070166, 0.00991158, 0.00402181, 0.0035494 ,\n",
       "        0.00289537, 0.02209788, 0.015025  , 0.00871912, 0.00344291,\n",
       "        0.01185657, 0.00850578, 0.00572834, 0.00319657, 0.0028211 ,\n",
       "        0.01031627, 0.00709236, 0.00498417, 0.00431795, 0.00202209,\n",
       "        0.00946548, 0.00549289, 0.00216897, 0.00190315, 0.006994  ,\n",
       "        0.00480832, 0.00337906, 0.00292739, 0.00137089, 0.00702571,\n",
       "        0.00160991, 0.00650516, 0.00377499, 0.00149063, 0.00385798,\n",
       "        0.00251348, 0.00185047, 0.00173822, 0.00121596, 0.00107915,\n",
       "        0.00376783, 0.00245474, 0.00180723, 0.0016976 , 0.00132396,\n",
       "        0.00118754, 0.00752837, 0.00511876, 0.00297046, 0.00117294,\n",
       "        0.00086773, 0.00408138, 0.00280592, 0.00197187, 0.00170829,\n",
       "        0.00079999, 0.00653399, 0.00444265, 0.00278361, 0.0025781 ,\n",
       "        0.00092324, 0.00075312], dtype=float32),\n",
       " 16: array([0.08542608, 0.06137098, 0.03859155, 0.03115577, 0.01426596,\n",
       "        0.05491483, 0.03945139, 0.02002801, 0.01363404, 0.00917065,\n",
       "        0.06436276, 0.02410994, 0.02306703, 0.00828645, 0.00804081,\n",
       "        0.01874002, 0.01138314, 0.00733721, 0.00707404, 0.00465893,\n",
       "        0.00463392, 0.03944432, 0.01477562, 0.01413648, 0.0050783 ,\n",
       "        0.00492776, 0.0357906 , 0.01340696, 0.01282702, 0.0046079 ,\n",
       "        0.029987  , 0.01123297, 0.01074707, 0.01002892, 0.00389929,\n",
       "        0.00374626, 0.00336606, 0.01308019, 0.01046509, 0.00939694,\n",
       "        0.00635675, 0.00477048, 0.0032475 , 0.00260171, 0.00258775,\n",
       "        0.00218436, 0.01120798, 0.00763268, 0.00506325, 0.00296762,\n",
       "        0.0025618 , 0.01002242, 0.0072002 , 0.00452766, 0.00365528,\n",
       "        0.00167372, 0.01560365, 0.00584504, 0.0055922 , 0.00200891,\n",
       "        0.00194936, 0.00499996, 0.00478368, 0.00171846, 0.0015705 ,\n",
       "        0.00539881, 0.00387856, 0.00243893, 0.001969  , 0.00090159,\n",
       "        0.00403984, 0.00138847, 0.0039471 , 0.00377637, 0.0013566 ,\n",
       "        0.00362076, 0.00219934, 0.00141762, 0.00136678, 0.00112359,\n",
       "        0.00090015, 0.00089532, 0.00328421, 0.00199491, 0.00128585,\n",
       "        0.00123973, 0.00081648, 0.0008121 , 0.00377582, 0.00271259,\n",
       "        0.00170574, 0.00137708, 0.00063055, 0.00727448, 0.00272498,\n",
       "        0.00260711, 0.00243289, 0.0009088 , 0.00081656], dtype=float32),\n",
       " 17: array([0.03767294, 0.02615719, 0.02253786, 0.01516968, 0.00992799,\n",
       "        0.03065385, 0.02128367, 0.01234333, 0.00807824, 0.00707006,\n",
       "        0.07800787, 0.05000273, 0.02929327, 0.01184465, 0.00763833,\n",
       "        0.04715239, 0.03022447, 0.01770651, 0.00715958, 0.00461704,\n",
       "        0.0446384 , 0.02861303, 0.02201277, 0.01676247, 0.00681159,\n",
       "        0.00676387, 0.00437088, 0.03554463, 0.02278396, 0.0133476 ,\n",
       "        0.00539707, 0.03526214, 0.02260289, 0.01324153, 0.00535417,\n",
       "        0.00345278, 0.01014011, 0.00829581, 0.00704051, 0.00595544,\n",
       "        0.0040831 , 0.00267223, 0.00252208, 0.00233873, 0.00970367,\n",
       "        0.00722603, 0.00432297, 0.00300269, 0.00298165, 0.00276434,\n",
       "        0.01039648, 0.00609061, 0.00246272, 0.01034637, 0.00606125,\n",
       "        0.00245085, 0.0055012 , 0.00381961, 0.00329109, 0.00221516,\n",
       "        0.00144974, 0.00781295, 0.00185073, 0.01152082, 0.0073848 ,\n",
       "        0.00568132, 0.00432626, 0.0017457 , 0.00112809, 0.00443412,\n",
       "        0.00303459, 0.00217849, 0.00155353, 0.00120386, 0.00092257,\n",
       "        0.0038637 , 0.00264422, 0.00189824, 0.00135368, 0.00104899,\n",
       "        0.00080389, 0.00250951, 0.00180154, 0.00128472, 0.00099555,\n",
       "        0.00076294, 0.00070747, 0.00752132, 0.00370903, 0.00282438,\n",
       "        0.00165237, 0.00114771, 0.00113967, 0.00073647, 0.00751966,\n",
       "        0.00482007, 0.00282376, 0.00114178, 0.00113942, 0.00073631],\n",
       "       dtype=float32),\n",
       " 18: array([0.04886324, 0.02440763, 0.01322565, 0.01167663, 0.06550064,\n",
       "        0.04020193, 0.02008123, 0.01380602, 0.01088132, 0.00960687,\n",
       "        0.03734314, 0.01010755, 0.02353473, 0.02165819, 0.01602681,\n",
       "        0.01506798, 0.00895719, 0.02054734, 0.01803598, 0.01472686,\n",
       "        0.01384581, 0.00823066, 0.03577851, 0.02035024, 0.01241291,\n",
       "        0.010969  , 0.01051569, 0.00754128, 0.00647686, 0.00524758,\n",
       "        0.02634815, 0.02575703, 0.01437765, 0.01030487, 0.00968837,\n",
       "        0.00575927, 0.01369762, 0.01202346, 0.00981747, 0.00923014,\n",
       "        0.00548687, 0.02448332, 0.01502698, 0.00750611, 0.0040673 ,\n",
       "        0.00359093, 0.02423353, 0.01487367, 0.01378364, 0.00840752,\n",
       "        0.00742953, 0.00510787, 0.00438691, 0.00355429, 0.01773614,\n",
       "        0.01733822, 0.01299891, 0.01550112, 0.01136085, 0.00845347,\n",
       "        0.0029666 , 0.01455593, 0.00998433, 0.00876402, 0.00672793,\n",
       "        0.00686337, 0.00383586, 0.00834531], dtype=float32),\n",
       " 19: array([0.04715062, 0.02436505, 0.01273156, 0.01206279, 0.04121533,\n",
       "        0.01112892, 0.06560558, 0.03544766, 0.01831756, 0.01287702,\n",
       "        0.00957154, 0.00906876, 0.00846027, 0.01467731, 0.01330945,\n",
       "        0.01631995, 0.01311641, 0.00975525, 0.04053605, 0.01841596,\n",
       "        0.01182452, 0.01131796, 0.01036968, 0.00795639, 0.00560336,\n",
       "        0.00522739, 0.03651636, 0.03318858, 0.02025409, 0.01659169,\n",
       "        0.01288944, 0.0103593 , 0.00770466, 0.01659821, 0.01056288,\n",
       "        0.00848943, 0.00631396, 0.02468921, 0.02243925, 0.017682  ,\n",
       "        0.0150627 , 0.01233902, 0.00958571, 0.00770407, 0.00572986,\n",
       "        0.02300264, 0.01242867, 0.01045036, 0.00670996, 0.00642251,\n",
       "        0.00451494, 0.00317969, 0.00296634, 0.02115385, 0.01142973,\n",
       "        0.00590631, 0.00308624, 0.00292413, 0.01154901, 0.00946069,\n",
       "        0.00734964, 0.00564703, 0.00419994, 0.01584667, 0.01712322,\n",
       "        0.01226336, 0.0095621 , 0.00307143, 0.00861879], dtype=float32)}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_list_dict_20_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'idx': [0],\n",
       "  'probs': array([0.09048778, 0.05076183, 0.04150419, 0.03866458, 0.03724753,\n",
       "         0.02748025, 0.02599083, 0.0244996 , 0.02396833, 0.02166077,\n",
       "         0.02079083, 0.02045504, 0.01967757, 0.01699181, 0.01649871,\n",
       "         0.01646895, 0.01611677, 0.01563914, 0.01525799, 0.01511502,\n",
       "         0.0150912 , 0.01467046, 0.01446176, 0.0141665 , 0.01414402,\n",
       "         0.01388623, 0.01383731, 0.01358511, 0.01355814, 0.01227592,\n",
       "         0.01215177, 0.01209789, 0.01193168, 0.01174672, 0.0116218 ,\n",
       "         0.01135304, 0.0110093 , 0.00950779, 0.0093345 , 0.00838564,\n",
       "         0.00834963, 0.00811123, 0.0080565 , 0.00794189, 0.00777975,\n",
       "         0.00775029, 0.00764003, 0.00736409, 0.0072037 , 0.00657532,\n",
       "         0.00617821, 0.0060964 , 0.00547115, 0.00531351, 0.00460301,\n",
       "         0.00442002, 0.00403647, 0.00402448, 0.00395668, 0.0032632 ,\n",
       "         0.00307392, 0.00305389, 0.00302047, 0.00301167, 0.00291913,\n",
       "         0.00280578, 0.00273657, 0.00265739, 0.00262445, 0.00260896,\n",
       "         0.00258839, 0.00254827, 0.00246287, 0.00245973, 0.0024149 ,\n",
       "         0.00233369, 0.00228716, 0.00216529, 0.00216011, 0.00215489,\n",
       "         0.00212424, 0.00208765, 0.00208086, 0.00197641, 0.00156235,\n",
       "         0.00155839, 0.00153622, 0.00142607, 0.00142347, 0.00140141,\n",
       "         0.00135444, 0.00115108], dtype=float32)},\n",
       " {'idx': [1],\n",
       "  'probs': array([0.08637714, 0.07856175, 0.05672276, 0.04606517, 0.04116594,\n",
       "         0.03513036, 0.03146222, 0.02811608, 0.02751385, 0.02502342,\n",
       "         0.02399382, 0.02284375, 0.02032179, 0.01881838, 0.01816048,\n",
       "         0.018068  , 0.01787195, 0.01681929, 0.01549786, 0.01531636,\n",
       "         0.01486621, 0.01385441, 0.01311266, 0.01247181, 0.01242422,\n",
       "         0.01220701, 0.01220643, 0.01185729, 0.01172456, 0.01143543,\n",
       "         0.01119013, 0.0109888 , 0.0106815 , 0.009893  , 0.00976245,\n",
       "         0.00867944, 0.00815883, 0.00794582, 0.00788441, 0.00788427,\n",
       "         0.00775222, 0.00769937, 0.00732288, 0.00698274, 0.00578198,\n",
       "         0.00569278, 0.00516704, 0.00509262, 0.00476848, 0.00458548,\n",
       "         0.00440947, 0.00430828, 0.00412436, 0.00405842, 0.00385007,\n",
       "         0.00345835, 0.00326853, 0.003019  , 0.00293203, 0.00281477,\n",
       "         0.00257689, 0.00254715, 0.00243141, 0.0022579 , 0.00224324,\n",
       "         0.00215878, 0.00211518, 0.00209734, 0.00203257, 0.00193231,\n",
       "         0.00185639, 0.00175873, 0.00167149, 0.0015219 , 0.00144896,\n",
       "         0.00141643, 0.00128192, 0.00120089, 0.00115399, 0.00111402,\n",
       "         0.00107965, 0.00099501, 0.0009399 ], dtype=float32)},\n",
       " {'idx': [2],\n",
       "  'probs': array([0.09445282, 0.05229262, 0.0494432 , 0.0329745 , 0.03117772,\n",
       "         0.02864361, 0.02699113, 0.0269179 , 0.02562434, 0.02361058,\n",
       "         0.02310612, 0.0221881 , 0.02009769, 0.02002779, 0.01943306,\n",
       "         0.01888684, 0.01886881, 0.01873863, 0.01771756, 0.01564761,\n",
       "         0.01563661, 0.01535594, 0.01451918, 0.01326493, 0.01288906,\n",
       "         0.01252503, 0.01250782, 0.01220322, 0.01182626, 0.01180023,\n",
       "         0.01130694, 0.0112812 , 0.01097137, 0.01096594, 0.00950888,\n",
       "         0.00937281, 0.00924749, 0.00861059, 0.00845623, 0.00841131,\n",
       "         0.00796586, 0.0077056 , 0.00769506, 0.00719763, 0.00685123,\n",
       "         0.00680543, 0.0067815 , 0.00599608, 0.00593946, 0.00577252,\n",
       "         0.00572355, 0.00564739, 0.00560947, 0.00519091, 0.00437794,\n",
       "         0.00437292, 0.00405425, 0.00368491, 0.00360869, 0.00360612,\n",
       "         0.00358352, 0.00340743, 0.00325173, 0.00323829, 0.00316061,\n",
       "         0.00314956, 0.0030931 , 0.00307177, 0.00291887, 0.0028362 ,\n",
       "         0.00279232, 0.00275648, 0.00275415, 0.00267862, 0.00263402,\n",
       "         0.0024816 , 0.00237786, 0.00227442, 0.0022021 , 0.00215742,\n",
       "         0.00194476, 0.00193598, 0.00167967, 0.00158761, 0.00154181,\n",
       "         0.00121177, 0.00119005], dtype=float32)},\n",
       " {'idx': [3],\n",
       "  'probs': array([0.15088388, 0.06915317, 0.04326241, 0.03883892, 0.02934929,\n",
       "         0.02842225, 0.02429774, 0.02401302, 0.0211699 , 0.01970579,\n",
       "         0.01953865, 0.01952429, 0.01939776, 0.01865333, 0.01778104,\n",
       "         0.0173837 , 0.01645525, 0.01643308, 0.01563137, 0.01479652,\n",
       "         0.01385865, 0.01350692, 0.01336845, 0.01326981, 0.01286226,\n",
       "         0.01270965, 0.01222425, 0.01183326, 0.01179313, 0.01131223,\n",
       "         0.01128231, 0.01060435, 0.01054758, 0.01045567, 0.01028058,\n",
       "         0.01020054, 0.00968013, 0.0090808 , 0.0088799 , 0.00830163,\n",
       "         0.00804667, 0.00768246, 0.0071382 , 0.00692006, 0.00601736,\n",
       "         0.00572899, 0.00555529, 0.00522372, 0.00468275, 0.00429908,\n",
       "         0.00419247, 0.00417736, 0.00378135, 0.00352484, 0.00350775,\n",
       "         0.00348546, 0.00335127, 0.00327195, 0.00302023, 0.00299951,\n",
       "         0.00295637, 0.00290412, 0.00281556, 0.00276087, 0.00265836,\n",
       "         0.00260558, 0.00243886, 0.00242667, 0.00242398, 0.00241118,\n",
       "         0.0024048 , 0.00236395, 0.00222861, 0.00201156, 0.00195738,\n",
       "         0.00192372, 0.00171758, 0.00163204, 0.00162323, 0.00153097,\n",
       "         0.00144665, 0.00142413, 0.00133872, 0.00133518, 0.00130984],\n",
       "        dtype=float32)},\n",
       " {'idx': [4],\n",
       "  'probs': array([0.08991416, 0.07934231, 0.0708739 , 0.06998449, 0.06901852,\n",
       "         0.06645869, 0.04590575, 0.03573061, 0.03538288, 0.03523742,\n",
       "         0.03120974, 0.03077898, 0.02976787, 0.02483011, 0.01962233,\n",
       "         0.0172757 , 0.01713152, 0.01513791, 0.01512261, 0.01346424,\n",
       "         0.01333427, 0.01327506, 0.01270957, 0.0122225 , 0.01177063,\n",
       "         0.01160818, 0.01146184, 0.00545065, 0.00536244, 0.00525923,\n",
       "         0.00502628, 0.00500664, 0.00474307, 0.00451993, 0.0044353 ,\n",
       "         0.00432019, 0.00418688, 0.0040565 , 0.00391219, 0.0038582 ,\n",
       "         0.00333253, 0.00312551, 0.00302752, 0.00298439, 0.00261509,\n",
       "         0.00259104, 0.00212541, 0.00208021, 0.00199568, 0.00192985,\n",
       "         0.0017453 , 0.00166405, 0.00163951, 0.00148945, 0.00148466,\n",
       "         0.0014062 , 0.00137176, 0.00134271, 0.00124621, 0.00117655,\n",
       "         0.000917  ], dtype=float32)},\n",
       " {'idx': [5],\n",
       "  'probs': array([0.11640742, 0.08895899, 0.08334686, 0.07378618, 0.05614652,\n",
       "         0.04510506, 0.04146026, 0.03421194, 0.02915883, 0.02792966,\n",
       "         0.02633681, 0.02284571, 0.02243717, 0.02159289, 0.0213636 ,\n",
       "         0.01929584, 0.01734655, 0.0167479 , 0.01643229, 0.01450484,\n",
       "         0.01447321, 0.01221141, 0.01159429, 0.01108537, 0.01037125,\n",
       "         0.00913479, 0.00875953, 0.00869318, 0.0083317 , 0.00781048,\n",
       "         0.00726551, 0.00698997, 0.00627452, 0.00586525, 0.00567046,\n",
       "         0.00551433, 0.00538615, 0.00516599, 0.00454963, 0.00435736,\n",
       "         0.0041605 , 0.00405625, 0.00336875, 0.00306984, 0.00294715,\n",
       "         0.00260759, 0.00253215, 0.00243881, 0.00204421, 0.00202398,\n",
       "         0.00195473, 0.00161804, 0.00155276, 0.00154207, 0.00148699,\n",
       "         0.00142514, 0.00128092, 0.0012723 , 0.00103222, 0.00096999,\n",
       "         0.00094513, 0.00075085], dtype=float32)},\n",
       " {'idx': [6],\n",
       "  'probs': array([0.08673111, 0.0747098 , 0.06814832, 0.06803267, 0.06784814,\n",
       "         0.06410839, 0.04393362, 0.03656654, 0.03510398, 0.03504441,\n",
       "         0.03494937, 0.03452051, 0.03446193, 0.0292767 , 0.02023804,\n",
       "         0.01634138, 0.01573325, 0.01554531, 0.01549305, 0.01508078,\n",
       "         0.01371531, 0.01284012, 0.01281833, 0.01236229, 0.01190112,\n",
       "         0.01051437, 0.00908665, 0.00790404, 0.00779055, 0.00551615,\n",
       "         0.00541608, 0.00537148, 0.00535492, 0.00533327, 0.00442669,\n",
       "         0.00426196, 0.00336165, 0.00324452, 0.0032301 , 0.00322896,\n",
       "         0.00321924, 0.00292736, 0.00265112, 0.00259616, 0.00251874,\n",
       "         0.00230709, 0.00228556, 0.00176189, 0.00171756, 0.00160889,\n",
       "         0.00145507, 0.00137932, 0.00137884, 0.00137691, 0.00137469,\n",
       "         0.00135961, 0.00124742, 0.00124698, 0.00122156, 0.00122113,\n",
       "         0.0012073 , 0.00120297, 0.00118884], dtype=float32)},\n",
       " {'idx': [7],\n",
       "  'probs': array([0.08548806, 0.08426452, 0.06786104, 0.06710856, 0.06687706,\n",
       "         0.06596335, 0.0427843 , 0.04194986, 0.03785712, 0.03329376,\n",
       "         0.03283888, 0.02961551, 0.02921088, 0.02593877, 0.01814641,\n",
       "         0.01697358, 0.01675236, 0.01588313, 0.01582433, 0.01329562,\n",
       "         0.01311397, 0.01255909, 0.01175526, 0.01171937, 0.01148659,\n",
       "         0.01061026, 0.0086027 , 0.00694848, 0.00648981, 0.00543783,\n",
       "         0.00520564, 0.00515681, 0.00494587, 0.00477682, 0.00470845,\n",
       "         0.00423713, 0.00420805, 0.0040024 , 0.00399909, 0.00373689,\n",
       "         0.00368583, 0.00350031, 0.0030941 , 0.0029713 , 0.00293358,\n",
       "         0.00262018, 0.00196623, 0.00194764, 0.00184584, 0.00178479,\n",
       "         0.0016925 , 0.00167421, 0.00167102, 0.00156219, 0.00146539,\n",
       "         0.00144938, 0.00137537, 0.00132667, 0.00116938, 0.00115474,\n",
       "         0.00110891, 0.00109693, 0.00109484, 0.00086923, 0.00085835,\n",
       "         0.00082428, 0.00081537, 0.00081382], dtype=float32)},\n",
       " {'idx': [8],\n",
       "  'probs': array([0.10134439, 0.05208046, 0.04775461, 0.04486982, 0.04452573,\n",
       "         0.03882215, 0.02488537, 0.02452254, 0.02387594, 0.02225229,\n",
       "         0.02178987, 0.02117902, 0.02113624, 0.01811942, 0.01764975,\n",
       "         0.01736018, 0.01664973, 0.01534668, 0.01492124, 0.01469004,\n",
       "         0.01386608, 0.01351721, 0.01336965, 0.01329627, 0.01140853,\n",
       "         0.01129158, 0.01103387, 0.01102305, 0.01096951, 0.01011987,\n",
       "         0.01001614, 0.00901535, 0.00888829, 0.00865792, 0.00852303,\n",
       "         0.00831676, 0.00812512, 0.00733303, 0.0072841 , 0.00706588,\n",
       "         0.00703106, 0.00699772, 0.00670714, 0.00629993, 0.00591936,\n",
       "         0.00587397, 0.00530313, 0.00516896, 0.00515079, 0.00485671,\n",
       "         0.00481946, 0.00470152, 0.00424813, 0.00422492, 0.0039609 ,\n",
       "         0.00394586, 0.00385494, 0.00368101, 0.00333586, 0.00332009,\n",
       "         0.0032511 , 0.00311195, 0.00309234, 0.00307484, 0.00299862,\n",
       "         0.00298898, 0.00296527, 0.00292142, 0.00287341, 0.00285788,\n",
       "         0.00279265, 0.00278835, 0.00272752, 0.00265844, 0.00259018,\n",
       "         0.00254919, 0.00253507, 0.0024583 , 0.0024524 , 0.00236135,\n",
       "         0.00235411, 0.00229986, 0.00228779, 0.00219179, 0.00211337,\n",
       "         0.00209462, 0.00208212, 0.00201551, 0.0020045 , 0.00199018,\n",
       "         0.00197641, 0.00188023, 0.00184359, 0.00183695, 0.00178323,\n",
       "         0.00151909, 0.0015178 , 0.0014631 , 0.00120246, 0.00119589],\n",
       "        dtype=float32)},\n",
       " {'idx': [9],\n",
       "  'probs': array([0.10520816, 0.05394945, 0.04768933, 0.04429671, 0.04332055,\n",
       "         0.03466612, 0.02649814, 0.02561499, 0.0255274 , 0.02496684,\n",
       "         0.02315187, 0.02143993, 0.01892729, 0.01889454, 0.01808251,\n",
       "         0.01761402, 0.01736845, 0.01668847, 0.01580598, 0.01476407,\n",
       "         0.01380483, 0.01334473, 0.01311901, 0.01301913, 0.01287839,\n",
       "         0.01168489, 0.01135255, 0.01118722, 0.01106366, 0.01095484,\n",
       "         0.00938317, 0.00917643, 0.00912249, 0.00812246, 0.00778003,\n",
       "         0.00775993, 0.00758183, 0.00756464, 0.00747141, 0.00718922,\n",
       "         0.0070265 , 0.00688801, 0.00687165, 0.00669234, 0.00626658,\n",
       "         0.00621625, 0.00616415, 0.00607926, 0.00590138, 0.00562989,\n",
       "         0.00548156, 0.00536076, 0.00481138, 0.00385063, 0.00382058,\n",
       "         0.00372229, 0.0036281 , 0.00353045, 0.00325922, 0.00311924,\n",
       "         0.00311566, 0.00311558, 0.00298538, 0.00291671, 0.00286841,\n",
       "         0.00279583, 0.00275504, 0.00265996, 0.00263254, 0.00262123,\n",
       "         0.00255961, 0.0025072 , 0.00248098, 0.00243735, 0.00240088,\n",
       "         0.00236275, 0.00232244, 0.00230869, 0.00219853, 0.00214928,\n",
       "         0.00213051, 0.0021004 , 0.00207247, 0.00206607, 0.00204958,\n",
       "         0.00197245, 0.00192902, 0.00169858, 0.00167497, 0.00167385,\n",
       "         0.00165536, 0.00152386, 0.00149895, 0.00140392], dtype=float32)},\n",
       " {'idx': [10],\n",
       "  'probs': array([0.07924433, 0.07020773, 0.05825401, 0.0492112 , 0.03717924,\n",
       "         0.03364392, 0.03155867, 0.03114144, 0.02804634, 0.02793984,\n",
       "         0.02367901, 0.02262711, 0.02094438, 0.02067393, 0.0169827 ,\n",
       "         0.0165817 , 0.01633329, 0.01587101, 0.01566149, 0.01512308,\n",
       "         0.01493662, 0.01451978, 0.01432379, 0.01423696, 0.01263892,\n",
       "         0.01158419, 0.01154106, 0.01134711, 0.01084303, 0.01074739,\n",
       "         0.00972588, 0.00969963, 0.00957657, 0.0094331 , 0.00870267,\n",
       "         0.00843537, 0.00838573, 0.00812444, 0.00809116, 0.00808719,\n",
       "         0.00784884, 0.00782913, 0.00761107, 0.00523842, 0.00432625,\n",
       "         0.00430785, 0.00395764, 0.00391188, 0.00384886, 0.00383424,\n",
       "         0.0035991 , 0.00351922, 0.00349131, 0.00331493, 0.00308641,\n",
       "         0.00304018, 0.00302218, 0.00301093, 0.00293515, 0.00287424,\n",
       "         0.00282826, 0.00281287, 0.0027053 , 0.00270262, 0.00267769,\n",
       "         0.00266146, 0.00264053, 0.00248796, 0.00247288, 0.00238427,\n",
       "         0.00235008, 0.00233015, 0.00232823, 0.00230709, 0.00228945,\n",
       "         0.00227326, 0.00225262, 0.0022392 , 0.00221887, 0.00217801,\n",
       "         0.00204979, 0.00200912, 0.00199058, 0.00192752, 0.00186676,\n",
       "         0.0018476 , 0.00178052, 0.00151182, 0.00142282, 0.0014047 ,\n",
       "         0.001322  , 0.00123311], dtype=float32)},\n",
       " {'idx': [11],\n",
       "  'probs': array([0.06990805, 0.06361362, 0.05424209, 0.04407782, 0.03830962,\n",
       "         0.034421  , 0.03251384, 0.02820999, 0.02709784, 0.02666302,\n",
       "         0.02600457, 0.02319275, 0.0205827 , 0.01996903, 0.01556036,\n",
       "         0.01483127, 0.01458966, 0.01442958, 0.01401448, 0.01365256,\n",
       "         0.01285692, 0.01268714, 0.0126753 , 0.01195669, 0.01153195,\n",
       "         0.01107731, 0.01043277, 0.01016948, 0.00948095, 0.00935693,\n",
       "         0.00927727, 0.00927322, 0.00926735, 0.00916882, 0.00901026,\n",
       "         0.00877699, 0.00872728, 0.00865543, 0.00848743, 0.00841399,\n",
       "         0.00837155, 0.00809485, 0.00802644, 0.00711414, 0.00658545,\n",
       "         0.00657798, 0.00649554, 0.00629466, 0.00578104, 0.00527836,\n",
       "         0.00513684, 0.00477035, 0.0045145 , 0.0041494 , 0.00412195,\n",
       "         0.00398582, 0.00391193, 0.00389223, 0.00386454, 0.00380158,\n",
       "         0.00373878, 0.00365171, 0.00337876, 0.00318186, 0.00317243,\n",
       "         0.00312075, 0.00302751, 0.00300809, 0.00299771, 0.00292981,\n",
       "         0.00283987, 0.00277373, 0.00274418, 0.00268137, 0.00238828,\n",
       "         0.00235894, 0.00229496, 0.00228298, 0.00225532, 0.00216994,\n",
       "         0.00213432, 0.00212221, 0.00211707, 0.00210433, 0.00209142,\n",
       "         0.00203669, 0.00199854, 0.00194795, 0.00192135, 0.00189337,\n",
       "         0.00189161, 0.00185141, 0.00171686, 0.00167373, 0.00166399,\n",
       "         0.00154033, 0.0015193 , 0.00144147, 0.00140059], dtype=float32)},\n",
       " {'idx': [12],\n",
       "  'probs': array([0.06722037, 0.05711686, 0.05706758, 0.05099855, 0.04601815,\n",
       "         0.03930195, 0.03416701, 0.03198482, 0.02670166, 0.02406795,\n",
       "         0.02290036, 0.02283815, 0.02233998, 0.01996417, 0.01854792,\n",
       "         0.01738547, 0.0170143 , 0.01394572, 0.01351061, 0.01328362,\n",
       "         0.01221425, 0.01111886, 0.01045278, 0.01028819, 0.01010958,\n",
       "         0.01003347, 0.00989375, 0.00981926, 0.00942177, 0.00935673,\n",
       "         0.00921914, 0.00905154, 0.0089647 , 0.00879065, 0.00853111,\n",
       "         0.00833479, 0.00826362, 0.00808893, 0.00783346, 0.00776603,\n",
       "         0.00746317, 0.0074484 , 0.00702156, 0.00646442, 0.00634142,\n",
       "         0.00631129, 0.00613988, 0.00596466, 0.00557439, 0.00557367,\n",
       "         0.00549279, 0.00548691, 0.00538666, 0.00510918, 0.00485534,\n",
       "         0.00473592, 0.00468594, 0.00455105, 0.00423518, 0.00389981,\n",
       "         0.00381744, 0.00381566, 0.00379341, 0.00373157, 0.00351515,\n",
       "         0.00342341, 0.00311639, 0.00287282, 0.00278   , 0.00266413,\n",
       "         0.00264642, 0.00263074, 0.00262649, 0.00246587, 0.00246384,\n",
       "         0.00223041, 0.00217043, 0.00199924, 0.00198502, 0.00189871,\n",
       "         0.00185621, 0.00185295, 0.001807  , 0.00180558, 0.0016609 ,\n",
       "         0.00161656, 0.00160439, 0.00156395, 0.00150002, 0.00143389,\n",
       "         0.00142863, 0.0014231 , 0.00139716, 0.00134845, 0.00129928,\n",
       "         0.00112025, 0.00099575, 0.00096936], dtype=float32)},\n",
       " {'idx': [13],\n",
       "  'probs': array([0.05862064, 0.05377216, 0.0511677 , 0.04693564, 0.04001238,\n",
       "         0.03695256, 0.03682204, 0.03059314, 0.02815383, 0.02576262,\n",
       "         0.02509213, 0.02396115, 0.02370846, 0.02301676, 0.0225898 ,\n",
       "         0.02205063, 0.01830862, 0.01821092, 0.01634961, 0.01625721,\n",
       "         0.01553374, 0.01491258, 0.01427095, 0.01392392, 0.0117254 ,\n",
       "         0.0109152 , 0.01090549, 0.01070865, 0.0102508 , 0.00935396,\n",
       "         0.00905482, 0.00903659, 0.00886764, 0.00862362, 0.00788769,\n",
       "         0.00716569, 0.00699833, 0.00696954, 0.00679547, 0.00675039,\n",
       "         0.00674007, 0.00659434, 0.0065262 , 0.00584599, 0.00569637,\n",
       "         0.00519576, 0.00501252, 0.00472309, 0.00462615, 0.00453422,\n",
       "         0.00426693, 0.0042311 , 0.00406942, 0.00391323, 0.00389555,\n",
       "         0.00386805, 0.00384377, 0.00383253, 0.00377254, 0.00369316,\n",
       "         0.00355602, 0.00342242, 0.00337884, 0.00335508, 0.00326133,\n",
       "         0.00324318, 0.00322739, 0.00317206, 0.00310391, 0.0029873 ,\n",
       "         0.00286741, 0.00265279, 0.00264592, 0.00250611, 0.0025002 ,\n",
       "         0.00249137, 0.00242299, 0.00240263, 0.00239895, 0.0022416 ,\n",
       "         0.00201439, 0.00200488, 0.00181109, 0.00180303, 0.00172626,\n",
       "         0.00168891, 0.0016453 , 0.00148712, 0.00146494, 0.00122228,\n",
       "         0.00121698, 0.00117341, 0.00115433, 0.00107696, 0.00106599,\n",
       "         0.00102058, 0.00100812, 0.00098867, 0.00094914, 0.00089768,\n",
       "         0.0008731 ], dtype=float32)},\n",
       " {'idx': [14],\n",
       "  'probs': array([0.06103452, 0.05836289, 0.04155604, 0.04076963, 0.04044906,\n",
       "         0.03898507, 0.03414549, 0.02957206, 0.02848099, 0.02532888,\n",
       "         0.02496356, 0.02473254, 0.02446788, 0.02404251, 0.02087821,\n",
       "         0.01841839, 0.01730794, 0.01691911, 0.01655033, 0.01645713,\n",
       "         0.0157447 , 0.01346557, 0.01296875, 0.01252427, 0.01233566,\n",
       "         0.0112619 , 0.01099298, 0.01070156, 0.01026178, 0.01016768,\n",
       "         0.00938699, 0.00929764, 0.0089761 , 0.00878559, 0.00849283,\n",
       "         0.00739261, 0.00728628, 0.00719498, 0.00718267, 0.00714575,\n",
       "         0.0069394 , 0.00677621, 0.00639124, 0.00635414, 0.00624054,\n",
       "         0.00525265, 0.00522422, 0.00506767, 0.00485249, 0.00473903,\n",
       "         0.00466685, 0.00465312, 0.00449475, 0.00444945, 0.00436926,\n",
       "         0.00435271, 0.004298  , 0.00394713, 0.00391074, 0.00389553,\n",
       "         0.00385249, 0.00383095, 0.00373956, 0.00370494, 0.00368386,\n",
       "         0.00356825, 0.0033662 , 0.00329495, 0.00327622, 0.00325247,\n",
       "         0.00323392, 0.00317599, 0.00316813, 0.00291037, 0.00290085,\n",
       "         0.00289252, 0.00276195, 0.00262301, 0.00258153, 0.0025686 ,\n",
       "         0.00253108, 0.00214653, 0.00186529, 0.00183859, 0.00180211,\n",
       "         0.00165542, 0.00162293, 0.00160669, 0.00159876, 0.00140613,\n",
       "         0.00130598, 0.00122586, 0.00121195, 0.0010996 , 0.00105448,\n",
       "         0.00103877, 0.00102504, 0.00099487, 0.00092618, 0.00090143,\n",
       "         0.00089186], dtype=float32)},\n",
       " {'idx': [15],\n",
       "  'probs': array([0.08494448, 0.06525496, 0.05839869, 0.0448623 , 0.04103978,\n",
       "         0.0365495 , 0.03555416, 0.02731298, 0.02596034, 0.02512006,\n",
       "         0.02485106, 0.02209788, 0.02149107, 0.01765119, 0.01707985,\n",
       "         0.01699498, 0.01667436, 0.01664993, 0.015025  , 0.01442127,\n",
       "         0.01400145, 0.0127906 , 0.01235867, 0.01185657, 0.01168392,\n",
       "         0.01070166, 0.01031627, 0.01030814, 0.01024312, 0.00991158,\n",
       "         0.00968281, 0.00946548, 0.00871912, 0.00850578, 0.00805168,\n",
       "         0.00752837, 0.00711338, 0.00709236, 0.00702571, 0.006994  ,\n",
       "         0.00677353, 0.00653399, 0.00650516, 0.00601145, 0.00572834,\n",
       "         0.00569452, 0.00549289, 0.00511876, 0.00498417, 0.00480832,\n",
       "         0.00444265, 0.00434266, 0.00431795, 0.00421274, 0.00408138,\n",
       "         0.00404469, 0.00402181, 0.00389519, 0.00385798, 0.00377499,\n",
       "         0.00376783, 0.0035494 , 0.00344291, 0.00337906, 0.00333118,\n",
       "         0.00319657, 0.00299222, 0.00297046, 0.00292739, 0.00289537,\n",
       "         0.0028211 , 0.00280592, 0.00278361, 0.0025781 , 0.00251348,\n",
       "         0.00245474, 0.00216897, 0.00202209, 0.00197187, 0.00190315,\n",
       "         0.00185047, 0.00180723, 0.00173822, 0.00170829, 0.0016976 ,\n",
       "         0.00160991, 0.00149063, 0.00137089, 0.00132396, 0.00121596,\n",
       "         0.00118754, 0.00117294, 0.00107915, 0.00092324, 0.00086773,\n",
       "         0.00079999, 0.00075312], dtype=float32)},\n",
       " {'idx': [16],\n",
       "  'probs': array([0.08542608, 0.06436276, 0.06137098, 0.05491484, 0.03945139,\n",
       "         0.03944432, 0.03859155, 0.0357906 , 0.03115578, 0.029987  ,\n",
       "         0.02410994, 0.02306703, 0.02002801, 0.01874002, 0.01560365,\n",
       "         0.01477563, 0.01426596, 0.01413648, 0.01363404, 0.01340696,\n",
       "         0.01308019, 0.01282702, 0.01138314, 0.01123297, 0.01120799,\n",
       "         0.01074707, 0.01046509, 0.01002892, 0.01002242, 0.00939695,\n",
       "         0.00917066, 0.00828645, 0.00804081, 0.00763269, 0.00733721,\n",
       "         0.00727448, 0.00720021, 0.00707404, 0.00635675, 0.00584504,\n",
       "         0.0055922 , 0.00539881, 0.0050783 , 0.00506325, 0.00499996,\n",
       "         0.00492776, 0.00478368, 0.00477048, 0.00465893, 0.00463392,\n",
       "         0.0046079 , 0.00452766, 0.00403984, 0.0039471 , 0.00389929,\n",
       "         0.00387856, 0.00377637, 0.00377582, 0.00374626, 0.00365528,\n",
       "         0.00362076, 0.00336606, 0.00328421, 0.0032475 , 0.00296762,\n",
       "         0.00272498, 0.00271259, 0.00260711, 0.00260171, 0.00258775,\n",
       "         0.0025618 , 0.00243893, 0.00243289, 0.00219934, 0.00218436,\n",
       "         0.00200891, 0.00199491, 0.001969  , 0.00194936, 0.00171846,\n",
       "         0.00170574, 0.00167372, 0.0015705 , 0.00141762, 0.00138847,\n",
       "         0.00137708, 0.00136678, 0.0013566 , 0.00128585, 0.00123973,\n",
       "         0.00112359, 0.0009088 , 0.00090159, 0.00090015, 0.00089532,\n",
       "         0.00081656, 0.00081648, 0.0008121 , 0.00063055], dtype=float32)},\n",
       " {'idx': [17],\n",
       "  'probs': array([0.07800786, 0.05000273, 0.04715239, 0.0446384 , 0.03767294,\n",
       "         0.03554463, 0.03526215, 0.03065385, 0.03022447, 0.02929327,\n",
       "         0.02861304, 0.02615719, 0.02278396, 0.02260289, 0.02253786,\n",
       "         0.02201278, 0.02128367, 0.01770651, 0.01676247, 0.01516968,\n",
       "         0.0133476 , 0.01324153, 0.01234333, 0.01184465, 0.01152082,\n",
       "         0.01039648, 0.01034637, 0.01014011, 0.00992799, 0.00970367,\n",
       "         0.00829581, 0.00807824, 0.00781295, 0.00763833, 0.00752132,\n",
       "         0.00751966, 0.0073848 , 0.00722603, 0.00715958, 0.00707006,\n",
       "         0.00704051, 0.00681159, 0.00676387, 0.00609061, 0.00606125,\n",
       "         0.00595544, 0.00568132, 0.0055012 , 0.00539707, 0.00535417,\n",
       "         0.00482007, 0.00461704, 0.00443412, 0.00437088, 0.00432626,\n",
       "         0.00432297, 0.0040831 , 0.0038637 , 0.00381961, 0.00370903,\n",
       "         0.00345278, 0.00329109, 0.00303459, 0.00300269, 0.00298165,\n",
       "         0.00282438, 0.00282376, 0.00276434, 0.00267223, 0.00264422,\n",
       "         0.00252208, 0.00250951, 0.00246272, 0.00245085, 0.00233873,\n",
       "         0.00221516, 0.00217849, 0.00189824, 0.00185073, 0.00180154,\n",
       "         0.0017457 , 0.00165237, 0.00155353, 0.00144974, 0.00135368,\n",
       "         0.00128472, 0.00120386, 0.00114771, 0.00114178, 0.00113967,\n",
       "         0.00113942, 0.00112809, 0.00104899, 0.00099555, 0.00092257,\n",
       "         0.00080389, 0.00076294, 0.00073647, 0.00073631, 0.00070747],\n",
       "        dtype=float32)},\n",
       " {'idx': [18],\n",
       "  'probs': array([0.06550065, 0.04886325, 0.04020193, 0.03734314, 0.03577851,\n",
       "         0.02634815, 0.02575703, 0.02448332, 0.02440763, 0.02423353,\n",
       "         0.02353474, 0.0216582 , 0.02054734, 0.02035024, 0.02008123,\n",
       "         0.01803599, 0.01773614, 0.01733823, 0.01602681, 0.01550112,\n",
       "         0.01506798, 0.01502698, 0.01487367, 0.01472686, 0.01455593,\n",
       "         0.01437765, 0.01384581, 0.01380603, 0.01378364, 0.01369763,\n",
       "         0.01322565, 0.01299891, 0.01241292, 0.01202346, 0.01167663,\n",
       "         0.01136085, 0.010969  , 0.01088132, 0.01051569, 0.01030487,\n",
       "         0.01010755, 0.00998433, 0.00981748, 0.00968837, 0.00960688,\n",
       "         0.00923014, 0.00895719, 0.00876402, 0.00845347, 0.00840752,\n",
       "         0.00834531, 0.00823067, 0.00754129, 0.00750611, 0.00742953,\n",
       "         0.00686337, 0.00672794, 0.00647686, 0.00575927, 0.00548687,\n",
       "         0.00524758, 0.00510787, 0.00438691, 0.0040673 , 0.00383586,\n",
       "         0.00359093, 0.00355429, 0.0029666 ], dtype=float32)},\n",
       " {'idx': [19],\n",
       "  'probs': array([0.06560558, 0.04715062, 0.04121533, 0.04053604, 0.03651636,\n",
       "         0.03544766, 0.03318857, 0.02468921, 0.02436505, 0.02300264,\n",
       "         0.02243925, 0.02115385, 0.02025409, 0.01841596, 0.01831756,\n",
       "         0.017682  , 0.01712322, 0.0165982 , 0.01659169, 0.01631995,\n",
       "         0.01584667, 0.0150627 , 0.01467731, 0.01330945, 0.01311641,\n",
       "         0.01288944, 0.01287702, 0.01273156, 0.01242867, 0.01233902,\n",
       "         0.01226336, 0.01206279, 0.01182452, 0.01154901, 0.01142973,\n",
       "         0.01131796, 0.01112892, 0.01056288, 0.01045036, 0.01036968,\n",
       "         0.01035929, 0.00975525, 0.0095857 , 0.00957154, 0.0095621 ,\n",
       "         0.00946069, 0.00906876, 0.00861879, 0.00848943, 0.00846027,\n",
       "         0.00795639, 0.00770466, 0.00770407, 0.00734964, 0.00670996,\n",
       "         0.0064225 , 0.00631396, 0.00590631, 0.00572986, 0.00564703,\n",
       "         0.00560336, 0.00522739, 0.00451494, 0.00419994, 0.00317969,\n",
       "         0.00308624, 0.00307143, 0.00296634, 0.00292413], dtype=float32)}]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_list_dict_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34, 35, 39, 40, 33])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_list_dict = []\n",
    "for d in probs_list_dict_20:\n",
    "    if len(d['probs']) > 1: # if prob_dict['probs'] is not 0\n",
    "        confidence = max(d['probs'])\n",
    "        confidence_list_dict.append(\n",
    "            {'idx': d['idx'], \n",
    "                'confidence': confidence}\n",
    "                )\n",
    "    elif d['idx']:\n",
    "        confidence_list_dict.append(\n",
    "            {'idx': d['idx'], \n",
    "                'confidence': np.array([0])}\n",
    "                )\n",
    "# deepAL+: return unlabeled_idxs[uncertainties.sort()[1][:n]]\n",
    "sorted_confidence_dict = sorted(confidence_list_dict, key=lambda d: d['confidence'])   \n",
    "unlabeled_idxs_20[[confidence_dict['idx'][0] for confidence_dict in sorted_confidence_dict[:5]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy(prob_list_dict, NUM_QUERY):\n",
    "    entropy_list_dict = []\n",
    "    for d in prob_list_dict:\n",
    "        if len(d['probs']) > 1: # if prob_dict['probs'] is not 0\n",
    "            log_probs = np.log(d['probs'])\n",
    "            entropy_list_dict.append(\n",
    "                {'idx': d['idx'], \n",
    "                'entropy': (d['probs']*log_probs).sum()}\n",
    "                )\n",
    "        elif d['idx']:\n",
    "            entropy_list_dict.append(\n",
    "                {'idx': d['idx'], \n",
    "                'entropy': np.array([0])}\n",
    "                )\n",
    "    # deepAL+: return unlabeled_idxs[uncertainties.sort()[1][:n]] # use smallest Entropy\n",
    "    sorted_entropy_dict = sorted(entropy_list_dict, key=lambda d: d['entropy'], reverse=True) # use largest Entropy, different from deepAL+\n",
    "    return unlabeled_idxs[[entropy_dict['idx'][0] for entropy_dict in sorted_entropy_dict[:NUM_QUERY]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 19, 15, 16, 18])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_idxs_20 = get_entropy(probs_list_dict_20, 5)\n",
    "q_idxs_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds, _, _ = trainer_qs.predict(unlabeled_data_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11129025, -2.3665497 , -0.79520124, ..., -4.5936365 ,\n",
       "        -4.586774  , -4.5850654 ],\n",
       "       [ 0.15815008, -2.4326143 , -0.5714892 , ..., -4.6285734 ,\n",
       "        -4.6285872 , -4.6248646 ],\n",
       "       [ 0.09457874, -2.5953221 , -1.8137492 , ..., -4.5691795 ,\n",
       "        -4.5709004 , -4.5793557 ],\n",
       "       ...,\n",
       "       [ 0.20229188, -2.5083427 , -2.0060809 , ..., -4.695624  ,\n",
       "        -4.69039   , -4.7005043 ],\n",
       "       [ 0.24428111, -2.3364782 , -0.4007522 , ..., -4.6479974 ,\n",
       "        -4.64676   , -4.645563  ],\n",
       "       [ 0.22122052, -2.4042737 , -1.0067688 , ..., -4.672873  ,\n",
       "        -4.674313  , -4.6712456 ]], dtype=float32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits, end_logits = preds\n",
    "start_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict with unlable data\n",
    "preds, _, _ = trainer_qs.predict(unlabeled_data_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11129025, -2.3665497 , -0.79520124, ..., -4.5936365 ,\n",
       "        -4.586774  , -4.5850654 ],\n",
       "       [ 0.15815008, -2.4326143 , -0.5714892 , ..., -4.6285734 ,\n",
       "        -4.6285872 , -4.6248646 ],\n",
       "       [ 0.09457874, -2.5953221 , -1.8137492 , ..., -4.5691795 ,\n",
       "        -4.5709004 , -4.5793557 ],\n",
       "       ...,\n",
       "       [ 0.20229188, -2.5083427 , -2.0060809 , ..., -4.695624  ,\n",
       "        -4.69039   , -4.7005043 ],\n",
       "       [ 0.24428111, -2.3364782 , -0.4007522 , ..., -4.6479974 ,\n",
       "        -4.64676   , -4.645563  ],\n",
       "       [ 0.22122052, -2.4042737 , -1.0067688 , ..., -4.672873  ,\n",
       "        -4.674313  , -4.6712456 ]], dtype=float32)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits, end_logits = preds\n",
    "start_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 624,  621,  627,  618,  628,  626,  617,  619,  622,  623,  620,\n",
       "        625, 1236, 1235,  446, 1224, 2579,  442,  445, 1237, 2577,  448,\n",
       "        439,  444, 1227,  450,  447,  451, 2581,  440, 2576, 1985,  443,\n",
       "       1983, 2981])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_idxs = get_entropy(probs_list_dict, NUM_QUERY)\n",
    "q_idxs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alqa",
   "language": "python",
   "name": "alqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6317ac8a4c65d05b4cf6bac76f72bfaae40b2e9380067c26c20c9afff1d8528e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
